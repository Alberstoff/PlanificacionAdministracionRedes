Tema 6: La capa de enlace.
Conceptos generales
Estándares
Dispositivos
Actividades
Bibliografía y referencias
Conceptos generales
La capa de enlace de datos se sitúa en el nivel 2 del modelo OSI. La misión de la capa de enlace es establecer una línea de comunicación libre de errores que pueda ser utilizada por la capa inmediatamente superior: la capa de red.

Como el nivel físico opera con bits, la capa de enlace tiene que montar bloques de información (llamados tramas en esta capa), dotarles de una dirección de capa de enlace (Dirección MAC), gestionar la detección o corrección de errores, y ocuparse del control de flujo entre equipos (para evitar que un equipo más rápido desborde a uno más lento).

En redes Ethernet esta capa se subdivide en dos subcapas:

Subcapa de enlace lógico (LLC – Logical Link Control)
Subcapa de acceso al medio (MAC - Medium Access Control)



La subcapa de enlace lógico se recoge en la norma IEEE 802.2 y es común para todos los demás tipos de redes (Ethernet o IEEE 802.3, IEEE 802.11 o Wi-Fi, IEEE 802.16 o WiMAX, etc.); todas ellas especifican un subcapa de acceso al medio así como una capa física distinta.

La subcapa de control de acceso al medio es la encargada de arbitrar el uso del medio de comunicación cuando este está compartido entre más de dos equipos como suele ser habitual en muchas LAN.



En la práctica la subcapa de acceso al medio suele formar parte de la propia tarjeta de comunicaciones, mientras que la subcapa de enlace lógico estaría en el programa adaptador de la tarjeta (driver en inglés).

Además de la formación de tramas, el nivel de enlace se ocupará del tratamiento de los errores que se produzcan en la recepción de las tramas, de eliminar tramas erróneas, solicitar retransmisiones, descartar tramas duplicadas, adecuar el flujo de datos entre emisores rápidos y receptores lentos, etc


Algunos protocolos y estándares que regulan aspectos de la capa de enlace

Parte de la especificación de los protocolos Ethernet y del estándar IEEE 802.3.
Parte de la especificación de la familia de estándares IEEE 802.11, para redes sin hilos.
Point to point protocol (PPP).
Parte de la especificación de tecnologías de enlace para WAN como HDLC, X.25, ATM, Frame Relay o xDSL.


Protocolo	Denominación	Usado en
HDLC	High--level Data Link Control	ISO
SDLC	Synchronous Data Link Control	IBM SNA
LAPB	Link Access Procedure – Balanced	X.25
LAPD	Link Access Procedure – D-channel	RDSI
LAPF	Link Access Procedure for Frame-mode	Frame Relay
LLC	Logical Link Control	IEEE 802
SLIP	Serial Line Internet Protocol	
PPP	Point-to-Point Protocol	
ATM	Asynchronous Transfer Mode	
La capa de enlace se encarga de los siguientes aspectos:

Delimitación de trama
Segmentación y bloque
Uso del medio compartido
Control de flujo
Control de errores
Delimitación de trama
Trama de 802.3 Ethernet
Preambulo
SDF
MAC destino
MAC origen
802.1Q Etiqueta (opcional)
longitud
Datos y relleno
CRC 32-bit
Gap entre frames
7 Bytes	1 Byte	6 Bytes	6 Bytes	(4 Bytes)	2 Bytes	De 46 (o 42) hasta 1500 Bytes	4 Bytes	12 Bytes
64–1522 Bytes	
72–1530 Bytes	
84–1542 Bytes
Nota: Al final de la trama hay un intervalo llamado IFG de 12 bytes que no se utiliza, se explica más adelante.


Campos de la trama:

Preámbulo: Sincronización bit "10101010" (x7).

SDF: Delimitador de comienzo de trama "10101011".

Direcciones MAC origen y destino:

Notación (por ejemplo): F2:3E:C1:8A:B1:01

OUI: Identificador organización.(3 bytes)

NIC: Id. Tarjeta interfaz de Red. (3 bytes)

Dirección de difusión (broadcast) FF:FF:FF:FF:FF:FF. Este tipo de dirección se utiliza para que todos los equipos conectados en el mismo dominio de difusión recojan la trama.

Etiqueta: es un campo opcional que indica la pertenencia a una VLAN o prioridad en IEEE P802.1p.

Longitud:

- Valores < 1536.

Datos + Relleno:

- Trama mínima de 64 bytes (512 bits -> 51,2 μs).

- Como Tx ≥ 2Tp: Datos+Relleno ≥ 46 bytes.

FCS (Frame Check Sequence) -> CRC (CRC, Cyclic Redundancy Check):

Secuencia de chequeo de trama. Es un CRC de un polinomio generador de orden 33:

x32+x26+x23+x22+x16+x12+x11+x10+x8+x7+x5+x4+x2+x+1


Espacio mínimo entre tramas:

IFG: "Inter-frame Gap" -> 12 bytes (96 bits) es un intervalo de espera que se realiza siempre antes de empezar a transmitir aún si el medio está libre.

CRC
La comprobación de redundancia cíclica (CRC) es un código de detección de errores usado frecuentemente en redes digitales y en dispositivos de almacenamiento para detectar cambios accidentales en los datos. Los bloques de datos ingresados en estos sistemas contiene un valor de verificación adjunto, basado en el residuo de una división de polinomios; el cálculo es repetido en el destino, y la acción de corrección puede tomarse en caso de que el valor de verificación no concuerde; por lo tanto se puede afirmar que este código es un tipo de función que recibe un flujo de datos de cualquier longitud como entrada y devuelve un valor de longitud fija como salida. El término suele ser usado para designar tanto a la función como a su resultado. Pueden ser usadas como suma de verificación para detectar la alteración de datos durante su transmisión o almacenamiento. Las CRC son populares porque su implementación en hardware binario es simple, son fáciles de analizar matemáticamente y son particularmente efectivas para detectar errores ocasionados por ruido en los canales de transmisión.

Ejemplo: Información a transmitir: 10110101101

Polinomio generador: 10011




Trama transmitida: 10110101101 0110

Resto (CRC-4): 0110

Segmentación y bloque
La segmentación surge por la longitud de las tramas ya que si es muy extensa, se debe de realizar tramas más pequeñas con la información de esa trama excesivamente larga.

Si estas tramas son excesivamente cortas, se ha de implementar unas técnicas de bloque que mejoran la eficiencia y que consiste en concatenar varios mensajes cortos de nivel superior en una única trama de la capa de enlace más larga.

Uso del medio compartido
División estática del canal
Técnicas de multiplexación (TDM, FDM o WDM, SDM, CDM)
División dinámica del canal
Técnicas de contención (CSMA/CD)
Protocolos libres de colisión (Paso de testigo, reserva)
División estática: Multiplexación
La multiplexación es la combinación de dos o más canales de información en un solo medio de transmisión usando un dispositivo llamado multiplexor. El proceso inverso se conoce como demultiplexación. Un concepto muy similar es el de control de acceso al medio.



Una aplicación usual de la multiplexación son las comunicaciones de larga distancia. Los enlaces de las redes de larga distancia son líneas de alta capacidad de fibra, de cable coaxial o de microondas, de modo que pueden transportar simultáneamente varias transmisiones de voz y de datos haciendo uso de las técnicas de multiplexación.

Una analogía posible para el problema del acceso múltiple sería una habitación (que representaría el canal) en la que varias personas desean hablar al mismo tiempo. Si varias personas hablan a la vez, se producirán interferencias y se hará difícil la comprensión. Para evitar o reducir el problema, podrían hablar por turnos (estrategia de división por tiempo - TDMA), hablar unos en tonos más agudos y otros más graves de forma que sus voces se distinguieran (división por frecuencia - FDMA), dirigir sus voces en distintas direcciones de la habitación (división espacial - SDMA) o hablar en idiomas distintos (división por código – CDMA), sólo las personas que conocen el código (es decir, el "idioma") pueden entenderlo.

TDMA (Acceso Múltiple por División de Tiempo)

Hace uso de multiplexación por división de tiempo o TDM (Time Division Multiplexing). En ella, el ancho de banda total del medio de transmisión es asignado a cada canal durante una fracción del tiempo total (intervalo de tiempo). Es decir se divide un único canal de frecuencia de radio en varias ranuras de tiempo. A cada persona que hace una llamada se le asigna una ranura de tiempo específica para la transmisión, lo que hace posible que varios usuarios utilicen un mismo canal simultáneamente sin interferir entre sí.



Existen varios estándares digitales basados en TDMA, tal como TDMA D-AMPS (Digital-Advanced Mobile Phone System), TDMA D-AMPS-1900, PCS-1900 (Personal Communication Services), GSM (Global System for Mobile Communication, en el que se emplea junto con saltos en frecuencia o frequency hopping ), DCS-1800 (Digital Communications System) y PDC (Personal Digital Cellular).


FDMA (Acceso Múltiple por División de Frecuencia)

Hace uso de multiplexación por división de frecuencia o FDM (Frequency Division Multiplexing) y su equivalente para medios ópticos, por división de longitud de onda o WDM (Wavelength Division Multiplexing).



FDM es un tipo de multiplexación utilizada generalmente en sistemas de transmisión analógicos. La forma de funcionamiento es la siguiente: se convierte cada fuente de varias que originalmente ocupaban el mismo espectro de frecuencias, a una banda distinta de frecuencias, y se transmite en forma simultánea por un solo medio de transmisión. Así se pueden transmitir muchos canales de banda relativamente angosta por un solo sistema de transmisión de banda ancha.



Hay muchas aplicaciones de FDM, por ejemplo, la radio FM comercial y las emisoras de televisión analógica, así como los sistemas de telecomunicaciones de alto volumen.

Una variante de FDM es la utilizada en fibra óptica, donde se multiplexan señales, que pueden ser analógicas o digitales, y se transmiten mediante portadoras ópticas de diferente longitud de onda, dando lugar a la denominada multiplexación por división de longitud de onda, o WDM del inglés Wavelength Division Multiplexing.


SDMA (Acceso Múltiple por División de Espacio)

Hace uso de multiplexación por división de espacio o SDM (Space Division Multiplexing).

El Acceso múltiple por división de espacio es una tecnología que segmenta el espacio en sectores utilizando antenas unidireccionales. Se utiliza generalmente en comunicaciones por satélite, pero también en redes celulares para reducir el número de estaciones base.


CDMA (Acceso Múltiple por División de Código)

Hace uso de multiplexación por división en código o CDM (Code Division Multiplexing).

La división por código se emplea en múltiples sistemas de comunicación por radiofrecuencia, tanto de telefonía móvil (como IS-95, CDMA2000, FOMA o UMTS), transmisión de datos (WiFi) o navegación por satélite (GPS).



División dinámica: diversas técnicas
CSMA/CD (Acceso Múltiple con Escucha de Portadora y Detección de Colisiones)

CSMA/CD (del inglés Carrier Sense Multiple Access with Collision Detection) o, en español, acceso múltiple con escucha de portadora y detección de colisiones, es un protocolo de acceso al medio compartido. Su uso está especialmente extendido en redes Ethernet donde es empleado para mejorar sus prestaciones. En CSMA/CD, los dispositivos de red escuchan el medio antes de transmitir, es decir, es necesario determinar si el canal y sus recursos se encuentran disponibles para realizar una transmisión. Además, mejora el rendimiento de CSMA finalizando el envío cuando se ha detectado una colisión.

En CSMA/CD, cada estación que desea transmitir debe realizar una escucha del medio – escucha de portadora- para comprobar si éste se encuentra libre, es decir, para comprobar que ninguna otra estación está en ese instante transmitiendo un mensaje. Si el medio se encuentra libre entonces tiene lugar dicha transmisión. Aun así, puede ocurrir que varias estaciones tengan mensajes para enviar y que comiencen a transmitir una trama en el mismo instante. Cuando esto se sucede, se dice que ha ocurrido una colisión en la red. La estación que ha detectado la colisión procederá a enviar un mensaje de jam de 32 bits al resto de estaciones para notificar dicho evento. Una vez que todas las estaciones han sido notificadas, automáticamente se paran todas las transmisiones y se ejecuta un algoritmo de backoff (o de postergación) que consiste en esperar un tiempo aleatorio (backoff) antes de volver a intentar la transmisión.


Token Ring (Paso de testigo)

Esta técnica se basa en una pequeña trama o testigo que circula a lo largo del anillo. Un bit indica el estado del anillo (libre u ocupado) y cuando ninguna estación está transmitiendo, el testigo simplemente circula por el anillo pasando de una estación a la siguiente. Cuando una estación desea transmitir, espera a recibir el testigo modificando el bit de estado del anillo de libre a ocupado e inserta a continuación la información a enviar junto con su propia dirección y la de la estación destino. El paquete de datos circula por el anillo hasta llegar a la estación receptora que copia su contenido y lo vuelve a poner en circulación incluyendo una marca de recepción, de tal forma que, cuando vuelve a llegar a la estación emisora, ésta lo retira de la red y genera un nuevo testigo libre.


Este sistema es poco eficiente para cargas bajas, pero para cargas altas el sistema se comporta de manera muy eficiente y equitativo. Una desventaja seria es que se pierda el testigo, en cuyo caso toda la red se bloquearía. Los bits que se modifican en el anillo indican si la trama que acompaña al anillo ha llegado a su destino, si no ha llegado o si ha llegado pero no se ha copiado. Esta información de control es muy importante para el funcionamiento del sistema.


Token Ring fue desarrollada por IBM en los años 1970 con topología física en anillo y técnica de acceso de paso de testigo, usando un frame de 3 bytes llamado token que viaja alrededor del anillo. Token Ring se recoge en el estándar IEEE 802.5. En desuso por la popularización de Ethernet.


Las características más destacadas de esta arquitectura son:



Utiliza una topología lógica en anillo, aunque por medio de una unidad de acceso de estación múltiple (MSAU o MAU - Multistation access unit), la red puede verse como si fuera una estrella. Tiene topología física estrella y topología lógica en anillo.
Cada equipo conectado a la red dispone de una interfaz de unidad adjunta (AUI - Attachment Unit Interface) que permite la conexión a la MAU.
Utiliza cable especial apantallado, aunque el cableado también puede ser par trenzado.
La longitud total de la red no puede superar los 366 metros.
La distancia entre una computadora y el MAU no puede ser mayor que 100 metros (por la degradación de la señal después de esta distancia en un cable de par trenzado).
A cada MAU se pueden conectar ocho computadoras.
Estas redes alcanzan una velocidad máxima de transmisión que oscila entre los 4 y los 16 Mbps.
Posteriormente el High Speed Token Ring (HSTR) elevó la velocidad a 110 Mbps pero la mayoría de redes no la soportan.
Control de flujo
El control de flujo es necesario para no saturar al receptor de uno a más emisores. Se realiza normalmente en la capa de transporte, y también a veces en la capa de enlace. Utiliza mecanismos de retroalimentación. El control de flujo conlleva dos acciones importantísimas que son la detección de errores y la corrección de errores.

Existen 2 técnicas:

Control de flujo mediante parada y espera
Control de flujo mediante ventana deslizante


Control de flujo mediante parada y espera
Nota: La numeración de tramas es 0 y 1. 
Después se reinicia la numeración, lo que no significa que se vuelvan a enviar las tramas,
sino que la numeración  vuelve a iniciarse. 

El procedimiento más sencillo para controlar el flujo, denominado control de flujo mediante parada y espera, funciona de la siguiente manera. Una entidad origen transmite una trama. Tras la recepción, la entidad destino indica su deseo de aceptar otra trama mediante el envío de una confirmación de la trama que acaba de recibir. El origen debe esperar a recibir la confirmación antes de proceder a la transmisión de la trama siguiente. De este modo, el destino puede parar el flujo de los datos sin más que retener las confirmaciones. Este procedimiento funciona adecuadamente y, de hecho, es difícil mejorar sus prestaciones cuando el mensaje se envía usando un número reducido de tramas de gran tamaño.


Sin embargo, en la práctica las tramas tienden a ser pequeñas puesto que así:

el receptor necesita menor memoria temporal.
se reduce el riesgo de errores.
se evita la ocupación excesiva del medio por parte de una única estación transmisora.
Control de flujo mediante ventana deslizante
Con el procedimiento anterior solo puede haber en tránsito una trama a la vez. Si se permite que transiten varias tramas al mismo tiempo sobre el enlace, la eficiencia mejorará significativamente.

Veamos cómo funcionaría este procedimiento para dos estaciones, A y B, conectadas mediante un enlace full-duplex. La estación B reserva memoria temporal suficiente para almacenar 3 tramas. Por tanto, B puede aceptar 3 tramas, permitiéndosele a A enviar este mismo número de tramas sin tener que esperar ninguna confirmación. Para saber qué tramas se han confirmado, cada una de ellas se etiqueta con un número de secuencia. B confirma una trama mediante el envío de una confirmación que incluye el número de secuencia de la siguiente trama que se espera recibir. Esta confirmación informa también, implícitamente, acerca de que B está preparado para recibir las 3 tramas siguientes, comenzando por la de número especificado.



Control de errores
El control de errores hace referencia a los mecanismos necesarios para la detección y la corrección de errores que aparecen en una transmisión de tramas. Como se ha considerado hasta ahora, los datos se envían en base a una secuencia de tramas, las cuales se reciben en el mismo orden en que fueron enviadas y cada una de ellas, con carácter previo a su recepción, sufre un retardo arbitrario y posiblemente variable. Se contemplan dos tipos de errores potenciales:

Tramas perdidas: se produce cuando una trama enviada no llega al otro extremo. Así, por ejemplo, una ráfaga de ruido puede dañar una trama de manera que el receptor no se percate siquiera de su transmisión.
Tramas dañadas: ocurre cuando una trama se recibe con algunos bits erróneos (modificados durante la transmisión).
Las técnicas más usuales para el control de errores se basan en algunas o todas las siguientes aproximaciones:

Detección de errores: haciendo uso de códigos de comprobación de redundancia cíclica (CRC, Cyclic Redundancy Check).
Confirmaciones positivas: el destino devuelve una confirmación positiva por cada trama recibida con éxito, libre de errores.
Retransmisión tras la expiración de un temporizador: la fuente retransmite las tramas que no se han confirmado tras un periodo de tiempo predeterminado.
Confirmación negativa y retransmisión: el destino devuelve una confirmación negativa para aquellas tramas en las que se detecta la ocurrencia de errores. El origen retransmitirá de nuevo dichas tramas.
Estos mecanismos se denominan genéricamente solicitud de repetición automática (ARQ, Automatic Repeat reQuest); el objetivo de un esquema ARQ es convertir un enlace de datos no fiable en fiable. Hay tres variantes ARQ estandarizadas:

ARQ con parada y espera.
ARQ con vuelta atrás N.
ARQ con rechazo selectivo.
ARQ con parada y espera
Si existe un error en el envío de la trama (por que llegue dañada -CRC no coincidente- o se pierda -expire el temporizador-), se vuelve a transmitir.

ARQ con vuelta atrás N
El emisor va enviando las tramas que tiene en su ventana deslizante. Si existe un error en el envío de la trama (por que llegue dañada -CRC no coincidente- o se pierda -expire el temporizador-) se vuelve a transmitir esa trama y todas las siguientes aunque ya hayan sido enviadas previamente.

ARQ con rechazo selectivo
El emisor va enviando las tramas que tiene en su ventana deslizante. Si existe un error en el envío de una trama (por que llegue dañada o su temporizador expire), se vuelve a transmitir sólo esa trama.

Estándares
Ethernet (IEEE 802.3)
IEEE 802.3 fue el primer intento para estandarizar ethernet. Aunque hubo un campo de la cabecera que se definió de forma diferente, posteriormente ha habido ampliaciones sucesivas al estándar que cubrieron las ampliaciones de velocidad (Fast Ethernet, Gigabit Ethernet y los de 10, 40 y 100 Gigabits Ethernet), redes virtuales, hubs, conmutadores y distintos tipos de medios, tanto de fibra óptica como de cables de cobre (tanto par trenzado como coaxial).

Los estándares de este grupo no reflejan necesariamente lo que se usa en la práctica, aunque a diferencia de otros grupos este suele estar cerca de la realidad.





Nombre	Medio	Distancia máx	Estándar
Ethernet (10 Mbps)
10BASE5	Coaxial grueso	500 m	802.3 orig.
10BASE2	Coaxial fino	185 m	802.3a
10BASE-T	Par trenzado cat. 3 o 5	100 m	802.3i
FastEthernet (100 Mbps)
100BASE-TX	Par trenzado cat. 5	100 m	802.3u
100BASE-FX	MMF	400 m o 2 km	802.3u
GigabitEthernet (1000 Mbps)
1000BASE-T	Par trenzado >= cat. 5	100 m	802.3ab
1000BASE-SX	MMF 850 nm	550 m	802.3z


1000BASE-LX	MMF y SMF 1310 nm	10 km
1000BASE-EX	SMF 1310 nm	40 km
1000BASE-ZX	SMF 1550 nm	80 km
10 GigabitEthernet (10 Gbps)
10GBASE-T	Par trenzado >= cat 6	100 m	802.3an
10GBASE-SR	MMF	400 m	802.3ae
10GBASE-LR	SMF	10 Km
40 GigabitEthernet (40 Gbps)
40GBASE-SR4	MMF	125 m	802.3ea
40GBASE-LR4	SMF	10 km
100 GigabitEthernet (100 Gbps)
100GBASE-SR10	MMF	125 m	802.3ea
100GBASE-LR4	SMF	10 km



Siglas:

MMF: Fibra multimodo (Multi Mode Fiber)

SMF: Fibra monomodo (Single Mode Fiber)

SR: Corto alcance (Short Range)

LR: Largo alcance (Long Range)

PoE (Power over Ethernet)
La alimentación a través de Ethernet (Power over Ethernet, PoE) es una tecnología que incorpora alimentación eléctrica a una infraestructura LAN estándar. Permite que la alimentación eléctrica se suministre a un dispositivo de red (switch, punto de acceso, router, teléfono o cámara IP, etc) usando el mismo cable que se utiliza para la conexión de red. Elimina la necesidad de utilizar tomas de corriente en las ubicaciones del dispositivo alimentado y permite una aplicación más sencilla de los sistemas de alimentación ininterrumpida (SAI) para garantizar un funcionamiento las 24 horas del día, 7 días a la semana.

Power over Ethernet se regula en la norma IEEE 802.3af, y está diseñado de manera que no haga disminuir el rendimiento de comunicación de los datos en la red o reducir el alcance de la red. La corriente suministrada a través de la infraestructura LAN se activa de forma automática cuando se identifica un terminal compatible y se bloquea ante dispositivos preexistentes que no sean compatibles. Esta característica permite a los usuarios mezclar en la red con total libertad y seguridad dispositivos preexistentes con dispositivos compatibles con PoE.

Actualmente existen en el mercado varios dispositivos de red como switches o hubs que soportan esta tecnología. Para implementar PoE en una red que no se dispone de dispositivos que la soporten directamente se usa una unidad base (con conectores RJ45 de entrada y de salida) con un adaptador de alimentación para recoger la electricidad y una unidad terminal (también con conectores RJ45) con un cable de alimentación para que el dispositivo final obtenga la energía necesaria para su funcionamiento.

Ventajas

PoE es una fuente de alimentación inteligente: Los dispositivos se pueden apagar o reiniciar desde un lugar remoto usando los protocolos existentes, como el Protocolo simple de administración de redes (SNMP, Simple Network Management Protocol).
PoE simplifica y abarata la creación de un suministro eléctrico altamente robusto para los sistemas: La centralización de la alimentación a través de concentradores (hubs) PoE significa que los sistemas basados en PoE se pueden enchufar al Sistema de alimentación ininterrumpida (SAI) central, que ya se emplea en la mayor parte de las redes informáticas formadas por más de uno o dos PC, y en caso de corte de electricidad, podrá seguir funcionando sin problemas.
Los dispositivos se instalan fácilmente allí donde pueda colocarse un cable LAN, y no existen las limitaciones debidas a la proximidad de una base de alimentación (dependiendo la longitud del cable se deberá utilizar una fuente de alimentación de mayor voltaje debido a la caída del mismo, a mayor longitud mayor perdida de voltaje, superando los 25 metros de cableado aproximadamente).
Un único juego de cables para conectar el dispositivo Ethernet y suministrarle alimentación, lo que simplifica la instalación y ahorra espacio.
La instalación no supone gasto de tiempo ni de dinero ya que no es necesario realizar un nuevo cableado.
PoE dificulta enormemente cortar o destrozar el cableado: Generalmente el cableado se encuentra unido a bandejas en los huecos del techo o detrás de conductos de plástico de muy difícil acceso. Cualquier corte de estos cables resultará obvio al momento para quien pase por el lugar y, por supuesto, para los usuarios de los ordenadores que serán incapaces de proseguir con su trabajo.
Desventajas

Ausencia de estándares tecnológicos para la interoperabilidad de equipos.
Para poder usar PoE, todos los dispositivos de Red (Hub/Switch, Cámaras IP, Puntos de Acceso,…) deben ser compatibles con esta norma.
El estándar original IEEE 802.3af-2003 de PoE proporciona hasta 15,4 W de potencia de CC (mínimo 44 V DC y 350 mA) para cada dispositivo. Sólo se aseguran 12,95 W en el dispositivo puesto que cierta energía se disipa en el cable.

El estandar actualizado IEEE 802.3af-2009 de PoE también conocido como PoE+ o PoE plus, proporciona hasta 25,5 W de potencia. Algunos vendedores han anunciado productos que dicen ser compatibles con el estándar 802.3af y ofrecen hasta 51 W de potencia en un solo cable utilizando los cuatro pares del cable de categoría 5.


Comparativa PoE y PoE+



Propiedad
802.3af (802.3at Tipo1)
802.3at Tipo 2
Potencia en el origen	15.40 W	34.20 W
Potencia para dispositivo final	12.95 W	25.50 W
Voltaje en el origen	44.0–57.0 V	50.0–57.0 V
Voltaje para el dispositivo final	37.0–57.0 V	42.5–57.0 V
Intensidad máxima	350 mA	600 mA
Resistencia máxima del cable	20 Ω (Categoría 3)	12.5 Ω (Categoría 5)
Punto a punto
Ubicación de PPP y TCP/IP


Aplicación
FTP
SMTP
HTTP
…
DNS
…
Transporte
TCP
UDP
Internet
IP
IPv6
Acceso a la red
PPP
PPPoE
PPPoA
Modem serie
Ethernet
ATM

Point-to-point Protocol (en español Protocolo punto a punto), también conocido por su acrónimo PPP, es un protocolo de nivel de enlace estandarizado en el documento RFC 1661. Comúnmente usado para establecer una conexión directa entre dos nodos de red. Puede proveer autentificación de conexión, cifrado de transmisión (usando ECP, RFC 1968), y compresión. PPP es usado en varios tipos de redes físicas incluyendo, cable serial, línea telefónica, line troncal, telefonía celular, especializado en enlace de radio y enlace de fibra óptica como SONET. PPP también es usado en las conexiones de acceso a internet (mercadeado como “broadband”). Los Proveedores de Servicio de Internet (ISPs) han usado PPP para que accedan a internet los usuarios de dial-up, desde que los paquetes de IP no pueden ser transmitidos via modem, sin tener un protocolo de enlace de datos. Dos derivados del PPP son:

- Point to Point Protocolo over Ethernet (PPPoE)

- Point to Point Protocol over ATM (PPPoA)

Son usados comúnmente por Provedores de Servivicio de Internet (ISPs) para establecer una Linea Suscriptora Digital (DSL) de servicios de internet para clientes. Por tanto, se trata de un protocolo asociado a la pila TCP/IP de uso en Internet.

Estructura de la trama



Delimitador
Dirección
Control
Protocolo
Datos
FCS
Delimitador
1 Byte
1 Byte	1 Byte	1 o 2 Bytes	Variable	2 o 4 Bytes	
1 Byte
01111110
11111111
00000011
01111110

La dirección 11111111 es la dirección de broadcast. Al tratarse de enlaces punto a punto no existe dirección concreta.

La secuencia de control 00000011 indica transmisión de datos sin secuencia. Se provee un servicio de enlace no orientado a conexión

PPPoE
PPPoE (Point-to-Point Protocol over Ethernet o Protocolo Punto a Punto sobre Ethernet) es un protocolo de red para la encapsulación PPP sobre una capa de Ethernet. Es utilizada mayoritariamente para proveer conexión de banda ancha mediante servicios de cablemódem y DSL. Este ofrece las ventajas del protocolo PPP como son la autenticación, cifrado, mantención y compresión. En esencia, es un protocolo, que permite implementar una capa IP sobre una conexión entre dos puertos Ethernet, pero con las características de software del protocolo PPP, por lo que es utilizado para virtualmente "marcar" a otra máquina dentro de la red Ethernet, logrando una conexión "serial" con ella, con la que se pueden transferir paquetes IP, basado en las características del protocolo PPP.

Esto permite utilizar software tradicional basado en PPP para manejar una conexión que no puede usarse en líneas seriales pero con paquetes orientados a redes locales como Ethernet para proveer una conexión clásica con autenticación para cuentas de acceso a Internet. Además, las direcciones IP en el otro lado de la conexión sólo se asignan cuando la conexión PPPoE es abierta, por lo que admite la reutilización de direcciones IP (direccionamiento dinámico).

El objetivo y funcionamiento de PPPoE es análogo al protocolo PPP sobre RTC con el que a finales de los 90 y bajo un stack tcp, se establecía un enlace ip punto a punto a través de la red telefonica conmutada (RTC), permitiendo utilizar por encima una serie de protocolos de nivel de aplicación tipo http, ftp, telnet, etc.

PPPoE fue desarrollado por UUNET, Redback y RouterWare. El protocolo está publicado en la RFC 2516.



PPPoA
PPPoA (Point-to-Point Protocol over ATM o Protocolo Punto a Punto sobre ATM), es un protocolo de red para la encapsulación PPP en capas ATM AAL5.

El protocolo PPPoA se utiliza principalmente en conexiones de banda ancha, como cable y DSL. Este ofrece las principales funciones PPP como autenticación, cifrado y compresión de datos. Actualmente tiene alguna ventaja sobre PPPoE debido a que reduce la pérdida de calidad en las transmisiones. Al igual que PPPoE, PPPoA puede usarse en los modos VC-MUX y LLC.

Este protocolo se define en la RFC 2364

Dispositivos
Dominios
Dominios de colisión
En Ethernet el medio de transmisión es compartido, entonces a medida que se aumentan nodos a un segmento será más complicado acceder al medio, dado que solo un nodo puede transmitir información a la vez. Cuando intentan acceder dos o más nodos al medio al mismo tiempo se presentan colisiones y estas a su vez generan retransmisiones.

La solución para este problema es dividir un segmento en varios dominios de colisión. Para lograr este objetivo se usan dispositivos de capa 2 como puentes y switches.

En un principio el dispositivo más popular para esta tarea era el puente. Este solo tiene dos puertos y es capaz de dividir un dominio de colisión en dos, gracias a decisiones que toma basado netamente en las direcciones MAC de los nodos de la red.

Un switch es básicamente un puente rápido multipuerto, que puede contener docenas de puertos. En vez de crear dos dominios de colisión, cada puerto crea su propio dominio de colisión. Este dispositivo crea y mantiene de forma dinámica una tabla de memoria de contenido direccionable, que contiene toda la información MAC necesaria para cada puerto.

Un dominio de colisión es una parte de la red o segmento en el cual puede haber colisiones, cada vez que ocurre una colisión todas las transmisiones en la red son detenidas por un tiempo aleatorio.



Los dispositivos que pueden segmentar la red en dominios de colisión son los de capa 2 y de capa 3, como los puentes, switches y routers.

Cuando se usan dispositivos de capa 1, lo que se esta haciendo es aumentar la cobertura de la red al permitirle extenderse. El problema es que todos los dispositivos que se anexen a ese segmento compartirán el mismo dominio de colisión, se aumentara el tráfico en la red, las colisiones y el rendimiento de la red será muy deficiente.

Segmentos
La capacidad para reconocer dominios de colisión es muy importante. Los dispositivos de capa 1 usados en una red generan un solo dominio de colisión. Los dispositivos de capa 2 (puentes y switches) son capaces de hacer un seguimiento de la dirección MAC de cada nodo y reconocer en que segmento de la red se encuentra, es decir que son capaces de controlar el flujo de tráfico al nivel de capa 2.

Al usar puentes y switches el dominio de colisión se divide en partes más pequeñas y a su vez cada parte se convierte en un domino de colisión independiente. Al encontrar menos host en un dominio de colisión es más probable que el medio este disponible para poder transmitir.

En el mundo de las redes de datos el término segmento se emplea en numerosas ocasiones. En el ámbito de las topologías físicas de una red se entiende segmento como la sección de una red limitada por puentes, routers o switches.



Difusión (Broadcast) de capa 2
En ocasiones los hosts de la red se ven en situaciones en las cuales necesitan la dirección MAC de otro nodo para acceder a alguna información requerida, pero en la tabla ARP del host no se encuentra dicha dirección. Entonces se envía una petición ARP que es en forma de broadcast.

El broadcast se usa para lograr llegar a todos los dominios de colisión. El broadcast de capa 2 se envía con una dirección MAC de la siguiente forma: 0xFFFFFFFFFFFF y todas las tarjetas de red deben responder a este llamado.

Dominios de difusión (Broadcast)
Un dominio de broadcast es un conjunto de dominios de colisión que se encuentran integrados por uno o más dispositivos de capa 2.

Cuando aumentan los dominios de colisión cada host puede acceder al medio de mejor manera, pero estos se pueden ver sobrepasados por la difusión de broadcast, estos deben ser controlados mediante la adición a la red de dispositivos de capa 3, dado que no envían broadcasts.

El envío de información en la capa 3 se basa en la dirección IP destino.



Adaptadores de red
Una tarjeta de red o adaptador de red es un periférico que permite la comunicación con aparatos conectados entre sí y también permite compartir recursos entre dos o más computadoras. A las tarjetas de red también se les llama NIC (por network interface card; en español "tarjeta de interfaz de red"). Hay diversos tipos de adaptadores en función del tipo de cableado o arquitectura que se utilice en la red (coaxial fino, coaxial grueso, Token Ring, etc.), pero actualmente el más común es del tipo Ethernet utilizando una interfaz o conector RJ-45.



Puentes
Un puente de red o bridge es un dispositivo de interconexión de redes de ordenadores que opera en la capa 2 (nivel de enlace de datos) del modelo OSI. Este interconecta segmentos de red (o divide una red en segmentos) haciendo la transferencia de datos de una red hacia otra con base en la dirección física de destino de cada paquete. En definitiva, un bridge conecta segmentos de red formando una sola subred (permite conexión entre equipos sin necesidad de routers). Funciona a través de una tabla de direcciones MAC detectadas en cada segmento al que está conectado. Cuando detecta que un nodo de uno de los segmentos está intentando transmitir datos a un nodo del otro, el bridge copia la trama para la otra subred, teniendo la capacidad de desechar la trama (filtrado) en caso de no tener dicha subred como destino. Para conocer por dónde enviar cada trama que le llega (encaminamiento) incluye un mecanismo de aprendizaje automático (autoaprendizaje) por lo que no necesitan configuración manual.



Switches
Un conmutador o switch es un dispositivo digital lógico de interconexión de redes de computadoras que opera en la capa de enlace de datos del modelo OSI. Su función es interconectar dos o más segmentos de red, de manera similar a los puentes de red, pasando datos de un segmento a otro de acuerdo con la dirección MAC de destino de las tramas en la red.

Un conmutador en el centro de una red en estrella.

Los conmutadores se utilizan cuando se desea conectar múltiples redes, fusionándolas en una sola. Al igual que los puentes, dado que funcionan como un filtro en la red, mejoran el rendimiento y la seguridad de las redes de área local.

Tipos:

compacto
de configuración modular
apilable
multicapa (multilayer)
gestionable
Switch compacto
Estos switches de configuración fija son los que más comúnmente estamos acostumbrados a ver en las redes locales y cibercafés, en las cuales los switches sólo soportan una tecnología y cuyas características no podemos cambiar, es decir, si compramos un switch de 24 puertos FastEthernet no podremos agregarle mas puertos.



Para unir 2 switches en cascada existen dos posibilidades:

Uplink
MDI/MDIX (Auto Cross)
Antiguamente se usaban puertos UPLINK para unir dos hubs o dos switches, usándose cables cruzados para ello. Por ejemplo, en un switch de 6 puertos, el puerto 6 solía ser uplink.

La forma de conexión se muestra a continuación:



Los switches más avanzados soportan MDIX, lo cual permite utilizar un cable directo para conectar 2 switches entre sí utilizando cualquier puerto. El propio switch detecta el tipo de conexión (Auto Cross), que es equivalente a usar un cable crossover (568A ↔ 568B).

Los puertos estándar para las estaciones terminales se conocen como MDI (Media Dependent Interface ), y los puertos estándar para los concentradores y conmutadores se conoce como MDIX (Media Dependent Interface Crossover) .

En los concentradores (hubs) y conmutadores (switches) las interfaces MDI se usan para conectar a otros hubs o switches sin el cable de red cruzado (que sería lo habitual) y se conocen como puertos MDI o puertos uplink. Estas interfaces son especiales y normalmente pueden ser configuradas manualmente o por software para que se comporten como MDI o MDIX. Existen interfaces que cambian su estado de MDI a MDIX automáticamente.



Switch de configuración modular
Estos switches están diseñados con ranuras que permiten insertar tarjetas en linea que le proporcionan nuevas funcionalidades, de tal forma que es posible agregar mas puertos Fast Ethernet, Modems o puertos de conexión Gigabit Ethernet, claro está que el switch en cuestión solo soporta un número y modelos determinados de tarjetas.



Enlace - Módulos Switch (1)

Enlace - Módulos Switch (2)


Transceptores SFP

Un transceptor es un dispositivo que cuenta con un transmisor y un receptor que comparten parte de la circuitería o se encuentran dentro de la misma caja.


El módulo de factor de forma pequeño (SFP: Small Form-factor Pluggable) es un transceptor (en inglés transceiver) modular óptico de intercambio dinámico para conectar dos equipos de telecomunicaciones, normalmente switches o routers...

Enlace - Transceptores SFP (1)

Enlace - Transceptores SFP (2)


Los módulos SFP fueron desarrollados para velocidades de 1 Gbit/s. No todos son ópticos (los hay de cobre) y los hay de muchos más tipos que 1000BaseSX ó 1000BaseLX (como por ejemplo, hay SFP de 1000BaseT, 1000BaseZX, SONET/SDH).


El transceptor SFP no ha sido estandarizado por ningún organismo de normalización oficial, sino que se especifica mediante un acuerdo multi-fuente entre fabricantes competidores. SFP fue diseñado después de la interfaz GBIC, y permite una mayor densidad de puertos (número de transceptores por cm a lo largo del borde de una placa) que el GBIC, que es la razón por la SFP también se conoce como mini-GBIC.

La versión mejorada de Small Form Factor Pluggable (SFP+) admite velocidades de datos de hasta 10 Gbit/s. La especificación SFP+ se publicó el 9 de mayo de 2006, y la versión 4.1 fue publicada el 6 de julio de 2009. SFP+ soporta 10 Gigabit Ethernet y 8 Gbit/s en redes Fibre Channel (usadas comúnmente en redes Storage Area Networks (SAN)). Es un formato popular de la industria con el apoyo de muchos fabricantes de componentes de red.


Transceptores CFP




El módulo de factor de forma C (CFP: C Form-factor Pluggable) es un transceptor para la transmisión de señales digitales de alta velocidad. La C indica la letra latina C para expresar el número 100 (centum), ya que el estándar fue desarrollado principalmente para sistemas Ethernet 100 Gigabit.

El transceptor CFP se especifica mediante un acuerdo multi-fuente entre fabricantes competidores. El CFP fue diseñado posteriormente a la interface SFP, pero es significativamente más rápido para soportar 40 y 100 Gbit/s.



Switch apilable
A esta configuración de switch se les conoce como en stack o stackwise. Se trata de conectar con cables de alta velocidad varios switches, el objetivo es obtener tolerancia a fallos, ofreciendo una configuración redundante.



Un grupo de switches (stack) puede apilarse (uniéndolos con enlaces de alta velocidad) y comportarse como un único switch con la capacidad de puertos de la suma de todos ellos. Por ejemplo 12 swiches de 48 puertos cada uno, equivalen a un switch de 576 puertos.

Los enlaces que unen los switch del stack pueden alcanzar los 20 Gbps.

Enlace - Switch apilable (Maestro y Backup)

Dentro de la pila (stack) existe un switch maestro y otro de respaldo (backup). El switch Master y el Backup se sincronizan constantemente para tener la misma configuración Si el Master falla, el Backup se convierte en el nuevo Master y otro switch del stack toma el rol de Backup.



Switch multicapa (multilayer)
Son los conmutadores que, además de las funciones tradicionales de la capa 2, incorporan algunas funciones de enrutamiento o routing, como por ejemplo la determinación del camino basado en informaciones de capa de red (capa 3 del modelo OSI), validación de la integridad del cableado de la capa 3 por checksum y soporte a los protocolos de routing tradicionales (RIP, OSPF, etc)

Los conmutadores de capa 3 (Layer 3) soportan también la definición de redes virtuales (VLAN), y según modelos posibilitan la comunicación entre las diversas VLAN sin la necesidad de utilizar un router externo.

Por permitir la unión de segmentos de diferentes dominios de difusión o broadcast, los switches de capa 3 son particularmente recomendados para la segmentación de redes LAN muy grandes, donde la simple utilización de switches de capa 2 provocaría una pérdida de rendimiento y eficiencia de la LAN, debido a la cantidad excesiva de broadcasts.

Se puede afirmar que la implementación típica de un switch de capa 3 es más escalable que un enrutador, pues éste último utiliza las técnicas de enrutamiento a nivel 3 y enrutamiento a nivel 2 como complementos, mientras que los switches sobreponen la función de enrutamiento encima del encaminamiento, aplicando el primero donde sea necesario.

Asimismo existen en el mercado algunos switches denominados Layer 3+ (Layer 3 Plus). Básicamente, incorporan a las funcionalidades de un conmutador de la capa 3; la habilidad de implementar la políticas y filtros a partir de informaciones de la capa 4 o superiores, como puertos TCP/UDP, SNMP, FTP, etc.

El icono utilizado para un switch multicapa es el siguiente:





Switch gestionable
Los switches multicapa (L3 o superiores) soportan la administración a través de red. Se accede a ellos a través de una dirección IP mediante servicios telnet, ssh o incluso web. Permiten la administración de diversos parámetros como pueden ser la creación y gestión de VLANs, el soporte de STP o RSTP, agregación de puertos (trunk), etc.



Distribución
Ciertos fabricantes utilizan un diseño de red jerárquica consistente en dividir la red en capas discretas. Cada capa proporciona funciones específicas que definen su papel dentro de la red global. Mediante la separación de las diversas funciones que existen en una red, el diseño de la red se convierte en modular, lo que facilita la escalabilidad y el rendimiento.


El modelo de diseño jerárquico típico se divide en tres capas:

núcleo (CORE)
distribución (DISTRIBUTION)
acceso (ACCESS)




Cableado entre dispositivos
Cable Recto (Straight Through):

Es el cable cuyas puntas están armadas con las misma norma (T568A ↔ T568A ó T568B ↔ T568B). Se utiliza entre dispositivos que funcionan en distintas capas del Modelo de Referencia OSI.

De PC a Switch/Hub.
De Switch a Router.
Cable Cruzado (Crossover):

Es el cable cuyas puntas están armadas con distinta norma (T568A ↔ T568B). Se utiliza entre dispositivos que funcionan en la misma capa del Modelo de Referencia OSI.

De PC a PC.
De Switch/Hub a Switch/Hub.
De Router a Router (el cable serial se considera cruzado).




Otras características de los switches
Puertos
Cada una de las entradas al switch se denomina puerto. Normalmente los puertos son para conectores RJ-45, aunque algunos pueden ser para conectores SC o LC de fibra óptica.

La disposición y función de los puertos varían entre distintos modelos de switch, aunque por los general suelen tener la siguiente:



1. Console port (No siempre se encuentra disponible)

2. Puertos normales (10/100/1000 Mbps) para conexión de equipos.

3. Otros puertos (para UPLINK, TRUNK o incluso entrada de PoE)


Ejemplo

]


El puerto de consola (console port)

Algunos switches (además de los routers) disponen de un puerto especial, denominado Console Port. Este puerto es muy importante pues permite realizar la configuración del dispositivo a través de él de forma directa. Es necesario un cable rollover.






El cable Rollover (también conocido como cable de consola Cisco o cable Yost) es un tipo de cable de módem nulo que se utiliza a menudo para conectar un terminal de ordenador al puerto de consola del switch o router. Este cable es generalmente plano (y tiene un color azul claro) para ayudar a distinguirlo de otros tipos de cableado de red.


Se pone el nombre de rollover debido a las patillas en un extremo se invierten de el otro.








En el caso de que nuestro ordenador no disponga de puerto serie DB-9 y solo disponga de USB necesitaremos además un adaptador USB a DB-9.




Para acceder a la configuración del switch o router a través de un puerto de consola haremos uso de los siguientes programas:

Hyperterminal (en Windows)
minicom (en Linux)
Modos de conmutación.
Existen básicamente dos formas mediante las cuales es conmutada la información hasta el destino:

método de corte (Cut-Through)
almacenamiento y envío (Store-and-Forward)
El método de corte es el de menor latencia pero con mayor cantidad de errores, consiste en comenzar a transmitir la trama tan pronto como se conoce la dirección MAC de destino, para poder usar este modo, tanto el origen como el destino deben operar a la misma velocidad (de forma síncrona), para no dañar la trama. El problema de este tipo de switch es que no detecta tramas corruptas causadas por colisiones (conocidos como runts), ni errores de CRC. Cuanto mayor sea el número de colisiones en la red, mayor será el ancho de banda que consume al encaminar tramas corruptas.

Una mejora de este modo es el método conocido como libre de fragmentos, cuando se reciben los primeros 64 bytes que incluyen el encabezado de la trama es cuando inicia la conmutación, este modo verifica la confiabilidad de direccionamiento y la información del protocolo de control de enlace lógico (Logical Link Control, LLC) para asegurar que el destino y manejo de los datos sean correctos.

El último de los métodos es el de almacenamiento y envío, el switch recibe toda la trama antes de iniciar a enviarla, esto le da al switch la posibilidad de verificar la secuencia de verificación de trama (FCS), para asegurarse de que la trama ha sido recibida de forma confiable y enviarla al destino. Este método asegura operaciones sin error y aumenta la confianza de la red. Pero el tiempo utilizado para guardar y chequear cada trama añade un tiempo de demora importante al procesamiento de las mismas. La demora o delay total es proporcional al tamaño de las tramas: cuanto mayor es la trama, más tiempo toma este proceso.

Los conmutadores cut-through son más utilizados en pequeños grupos de trabajo y pequeños departamentos. En esas aplicaciones es necesario un buen volumen de trabajo o throughput, ya que los errores potenciales de red quedan en el nivel del segmento, sin impactar la red corporativa.

Los conmutadores store-and-forward son utilizados en redes corporativas, donde es necesario un control de errores.



Port security
Es una característica de los switches Cisco que nos permite retener las direcciones MAC conectadas a un puerto y permitir solamente esas direcciones MAC registradas comunicarse a través de ese puerto del switch.

Nos permite:

Restringir el acceso a los puertos del switch según la MAC.
Restringir el número de MACs por puerto en el switch.
Reaccionar de diferentes maneras a violaciones de las restricciones anteriores.
Establecer la duración de las asociaciones MAC-Puerto.
Si un dispositivo con otra dirección MAC intenta comunicarse a través de un puerto de la LAN, port-security deshabilitará el puerto.



Port mirroring (Puerto espejo)
Es una función que tienen los switches para copiar todo el tráfico de un puerto específico a otro puerto. Esta función generalmente se utiliza para atrapar todo el tráfico de una red y poder analizarlo (con herramientas como wireshark por ejemplo).

El puerto espejo en un sistema de switch Cisco generalmente se refiere a un Analizador de Puertos del switch (Switched Port Analyzer; SPAN) algunas otras marcas usan otros nombres para esto, tal como Roving Analysis Port (RAP) en los switches 3Com.



MACsec
Media Access Control de Seguridad (MACsec) es una tecnología de seguridad estándar de la industria que proporciona una comunicación segura para todo el tráfico en enlaces Ethernet. MACsec proporciona seguridad de punto a punto de enlaces Ethernet entre nodos conectados directamente-y es capaz de identificar y prevenir la mayoría de las amenazas a la seguridad, incluida la denegación de servicio, intrusión, man-in-the-middle, enmascaramiento, las escuchas telefónicas pasivo, y los ataques de reproducción. MACsec está estandarizado en IEEE 802.1AE.


Una vez que un enlace punto a punto Ethernet ha habilitado MACsec, todo el tráfico que atraviesa el enlace es asegurado mediante el uso de controles de integridad de datos y cifrado si se desea.

Las comprobaciones de integridad de datos verifican la integridad de los datos en ambos lados del enlace asegurado Ethernet. MACsec añade una cabecera de 8 bytes y una cola de 16 bytes a todas las tramas Ethernet que atraviesan el enlace, y la cabecera y la cola son revisados por la interfaz de recepción para asegurar que los datos no se vieron comprometidos al atravesar el enlace. Si la comprobación de integridad de datos detecta algo irregular sobre el tráfico , el tráfico se desecha.

MACsec también se puede utilizar para cifrar todo el tráfico en el enlace Ethernet. El cifrado utilizado por MACsec asegura que los datos de la trama Ethernet no pueden ser vistos por cualquier persona al monitorear el tráfico en el enlace. El cifrado MACsec es opcional y configurable por el usuario.



STP
STP (Spanning Tree Protocol) o protocolo de árbol de extensión es un protocolo basado en estándares que se usa para evitar bucles de switcheo. Cuando se comprobó la eficiencia de los switches para realizar la conmutación en grandes redes, se inicio su incorporación de manera copiosa hasta el punto de crear redes con switches anidados, formando una estructura de árbol jerárquico plagado de rutas redundantes que son recomendadas para ofrecer más confiabilidad y tolerancia a las fallos, pero que pueden generar efectos indeseables como los bucles y pueden llegar a convertirse en tormentas de broadcast que rápidamente abrumen la red.

Los bucles ocurren cuando hay rutas alternativas hacia un mismo destino (sea una máquina o segmento de red). Estas rutas alternativas son necesarias para proporcionar redundancia y así ofrecer una mayor fiabilidad a la red, dado que en caso de que un enlace falle, los otros puede seguir soportando el tráfico de ésta. Los problemas aparecen cuando utilizamos dispositivos de interconexión de nivel de enlace, como un puente de red o un conmutador de paquetes.




Cuando existen bucles en la topología de red, los dispositivos de interconexión de nivel de enlace de datos reenvían indefinidamente las tramas broadcast y multicast, creando así un bucle infinito que consume tanto el ancho de banda de la red como CPU de los dispositivos de enrutamiento. Esto provoca que se degrade el rendimiento de la red en muy poco tiempo, pudiendo incluso llegar a quedar inutilizable. Al no existir un campo TTL (tiempo de vida) en las tramas de capa 2, éstas se quedan atrapadas indefinidamente hasta que un administrador de sistemas rompa el bucle. Un router, por el contrario, sí podría evitar este tipo de reenvíos indefinidos. La solución consiste en permitir la existencia de enlaces físicos redundantes, pero creando una topología lógica libre de bucles. STP calcula una única ruta libre de bucles entre los dispositivos de la red pero manteniendo los enlaces redundantes desactivados como reserva, con el fin de activarlos en caso de fallo.

Si la configuración de STP cambia, o si un segmento en la red redundante llega a ser inalcanzable, el algoritmo reconfigura los enlaces y restablece la conectividad, activando uno de los enlaces de reserva. Si el protocolo falla, es posible que ambas conexiones estén activas simultáneamente, lo que podrían dar lugar a un bucle de tráfico infinito en la LAN.

El árbol de expansión (Spanning tree) permanece vigente hasta que ocurre un cambio en la topología, situación que el protocolo es capaz de detectar de forma automática. El máximo tiempo de duración del árbol de expansión es de cinco minutos. Cuando ocurre uno de estos cambios, el puente raíz actual redefine la topología del árbol de expansión o se elige un nuevo puente raíz.

El algoritmo transforma una red física con forma de malla, en la que existen bucles, por una red lógica en forma de árbol (libre de bucles). Los puentes se comunican mediante mensajes de configuración llamados Bridge Protocol Data Units (BPDU).




STP actúa contra los bucles, haciendo que cada switch que opera con este protocolo envíe un mensaje denominado BPDU desde cada uno de sus puertos para que los demás sepan de su existencia. Luego con la ayuda del STA (Spanning Tree Algorithm), se detectan cuales son las rutas redundantes y son bloqueadas.

El resultado es la eliminación de los bucles mediante la creación de un árbol jerárquico, pero en caso de ser necesitadas la rutas alternativas pueden ser activadas.

Existen múltiples variantes del STP debido, principalmente, al tiempo que tarda en converger el algoritmo utilizado. Una de estas variantes es el Rapid Spanning Tree Protocol (RSTP), que hoy en día ha reemplazado el uso del STP original.

Como extensión de RSTP, además tenemos Multiple Spanning Tree Protocol (MSTP), que tiene características más novedosas.



CDP
CDP (Cisco Discovery Protocol, ‘protocolo de descubrimiento de Cisco’, es un protocolo de red propietario de nivel 2, desarrollado por Cisco Systems y usado en la mayoría de sus equipos. Es utilizado para compartir información sobre otros equipos Cisco directamente conectados, tal como la versión del sistema operativo y la dirección IP. CDP también puede ser usado para realizar encaminamiento bajo demanda (ODR, On-Demand Routing), que es un método para incluir información de encaminamiento en anuncios CDP, de forma que los protocolos de encaminamiento dinámico no necesiten ser usados en redes simples.

Los dispositivos Cisco envían anuncios a la dirección de destino de multidifusión. Los anuncios CDP (si está soportados y configurados en el IOS) se envían por defecto cada 60 segundos en las interfaces que soportan cabeceras SNAP, incluyendo Ethernet, Frame Relay y ATM. Cada dispositivo Cisco que soporta CDP almacena la información recibida de otros dispositivos en una tabla que puede consultarse usando el comando show cdp neighbor. La información de la tabla CDP se refresca cada vez que se recibe un anuncio y la información de un dispositivo se descarta tras tres anuncios no recibidos por su parte (tras 180 segundos usando el intervalo de anuncio por defecto).

La información contenida en los anuncios CDP varía con el tipo de dispositivo y la versión del sistema operativo que corra. Dicha información incluye la versión del sistema operativo, el nombre de equipo, todas la direcciones de todos los protocolos configurados en el puerto al que se envía la trama CDP (por ejemplo, la dirección IP), el identificador del puerto desde el que se envía el anuncio, el tipo y modelo de dispositivo, la configuración duplex/simplex, el dominio VTP, la VLAN nativa, el consumo energético (para dispositivos PoE) y demás información específica del dispositivo. El protocolo está habilitado por defecto en todos las interfaces de los equipos CISCO. Para deshabilitarlo de forma global se utiliza el comando no cdp run en modo enable y para deshabilitarlo en una interfaz concreta se utiliza el comando no cdp enable en la configuración de dicha interfaz.



Port trunking (link aggregation)
Permite combinar varios enlaces físicos en un enlace lógico (trunk), que funciona como un único puerto de mayor ancho de banda

Características:

Aumenta el ancho de banda entre 2 switches
Implica redundancia, lo que mejora la fiabilidad
Es una solución escalable
Puede usarse para aumentar el ancho de banda entre un switch y un equipo de la red
Cisco denomina esta técnica como EtherChannel.

EtherChannel nos permite sumar la velocidad de cada puerto físico y así obtener un único enlace troncal de alta velocidad.

Cuando tenemos muchos servidores que salen por un único enlace troncal, puede que el tráfico colapse el enlace. Una de las soluciones más prácticas es el uso de EtherChannel.

De esta manera sumamos la velocidad de los puertos que agregamos al enlace lógico.




Modos de configuración

Podemos configurar un EtherChannel de 3 formas diferentes:

Mode ON: no se realiza ningún tipo de negociación, todos los puertos se ponen activos. No utiliza ningún protocolo.
PAgP (Port Aggregation Protocol): es un protocolo propietario de Cisco. El switch negocia con el otro extremo qué puertos deben ponerse activos.
LACP (Link Aggregation Control Protocol): protocolo abierto con estándar IEEE 802.3ad y 802.3ax.




On (sin protocolo)
Etherchannel - ON

PAgP: Desirable /Auto
Etherchannel - PAgP

LACP : Active/Passive
Etherchannel - LACP





Recomendaciones

Antes de configurar nuestro EtherChannel tener en cuenta las siguientes recomendaciones:

No se debe configurar un puerto en dos grupos diferentes.
No se debe configurar un puerto en dos modos diferentes, LACP y PAgP.
No configurar Switched Port Analyzer (SPAN) como parte de un EtherChannel.
No configurar securización de puertos.
Asignar todos los puertos del EtherChannel a la misma VLAN o configurar todos como troncales.
Verificar que todos los puertos del grupo están en un mismo odo de encapsulación, ISL o 802.1Q
VLAN
Algunos switches L3 (de capa 3) soportan la creación de LAN virtuales o VLAN.

Una VLAN (acrónimo de virtual LAN, «red de área local virtual») es un método para crear redes lógicas independientes dentro de una misma red física. Varias VLANs pueden coexistir en un único conmutador físico o en una única red física. Son útiles para reducir el tamaño del dominio de difusión y ayudan en la administración de la red, separando segmentos lógicos de una red de área local (como departamentos de una empresa) que no deberían intercambiar datos usando la red local (aunque podrían hacerlo a través de un enrutador o un conmutador de capa 3 y 4).

Actividades
Explica cuáles son las principales funciones de la capa de enlace.
En redes Ethernet la capa de enlace se dividen en dos subcapas, ¿cuáles? Explica cada una de ellas brevemente.
Haz un esquema de una trama 802.3 y explica las diferencias con la trama Ethernet original.
Busca información acerca del protocolo HDLC. ¿Qué significan las siglas? ¿Qué protocolos se basan en él? ¿Cuál es el formato de una trama HDLC?
Haz una comparativa entre una trama HDLC y una trama PPP.
Calcula el CRC para el siguiente caso:
Información a transmitir: 111101001101
Polinomio generador: 10101
Busca información acerca del polinomio generador utilizado en Ethernet para generar el CRC-32.
Busca información acerca del significado de las siglas MTU. ¿Cuál es la MTU para Ethernet?
En medios compartidos con división estática del canal, indicar las 4 técnicas utilizadas y donde se emplea cada una de ellas.
En medios compartidos con división dinámica del canal, indicar las 2 técnicas estudiadas y donde se emplea cada una de ellas.
Explica la técnica CSMA/CD.
Explica la técnica Token Ring (paso de testigo)
Explica la técnica de control de flujo mediante ventana deslizante.
Explica la técnica de control de errores ARQ de vuelta atrás N.
Explica qué son y para qué sirven las tecnologías PoE y PoE+.
Para las siguientes versiones Ethernet nombra un estándar que haga uso de cable de par trenzado, indicando nombre, tipo de cable, distancia y norma.
Ethernet 10 Mbps
Ethernet 100 Mbps (FastEthernet)
Ethernet 1000 Mbps (Gigabit Ethernet)
Ethernet 10000 Mbps (10 Gigabit Ethernet)
Para las siguientes versiones Ethernet nombra un estándar que haga uso de cable de fibra óptica multimodo, indicando nombre, distancia y norma.
Ethernet 1 Gbps (Gigabit Ethernet)
Ethernet 10 Gbps (10 Gigabit Ethernet)
Ethernet 40 Gbps (40 Gigabit Ethernet)
Ethernet 100 Gbps (100 Gigabit Ethernet)
¿Qué se entiende por dominio de colisión y dominio de difusión?
¿Para qué sirven los puertos UPLINK de un switch?
Si un switch tiene soporte MDIX en sus puertos, significa que …
Haz un esquema del cableado de par trenzado y su distribución de hilos en:
cable directo (straight)
cable cruzado (crossover)
cable invertido (rollover)
Para los siguientes tipos de switches y fabricantes busca un modelo:
<td style="border-top:none;border-bottom:0.05pt solid #000000;border-left:0.05pt solid #000000;border-right:none;padding:0.097cm;"<td style="border-top:none;border-bottom:0.05pt solid #000000;border-left:0.05pt solid #000000;border-right:none;padding:0.097cm;"
Fabricantes
Tipos	Cisco	3com	Linksys	D-Link.
Compacto			
Modular			
Apilable				
Multicapa				
Para los modelos anteriores mostrar un imagen y especificaciones técnicas.
¿Qué son y para qué sirven los transceptores (transceiver en inglés)?
¿Qué velocidades se alcanzan con los transceptores SFP y CFP?
Símbolo del switch multicapa.
¿Qué tipos de cables de par trenzado se utilizan para conectar los siguientes dispositivos entre si?
Computador	Switch	Router
Computador			
Switch			
Router			
Explica qué es y para qué sirve STP y RSTP.
Explica qué es y para qué sirve la agregación de enlaces.
Para la planificación de la red local que se realizó en el Tema 4, buscar los switches adecuados suponiendo que tenemos 2 switch de distribución (en el distribuidor de cada edificio) y múltiples switch de planta. La conexión entre los switch de distribución y los de planta se realiza por fibra óptica.
Imagina que te dan un switch y te piden que lo configures. Indica los pasos que debes seguir para tener acceso a él.
Visita la página http://www.tp-link.com/en/emulators.html y elige 3 switches. Para cada uno de ellos indica que características soporta de las vistas este tema.
Bibliografía y referencias
Comunicaciones y Redes de Computadores – W. Stallings - 7a edición
Redes de Computadoras - Andrew S. Tanenbaum – 4a edición.
Implementing Cisco Switched Networks. 2009.
Acceso al medio (PDF)
Documentación sobre EtherChannel, Port Mirroring, Port Security y otros
Ethernet
Tema 7



Tema 7: Redes inalámbricas.
Conceptos generales
Estándares
Dispositivos
Actividades
Bibliografía y referencias
Conceptos generales
Tecnologías inalámbricas
Las redes inalámbricas hacen uso de un medio sin cables para la transmisión de la información mediante ondas electromagnéticas. Actualmente su uso está ampliamente extendido debido al soporte tecnológico existente y a la movilidad que proporcionan. Se emplean diversas tecnologías según el ámbito en el que operan.

Redes Personales: WPAN (Wireless PAN)
Redes Locales: WLAN (Wireless LAN)
Redes Metropolitanas: WMAN (Wireless MAN)
Redes Amplias: WWAN (Wireless WAN)
Topología celular o en celdas
Las redes de telefonía móvil y otras redes inalámbricas similares están constituidas por un conjunto de estaciones cada una de las cuales tiene un área de cobertura. De esta forma, el territorio se divide en celdas, en teoría, de forma hexagonal, controladas cada una por una estación terrestre, que soportan un número limitado de llamadas. Cuando un usuario se encuentra en determinada célula, será atendido por su estación correspondiente. Pero si al desplazarse pasa a otra célula, entonces será otra estación la que le permita seguir manteniendo la conversación.

En las zonas limítrofes, las células se solapan, de forma que el usuario no pierda la cobertura cuando pasa de una a otra. Cada estación utiliza un rango de frecuencias específico y diferente del de las células que la rodean, que son adyacentes a ella, pues en caso contrario podrían producirse interferencias entre células. Células no adyacentes si pueden usar el mismo rango de frecuencias. El conjunto de todas las celdas de una red forman la zona de cobertura.


Celdas simplificadas



Celdas reales vs simplificadas


Tipos de celdas según su extensión
Pequeñas celdas
Femtocelda(Interior - Indoor)
Picocelda (Exterior - Outdoor)
Microcelda (Exterior - Outdoor)
Macroceldas
Estándares
A continuación se muestra un gráfico de tipos de redes inalámbricas atendiendo a su distancia y velocidades.

Tecnologías inalámbricas - Comparativa







WPAN: Bluetooth

Logo Bluetooth
Bluetooth es una especificación industrial para Redes Inalámbricas de Área Personal (WPAN) que posibilita la transmisión de voz y datos entre diferentes dispositivos mediante un enlace por radiofrecuencia en la banda ISM de los 2,4 GHz. Los principales objetivos que se pretenden conseguir con esta norma son:

Facilitar las comunicaciones entre equipos móviles.
Eliminar los cables y conectores entre éstos.
Ofrecer la posibilidad de crear pequeñas redes inalámbricas y facilitar la sincronización de datos entre equipos personales.
Los dispositivos que con mayor frecuencia utilizan esta tecnología pertenecen a sectores de las telecomunicaciones y la informática personal, como PDA, teléfonos móviles, computadoras portátiles, ordenadores personales, impresoras o cámaras digitales.

Estos dispositivos se clasifican como "Clase 1", "Clase 2" o "Clase 3" en referencia a su potencia de transmisión. A mayor potencia mayor distancia.



Clase
Potencia máxima permitida (mW)
Potencia máxima permitida (dBm)
Alcance(aproximado)
Clase 1
100 mW
20 dBm
~30 metros
Clase 2
2.5 mW
4 dBm
~10-5 metros
Clase 3
1 mW
0 dBm
~1 metro
En la mayoría de los casos, la cobertura efectiva de un dispositivo de clase 2 se extiende cuando se conecta a un transceptor de clase 1. Esto es así gracias a la mayor sensibilidad y potencia de transmisión del dispositivo de clase 1, es decir, la mayor potencia de transmisión del dispositivo de clase 1 permite que la señal llegue con energía suficiente hasta el de clase 2. Por otra parte la mayor sensibilidad del dispositivo de clase 1 permite recibir la señal del otro pese a ser más débil.


Los dispositivos con Bluetooth también pueden clasificarse según su ancho de banda:



Versión
Ancho de banda
Versión 1.2	
1 Mbit/s
Versión 2.0 + EDR	
3 Mbit/s
Versión 3.0 + HS	
24 Mbit/s
Versión 4.0	
24 Mbit/s
Las prestaciones fueron publicadas por el Bluetooth Special Interest Group (SIG). El SIG las anunció formalmente el 20 de mayo de 1998. Hoy cuenta con una membresía de más de 14.000 empresas en todo el mundo. Fue creado por Ericsson, IBM, Intel, Toshiba y Nokia, y posteriormente se sumaron muchas otras compañías. Todas las versiones de los estándares de Bluetooth están diseñadas para la compatibilidad hacia abajo, que permite que el último estándar cubra todas las versiones anteriores.

Versiones
Bluetooth v1.0 y v1.0b

Las versiones 1.0 y 1.0b han tenido muchos problemas, y los fabricantes tenían dificultades para hacer sus productos interoperables. Las versiones 1.0 y 1.0b incluyen en hardware de forma obligatoria la dirección del dispositivo Bluetooth (BD_ADDR) en la transmisión (el anonimato se hace imposible a nivel de protocolo), lo que fue un gran revés para algunos servicios previstos para su uso en entornos Bluetooth.

Bluetooth v1.1 (2002)

Ratificado como estándar IEEE 802.15.1-2002
Se corrigieron muchos errores en las especificaciones 1.0b.
Añadido soporte para canales no cifrados.
Indicador de señal recibida (RSSI).
Bluetooth v1.2 (2003)

Las principales mejoras son las siguientes:

Una conexión más rápida y Discovery (detección de otros dispositivos bluetooth).
Salto de frecuencia adaptable de espectro ampliado (AFH), que mejora la resistencia a las interferencias de radio frecuencia, evitando el uso de las frecuencias de lleno en la secuencia de saltos.
Mayor velocidad de transmisión en la práctica, de hasta 721 kbit/s, que en v1.1.
Introdujo el control de flujo y los modos de retransmisión de L2CAP.
Bluetooth v2.0 + EDR (2004)

Fue lanzado en 2004 y es compatible con la versión anterior 1.2. La principal diferencia es la introducción de una velocidad de datos mejorada (EDR "Enhanced Data Rate" "mayor velocidad de transmisión de datos") para acelerar la transferencia de datos. La tasa nominal de EDR es de 3 Mbit / s, aunque la tasa de transferencia de datos práctica es de 2,1 Mbit / s.

Bluetooth v2.1 + EDR (2007)

Bluetooth Core Version especificación 2.1 + EDR es totalmente compatible con 1.2, y fue adoptada el 26 de julio de 2007.

Bluetooth v3.0 + HS (2009)

Aprobado por el Bluetooth SIG el 21 de abril de 2009. Bluetooth 3.0 + HS soporta velocidades de transferencia de datos teórica de hasta 24 Mbits entre sí, aunque no a través del enlace Bluetooth propiamente dicho. La conexión Bluetooth nativa se utiliza para la negociación y el establecimiento mientras que el tráfico de datos de alta velocidad se realiza mediante un enlace 802.11. Su principal novedad es AMP (Alternate MAC / PHY), la adición de 802.11 como transporte de alta velocidad. Estaban inicialmente previstas dos tecnologías para incorporar en AMP: 802.11 y UWB, pero finalmente UWB no se encuentra en la especificación.

La incorporación de la transmisión a alta velocidad no es obligatoria en la especificación y por lo tanto, los dispositivos marcados con "+ HS" incorporan el enlace 802.11 de alta velocidad de transferencia de datos. Un dispositivo Bluetooth 3.0, sin el sufijo "+ HS" no apoyará la alta velocidad.

Bluetooth v4.0 (2010)

El SIG de Bluetooth ha completado la especificación del Núcleo de Bluetooth en su versión 4.0, que incluye Bluetooth clásico, Bluetooth de alta la velocidad y protocolos Bluetooth de bajo consumo. Bluetooth de alta velocidad se basa en Wi-Fi, y Bluetooth clásico consta de protocolos Bluetooth heredados. Esta versión ha sido adoptada el 30 de junio de 2010. Bluetooth de baja energía (BLE) es un subconjunto de Bluetooth v4.0 con una pila de protocolo completamente nuevo.

WLAN: Wi-Fi

Logo Wi-Fi

Wi-Fi (/ˈwaɪfaɪ/; en algunos países hispanoparlantes /ˈwifi/) es un mecanismo de conexión de dispositivos electrónicos de forma inalámbrica. Los dispositivos habilitados con Wi-Fi, tales como: un ordenador personal, una consola de videojuegos, un smartphone o un reproductor de audio digital, pueden conectarse a Internet a través de un punto de acceso de red inalámbrica. Dicho punto de acceso (o hotspot) tiene un alcance de unos 20 metros en interiores y al aire libre una distancia mayor. Pueden cubrir grandes áreas la superposición de múltiples puntos de acceso.

Esta nueva tecnología surgió por la necesidad de establecer un mecanismo de conexión inalámbrica que fuese compatible entre los distintos dispositivos. Buscando esa compatibilidad fue que en 1999 las empresas 3com, Airones, Intersil, Lucent Technologies, Nokia y Symbol Technologies se reunieron para crear la Wireless Ethernet Compatibility Alliance, o WECA, actualmente llamada Wi-Fi Alliance. El objetivo de la misma fue designar una marca que permitiese fomentar más fácilmente la tecnología inalámbrica y asegurar la compatibilidad de equipos.

De esta forma, en abril de 2000 WECA certifica la interoperabilidad de equipos según la norma IEEE 802.11b, bajo la marca Wi-Fi. Esto quiere decir que el usuario tiene la garantía de que todos los equipos que tengan el sello Wi-Fi pueden trabajar juntos sin problemas, independientemente del fabricante de cada uno de ellos. Se puede obtener un listado completo de equipos que tienen la certificación Wi-Fi en Alliance - Certified Products.

En el año 2002 la asociación WECA estaba formada ya por casi 150 miembros en su totalidad. La familia de estándares 802.11 ha ido naturalmente evolucionando desde su creación, mejorando el rango y velocidad de la transferencia de información, entre otras cosas.

La norma IEEE 802.11 fue diseñada para sustituir el equivalente a las capas físicas y MAC de la norma 802.3 (Ethernet). Esto quiere decir que en lo único que se diferencia una red Wi-Fi de una red Ethernet es en cómo se transmiten las tramas o paquetes de datos; el resto es idéntico. Por tanto, una red local inalámbrica 802.11 es completamente compatible con todos los servicios de las redes locales (LAN) de cable 802.3 (Ethernet).



Trama 802.11 (Wi-Fi)

Trama 802.11
Cabecera 802.11 vs 802.3


Cabeceras 802.11 y 802.3

Dirección 1 (Destination Address (DA)): dirección MAC del nodo final.

Dirección 2 (Source Address (SA)): dirección MAC del nodo inicial.

Dirección 3 (Receiver Address (RA)): dirección MAC que identifica el dispositivo wireless que es el receptor inmediato de la trama.

Dirección 4 (Transmitter Address (TA)): dirección MAC que identifica el dispositivo wireless que transmite la trama.



CSMA/CA
Para el control de la transmisión se utilizan dos protocolos complementarios: CSMA/CA y RTS/CTS.

El mecanismo definido en el CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance, acceso múltiple con escucha de portadora y evasión de colisiones) es una adaptación del CSMA/CD utilizado en las redes Ethernet, pero modificado para tener en cuenta la limitación de las comunicaciones por radiofrecuencia según la cual una estación transmitiendo no puede detectar una colisión con otra transmisión simultánea. El algoritmo dicta que un equipo que desea transmitir, antes de hacerlo ha de escuchar para comprobar si ya existe otra estación enviando datos. En caso de no ser así podrá transmitir, pero si ya hubiera algún equipo transmitiendo deberá esperar un tiempo aleatorio y transcurrido este, volver a comprobar si el medio esta ocupado por otra transmisión. Este algoritmo presenta varios problemas. Uno es que existe la posibilidad de que dos o mas equipos comprueben a la vez si se esta transmitiendo y al detectar que el canal esta libre, empiecen a emitir de forma simultanea. Este problema deberá ser solucionado por protocolos superiores como TCP que se encargarán de detectar pérdidas de información y pedir la retransmisión de esta. Así mismo, al ser el tiempo de espera, cuando se detecta el canal ocupado, tomado de forma aleatoria se consigue paliar en parte el problema de la concurrencia de equipos al comprobar el uso del canal. Otro es el problema conocido como “terminal oculto”, que se muestra en la siguiente ilustración.


Estacions inal·làmbriques A, B i S


Este problema se produce cuando, estando los terminales “A”, “B” y “S” en la misma celda, cuya cobertura esta mostrada en azul, un terminal “A” tiene visibilidad de otro terminal “B” pero no de un terminal “S”, como se ve por su área de cobertura mostrada en verde. Un caso típico en el que puede pasar esto es que se encuentren en fila por lo que la distancia de “A” a “B” sea relativamente corta, pero la de “A” a “S” suficientemente larga como para que no se detecten, pero sin embargo “B” al estar a mitad de camino si tenga recepción de “S”, cuya área de cobertura se muestra en rojo. Esta situación también puede suceder por elementos arquitectónicos que impidan la visibilidad entre “A” y “S”, pero si permitan la comunicación entre “S” y “B” y entre “A” y “B”.

En esta situación el terminal “S” puede emitir para enviar información a “B”. Si el terminal “A” así mismo quisiera transmitir, escucharía el canal, y al no tener visibilidad de “S” encontrará el canal vacío y transmitirá. El problema surge del hecho de que “B” sí tiene visibilidad de ambos terminales, así que detectará ambas señales de forma simultánea, que interferirán y harán la comunicación inválida, y lo peor es que ni “A” ni “S” tendrán constancia del problema, así que la situación puede dilatarse en el tiempo indefinidamente.

Para solventar este problema, así como alguno más (por ejemplo la iteración entre clientes 802.11b y 802.11g) se implementó en estas redes Wi-Fi el protocolo RTS/CTS. Es obligatorio para los equipos tener implementado este protocolo, pero no lo es tenerlo activado, aunque por defecto suele estar activo para evitar problemas como el del terminal oculto.

Cuando el protocolo RTS/CTS esta activado, se añade al CSMA/CA, de manera que una vez que el terminal que ha detectado que nadie está transmitiendo, enviará una trama RTS (Request To Send) al terminal destino, indicándole que desea transmitir y, entre otros datos, cuanto tiempo (en bytes) durará esa transmisión. Si en terminal destino está en condiciones de recibir la información, responderá con una trama CTS (Clear To Send) repitiendo así mismo la información que indica cuanto tiempo durará la transmisión. Con este intercambio, se consigue que el canal quede reservado y los demás equipos sepan que han de esperar al menos el tiempo que se indica en las tramas RTS y CTS para poder transmitir ellos, y puesto que tanto emisor como receptor transmiten la información, todos aquellos sistemas que pudieran interferir con esa transmisión recibirán la trama RTS, la CTS o ambas.



Normas 802.11 más importantes
La familia de estándares desarrollados por la IEEE para tecnologías de red inalámbricas (redes wifi). Originalmente ofrecía una velocidad de transmisión de 1 o 2 Mbps en la banda de frecuencia wifi de 2.4 GHz. Se le conoce popularmente como WIFI (WIreless-FIdelity). Tiene un área de cobertura aproximada de 100 metros.



Norma	Velocidad	Frecuencia	Año
802.11a	54 Mbps	5 Ghz (OFDM)	
1999
802.11b	11 Mbps	2,4 Ghz (DSSS)	
1999
802.11g	54 Mbps	2,4 Ghz (OFDM)	
2003
802.11G +	108 Mbps	2,4 Ghz	
802.11n	300 Mbps	2,4 / 5 Ghz	
2009
802.11ac	1 Gbps	5 Ghz	
2014
802.11ad	7 Gbps	2,4 / 5 / 60 Ghz	
2015?
Siglas:

OFDM: Orthogonal Frecuency División Multiplexing
DSSS: Direct Sequencing Spread Spectrum
Otras normas

• 802.11h: regula la potencia de emisión de las redes Wifi, el objetivo es cumplir los reglamentos europeos para redes inalámbricas a 5 GHz.

• 802.11i: Estándar de seguridad para redes wifi aprobado a mediados de 2004. En él se define al protocolo de encriptación WPA2 basado en el algoritmo AES. Pretende mejorar la seguridad del cifrado wifi y añadir autenticación.

• 802.11j: Estándar wifi equivalente al 802.11h, en la regulación japonesa.

• 802.11ac: Estándar de conexión WiFi en desarrollo, con notables mejorías respecto a 802.11n, para que sea de uso común se calcula que será en 2014. Se utiliza parte de los estándares 802.11a y n. Puede suministrar una velocidad de transmisión de más de 1 Gbps en la banda de 5 GHz.

• 802.11ad: Una propuesta de un estándar de conexión WiFi diseñado con WiGig, la evolución del 802.11ac. Para que sea de uso popular se calcula que será en 2015. Se utiliza parte de los estándares 802.11n y ac. Puede suministrar una velocidad de transmisión de hasta 7 Gbps teóricos en la banda de 60 GHz sin licencia, aunque también funciona en la de 2,4 y 5GHz, serán routers tri-banda . La banda de 60 GHz será usada en enlaces de corta distancia, y su señal es muy direccional. Otra ventaja es que el consumo de energía disminuirá con una misma tasa de datos de 802.11n o ac, siendo más eficiente para móviles y portátiles.

Seguridad y fiabilidad
Uno de los problemas a los cuales se enfrenta actualmente la tecnología Wi-Fi es la progresiva saturación del espectro radioeléctrico, debido a la masificación de usuarios, esto afecta especialmente en las conexiones de larga distancia (mayor de 100 metros). En realidad Wi-Fi está diseñado para conectar ordenadores a la red a distancias reducidas, cualquier uso de mayor alcance está expuesto a un excesivo riesgo de interferencias.

Un muy elevado porcentaje de redes son instalados sin tener en consideración la seguridad convirtiendo así sus redes en redes abiertas (o completamente vulnerables ante el intento de acceder a ellas por terceras personas), sin proteger la información que por ellas circulan. De hecho, la configuración por defecto de muchos dispositivos Wi-Fi es muy insegura (routers, por ejemplo) dado que a partir del identificador del dispositivo se puede conocer la clave de éste; y por tanto acceder y controlar el dispositivo se puede conseguir en sólo unos segundos.

El acceso no autorizado a un dispositivo Wi-Fi es muy peligroso para el propietario por varios motivos. El más obvio es que pueden utilizar la conexión. Pero además, accediendo al Wi-Fi se puede monitorizar y registrar toda la información que se transmite a través de él (incluyendo información personal, contraseñas....).

Existen varias alternativas para garantizar la seguridad de estas redes. Las más comunes son la utilización de protocolos de cifrado de datos para los estándares Wi-Fi como el WEP, el WPA, o el WPA2 que se encargan de codificar la información transmitida para proteger su confidencialidad, proporcionados por los propios dispositivos inalámbricos. La mayoría de las formas son las siguientes:

WEP, cifra los datos en su red de forma que sólo el destinatario deseado pueda acceder a ellos. Los cifrados de 64 y 128 bits son dos niveles de seguridad WEP. WEP codifica los datos mediante una “clave” de cifrado antes de enviarlo al aire. Este tipo de cifrado no está muy recomendado debido a las grandes vulnerabilidades que presenta ya que cualquier cracker puede conseguir sacar la clave, incluso aunque esté bien configurado y la clave utilizada sea compleja.
WPA: presenta mejoras como generación dinámica de la clave de acceso. Las claves se insertan como dígitos alfanuméricos.
Filtrado de MAC, de manera que sólo se permite acceso a la red a aquellos dispositivos autorizados. Es lo más recomendable si solo se va a usar con los mismos equipos, y si son pocos.
Ocultación del punto de acceso: se puede ocultar el punto de acceso (Router) de manera que sea invisible a otros usuarios.
El protocolo de seguridad llamado WPA2 (estándar 802.11i), que es una mejora relativa a WPA. En principio es el protocolo de seguridad más seguro para Wi-Fi en este momento. Sin embargo requieren hardware y software compatibles, ya que los antiguos no lo son.
Sin embargo, no existe ninguna alternativa totalmente fiable, ya que todas ellas son susceptibles de ser vulneradas.

La Wi-Fi Alliance distingue:

WPA-Personal y WPA2-Personal (con PSK, clave pre-compartida)
WPA-Enterprise y WPA2-Enterprise (autenticación 802.1x/EAP)
Los fabricantes comenzaron a producir la nueva generación de puntos de accesos apoyados en el protocolo WPA2 que utiliza el algoritmo de cifrado AES (Advanced Encryption Standard) superior al TKIP utilizado en WPA.

El WPA-Enterprise requiere de una infraestructura de autenticación 802.1x con un servidor de autenticación, generalmente un servidor RADIUS. Este presta un servicio AAA (Authentication, Authorization and Accounting, ‘autenticación, autorización y contabilización’)

El problema de las claves compartidas está en que todo usuario con acceso a la red conoce la clave, por lo que, si se quiere retirar el acceso a un usuario o grupo de usuarios o si la clave es descubierta por personas no autorizadas, se debe cambiar la clave y comunicarla a todos los usuarios de la red para que la cambien en sus dispositivos, procedimiento que suele ser lento e inseguro. Este problema es especialmente preocupante en entornos empresariales o con muchos usuarios, como en los centros docentes y universitarios.

El estandar IEEE 802.1x ofrece una solución a este problema, tanto a redes 802.3 como a 802.11. Consiste en que cada usuario tiene sus propias credenciales de acceso a la red y se autentica con ellas, independientemente de que ademas se utilice o no una clave compartida para acceder a la red.


Siglas:

- PSK: PreShared Key

- EAP: Extensible Authentication Protocol

WPS (Wi-Fi Protected Setup)
WPS (Wi-Fi Protected Setup) es un estándar de 2007, promovido por la Wi-Fi Alliance para facilitar la creación de redes WLAN. En otras palabras, WPS no es un mecanismo de seguridad por sí, se trata de la definición de diversos mecanismos para facilitar la configuración de una red WLAN segura con WPA2, pensados para minimizar la intervención del usuario en entornos domésticos o pequeñas oficinas (SOHO: Small Office Home Office). Concretamente, WPS define los mecanismos a través de los cuales los diferentes dispositivos de la red obtienen las credenciales (SSID y PSK) necesarias para iniciar el proceso de autenticación.








Arquitectura técnica

WPS define una arquitectura con tres elementos con roles diferentes:

Registrar (matriculador): dispositivo con la autoridad de generar o revocar las credenciales en la red. Tanto un AP como cualquier otra estación o PC de la red pueden tener este rol. Puede haber más de un Registrar en una red.
Enrollee (matriculado): dispositivo que solicita el acceso a la red WLAN.
Authenticator (autenticador): AP funcionando de proxy entre el Registrar y el Enrollee.
Métodos

WPS contempla cuatro tipos de configuraciones diferentes para el intercambio de credenciales, PIN (Personal Identification Number), PBC (Push Button Configuration), NFC (Near Field Communications) y USB (Universal Serial Bus):

PIN: tiene que existir un PIN asignado a cada elemento que vaya a asociarse a la red. Este PIN tiene que ser conocido tanto por el Registrar, como por el usuario (Enrollee). Es necesaria la existencia de una interfaz (e.g. pantalla y teclado) para que el usuario pueda introducir el mencionado PIN.
PBC: la generación y el intercambio de credenciales son desencadenados a partir que el usuario presiona un botón (físico o virtual) en el AP (o en otro elemento Registrar) y otro en el dispositivo. Notar que en el corto lapso de tiempo entre que se presiona el botón en el AP y se presiona en el dispositivo, cualquier otra estación próxima puede ganar acceso a la red.
NFC: intercambio de credenciales a través de comunicación NFC. La tecnología NFC (Near Field Communication), basada en RFID (Radio Frequency IDentification) permite la comunicación sin hilos entre dispositivos próximos (0 - 20 cm). Entonces, el dispositivo Enrollee se tiene que situar al lado del Registrar para desencadenar la autenticación. De esta manera, cualquier usuario que tenga acceso físico al Registrar, puede obtener credenciales válidas.
USB: con este método, las credenciales se transfieren mediante un dispositivo de memoria flash (e.g. pendrive) desde el Registrar al Enrollee.
﻿Los métodos PBC, NFC y USB pueden usarse para configurar dispositivos sin pantalla ni teclado (e.g. impresoras, webcams, etc.), pero aunque el estándar contempla NFC y USB, todavía no se certifican estos mecanismos. Actualmente sólo el método PIN es obligatorio en todas las estaciones para obtener la certificación WPS; PBC es obligatorio sólo en APs.

Vulnerabilidades

Existe una falla de seguridad descubierta en diciembre del 2011 por Stefan Viehböck, la cual afecta a routers inalámbricos que tienen la función WPS (también llamada QSS: Quick Security Setup), la misma que en dispositivos actuales se encuentra habilitada por defecto. La falla permite a un atacante recuperar el PIN WPS y con la misma la clave pre-compartida de la red WPA/WPA2 usando ataques de fuerza bruta en pocas horas. Los usuarios deben deshabilitar la función WPS como solución temporal. En ciertos dispositivos, es posible que no se pueda realizar dicho procedimiento.

WMAN: WiMAX
WiMAX, siglas de Worldwide Interoperability for Microwave Access (interoperabilidad mundial para acceso por microondas), es una norma de transmisión de datos que utiliza las ondas de radio en las frecuencias de 2,3 a 3,5 GHz y puede tener una cobertura de hasta 50 km y 70 Mbps. En el estandar WiMAX2 (IEEE 802.16m) teóricamente sería posible alcanzar hasta 1 Gbps en reposo y 100 Mbps en movimiento en la descarga mediante la agrupación de canales.

Es una tecnología dentro de las conocidas como tecnologías de última milla, también conocidas como bucle local que permite la recepción de datos por microondas y retransmisión por ondas de radio. El estándar que define esta tecnología es el IEEE 802.16. Una de sus ventajas es dar servicios de banda ancha en zonas donde el despliegue de cable o fibra por la baja densidad de población presenta unos costos por usuario muy elevados (zonas rurales).

El único organismo habilitado para certificar el cumplimiento del estándar y la interoperabilidad entre equipamiento de distintos fabricantes es el Wimax Forum: todo equipamiento que no cuente con esta certificación, no puede garantizar su interoperabilidad con otros productos.

El WiMAX se puede utilizar para una serie de aplicaciones, incluyendo conexiones de banda ancha para Internet, puntos de acceso, etc. Es similar a Wi-Fi, pero puede funcionar para distancias mucho mayores.

Wireless Speed vs Mobility.png


El ancho de banda y rango del WiMAX lo hacen adecuado para las siguientes aplicaciones potenciales:

Proporcionar conectividad portátil de banda ancha móvil a través de ciudades y países por medio de una variedad de dispositivos.
Proporcionar una alternativa inalámbrica al cable y línea de abonado digital (DSL) de "última milla" de acceso de banda ancha.
Proporcionar datos, telecomunicaciones (VoIP) y servicios de IPTV (triple play).
Proporcionar una fuente de conexión a Internet como parte de un plan de continuidad del negocio.
Para redes inteligentes y medición.


WiMAX vs LMDS
LMDS (Local Multipont Delivery Service): es una tecnología inalámbrica de acceso a la banda ancha, es también denominada como WiBAS (Wireless Broadband Access System) .

Es un servicio de acceso inalámbrico de banda ancha regulado por el IEEE y se describe el 802 por LAN/MAN Standards Committee a través de los esfuerzos del Grupo de Trabajo IEEE 802.16.1.
Trabaja fundamentalmente en la banda de los 26 GHz y los 29 GHz, según las regulaciones locales aplicables. En los Estados Unidos, las frecuencias de 31,0 a 31,3 GHz se consideran también las frecuencias de LMDS.
Está pensada para trabajar en modo punto a punto o punto-multipunto.
Las radiocomunicaciones en la banda de 26 GHz necesitan visibilidad directa entre antenas.
El abastecimiento del servicio LMDS, viene limitado por las características del medio y las exigencias de disponibilidad contratadas, entre otros factores técnicos.
Se puede hablar de distancias máximas entre 2,5 Km. y 14 Km, aunque las utilizaciones típicas de LMDS acostumbran a cubrir distancias de entre 3 y 5 Km., con un grado de disponibilidad muy alto.
WiMAX es una tecnología basada en estándares que permite la entrega de última milla de acceso inalámbrico de banda ancha como una alternativa al cable y DSL".

La tecnología se basa en el estándar IEEE 802.16 (también denominado Broadband Wireless Access).
Trabaja en la banda de 2 a 11 GHz, por tanto, no le afectan las limitaciones de propagación de la banda de 26 GHz.
Proporciona transmisión inalámbrica de datos usando varios de modos de transmisión, de punto a multipunto para portátiles y acceso a Internet completamente móvil.
Una diferencia principal es que WiMAX puede trabajar tanto sin visibilidad directa, como con visibilidad directa.
Otra diferencia fundamental es la capacidad de WiMAX de adaptarse a las condiciones variables del medio, mediante mecanismos de control de potencia emitida, modulación adaptativa y selección automática de frecuencia que permiten una combinación de abastecimiento y de velocidad de transmisión de datos superior.
WWAN: 4G
Evolución de la tecnología móvil
0G	Radio analógica AM/FM (años 40)
1G	Primeros teléfonos móviles: FM (años 80)
TACS [Total Access Communication System]

2G	Transmisión digital de voz (años 90)
GSM [Global System for Mobile Communications]

2G transitional
(2.5G, 2.75G)

Nuevos servicios, p.j. MMS
GPRS [General Packet Radio Service]

EDGE [Enhaced Data rates for GSM Evolution]

3G	Transmisión digital de voz y datos
UMTS [Universal Mobile Telecommunications System]

3G transitional
(3.5G, 3.75G, 3.9G)

HSPA [High Speed Packet Access] / LTE [Long Term Evolution]


4G	LTE Advanced (E-UTRA)
3GPP
El Proyecto Asociación de Tercera Generación o más conocido por el acrónimo inglés 3GPP 3rd Generation Partnership Project es una colaboración de grupos de asociaciones de telecomunicaciones, conocidos como Miembros Organizativos.


Miembros organizativos

Organización
Procedencia
Web
The Association of Radio Industries and Businesses (ARIB)	
Japón
www.arib.or.jp
The Alliance for Telecommunications Industry Solutions (ATIS)	
Estados Unidos
www.atis.org
China Communications Standards Association (CCSA)	
China
www.ccsa.org.cn
The European Telecommunications Standards Institute (ETSI)	
Europa
www.etsi.org
Telecommunications Technology Association (TTA)	
Corea del Sur
www.tta.or.kr
Telecommunication Technology Committee (TTC)	
Japón
www.ttc.or.jp



El objetivo inicial del 3GPP era asentar las especificaciones de un sistema global de comunicaciones de tercera generación 3G para móviles basándose en las especificaciones del sistema evolucionado "Global System for Mobile Communications" GSM dentro del marco del proyecto internacional de telecomunicaciones móviles 2000 de la Unión Internacional de Telecomunicaciones ITU. Más tarde el objetivo se amplió incluyendo el desarrollo y mantenimiento de:

El Sistema Global de telecomunicaciones móviles GSM incluyendo las tecnologías de radio-acceso evolucionadas del GSM (cómo por ejemplo GPRS o el EDGE).
Un sistema de tercera generación evolucionado y más allá del sistema móvil basado en las redes de núcleo evolucionadas del 3GPP y las tecnologías de radio-acceso apoyadas por los miembros del proyecto (cómo por ejemplo la tecnología UTRAN y sus modos FDD y TDD).
Un Subsistema Multimedia IP (IMS) desarrollado en un acceso de forma independiente.
La estandarización 3GPP abarca radio, redes de núcleo y arquitectura de servicio. El proyecto 3GPP se estableció en Diciembre del año 1988 y no se tiene que confundir con el Proyecto Asociación de Tercera Generación 2 (3GPP2), que tiene por objetivo la especificación de los estándares por otra tecnología 3G basada en el sistema IS95 (CDMA), y que es más conocido por el acrónimo CDMA2000. El equipo de apoyo 3GPP, también conocido como el Centro de Competencias Móviles se encuentra situado en las oficinas de la ETSI en Sophia Antípolis (Francia).

Los sistemas 3GPP se encuentran desplegados por la mayoría del territorio donde el mercado GSM está establecido. Mayormente encontramos sistemas de Versión 6, pero desde 2010, con el mercado de teléfonos inteligentes creciendo de forma exponencial, el interés por los sistemas HSPA+ y LTE está impulsando a las compañías a adoptar sistemas Versión 7 y de más avanzados.

Desde 2005, los sistemas 3GPP están siendo desarrollados en los mismos mercados que los sistemas 3GPP2 de tecnología CDMA. Eventualmente los estándares 3GPP2 desaparecerán dejando a los 3GPP como únicos estándares de tecnología móvil.

3GPP vs 3GPP2



LTE
3GPP Long Term Evolution Country Map.svg


Lugares donde se ha adoptado la tecnología LTE (7 de Diciembre 2014)

Lugares con servicios de LTE comercial
Lugares con despliegue de red LTE comercial en marcha o en proyecto
Lugares donde se están ejecutando pruebas en sistemas LTE (pre-acuerdo inicial)

Comparativa LTE frente a LTE Advanced



LTE versión 8
LTE Advanced
Pico de velocidad de datos
Bajada
300 Mbit/s
1 Gbit/s
Subida
75 Mbit/s
500 Mbit/s


Especificaciones de la ITU
El UIT-R (sector de las Radiocomunicaciones de la Unión Internacional de Telecomunicaciones) emitió en 2008 los requisitos que deberían cumplir la telefonía móvil y el servicio de acceso a Internet para ser considerados como 4G. Estas especificaciones se conocen como IMT-Advanced (International Mobile Telecommunications-Advanced)

Entre las especificaciones están:

Servicio basado en protocolos de Internet (IP)
Interoperatividad con estándares inalámbricos existentes.
Una velocidad de datos nominal de 100 Mbit/s, mientras que el usuario se mueve físicamente a altas velocidades relativas a la estación, y 1 Gbit/s, mientras que el usuario y la estación se encuentran en posiciones relativamente fijas. Simplificando, 100 Mb/s en movimiento y 1Gb/s en reposo.
Uso y compartición dinámica de los recursos de la red para soportar más usuarios simultáneos por celda.
Ancho de banda del canal escalable de 5–20 MHz, opcionalmente hasta 40 MHz.
Diversas mejoras en el uso del espectro.
NOTA: Para las comunicaciones inalámbricas 3G, la ITU ya había emitido unas especificaciones conocidas como IMT-2000.

Dispositivos
Antenas
Una antena es un dispositivo (conductor metálico) diseñado con el objetivo de emitir o recibir ondas electromagnéticas hacia el espacio libre. Una antena transmisora transforma voltajes en ondas electromagnéticas, y una receptora realiza la función inversa.

Existe una gran diversidad de tipos de antenas. En unos casos deben expandir en lo posible la potencia radiada, es decir, no deben ser directivas o direccionales (ejemplo: una emisora de radio comercial o una estación base de teléfonos móviles), otras veces deben serlo para canalizar la potencia en una dirección y no interferir a otros servicios (antenas entre estaciones de radioenlaces). También es una antena la que está integrada en la computadora portátil para conectarse a las redes Wi-Fi.

Diagrama de radiación
Es la representación gráfica de las características de radiación de una antena, en función de la dirección (coordenadas en azimut y elevación). Lo más habitual es representar la densidad de potencia radiada, aunque también se pueden encontrar diagramas de polarización o de fase. Atendiendo al diagrama de radiación, podemos hacer una clasificación general de los tipos de antena y podemos definir la directividad de la antena (antena isotrópica, antena directiva, antena bidireccional, antena omnidireccional,…)

Diagramas de radiación





Clases de antenas según su forma
Existen tres tipos básicos de antenas:

antenas de hilo,
antenas de apertura
antenas planas.
antenas parabolicas

Asimismo, las agrupaciones de estas antenas (arrays) se suelen considerar en la literatura como otro tipo básico de antena.


Antenas de hilo



Las antenas de hilo son antenas cuyos elementos radiantes son conductores de hilo que tienen una sección despreciable respecto a la longitud de onda de trabajo. Se utilizan extensamente en las bandas de MF, HF, VHF y UHF. Se pueden encontrar agrupaciones de antenas de hilo. Ejemplos de antenas de hilo son:

El monopolo vertical
El dipolo y su evolución, la antena Yagi
La antena espira
La antena helicoidal es un tipo especial de antena que se usa principalmente en VHF y UHF. Un conductor describe una hélice, consiguiendo así una polarización circular.
Antenas de apertura



Las antenas de apertura son aquellas que utilizan superficies o aperturas para direccionar el haz electromagnético de forma que concentran la emisión y recepción de su sistema radiante en una dirección. La más conocida y utilizada es la antena parabólica, tanto en enlaces de radio terrestres como de satélite.

Hay varios tipos de antenas de apertura, como la antena de bocina, la antena parabólica, la antena parabólica del Radar Doppler y superficies reflectoras en general.


Antenas planas




Un tipo particular de antena plana son las antenas de apertura sintética, típicas de los radares de apertura sintética (SAR).


Antenas de Array



Las antenas de array están formadas por un conjunto de dos o más antenas idénticas distribuidas y ordenadas de tal forma que en su conjunto se comportan como una única antena con un diagrama de radiación propio.

La característica principal de los arrays de antenas es que su diagrama de radiación es modificable, pudiendo adaptarlo a diferentes aplicaciones/necesidades. Esto se consigue controlando de manera individual la amplitud y fase de la señal que alimenta a cada uno de los elementos del array.


Atendiendo a la distribución de las antenas que componen un array podemos hacer la siguiente clasificación:

Arrays lineales: Los elementos están dispuestos sobre una línea.
Arrays Planos: Los elementos están dispuestos bidimensionalmente sobre un plano.
Arrays conformados: Los elementos están dispuestos sobre una superficie curva.
Puntos de acceso (AP: Access Point)
Uso de canales
Existen 14 canales, aunque en Europa solo se utilizan 13.



Canal
Frecuecia(MHz)
Norte America
Japón
Mayor parte del mundo
1	2412	
Sí
Sí
Sí
2	2417	
Sí
Sí
Sí
3	2422	
Sí
Sí
Sí
4	2427	
Sí
Sí
Sí
5	2432	
Sí
Sí
Sí
6	2437	
Sí
Sí
Sí
7	2442	
Sí
Sí
Sí
8	2447	
Sí
Sí
Sí
9	2452	
Sí
Sí
Sí
10	2457	
Sí
Sí
Sí
11	2462	
Sí
Sí
Sí
12	2467	
No
Sí
Sí
13	2472	
No
Sí
Sí
14	2484	
No
solo en 11b
No
Si deseamos crear una red Wi-Fi cuya cobertura esté soportada por varios puntos de acceso, deberemos de establecer los canales de los distintos puntos de acceso de forma que no se solapen. Canales Wi-Fi en 2,4 GHz

2.4 GHz Wi-Fi channels (802.11b,g WLAN).svg

Por ello se recomienda utilizar los canales 1, 6 y 11. También pueden usarse 2, 7 y 12. Otra posibilidad son 3, 8 y 13.


Topología celular con canales 1, 6 y 11

Selección de canal en un punto de acceso



Modos básicos de funcionamiento
Un punto de acceso (AP) puede configurar de muchas maneras, según la funcionalidad que queramos proporcionarle. Los modos básicos son:

Modo punto de acceso
Modo repetidor
Modo puente (bridge)


Modo Punto de Acceso
En el modo de punto de acceso, los clientes deben utilizar el mismo SSID (nombre de red inalámbrica) y canal que el AP con el fin de conectarse. Si la seguridad inalámbrica está activada en el AP, será necesario que el cliente introduzca una contraseña para conectarse a la AP. En el modo de punto de acceso, múltiples clientes pueden conectarse al punto de acceso al mismo tiempo.





Modo Repetidor
En el modo de repetidor, el AP aumenta el alcance de la red inalámbrica mediante la ampliación de la cobertura inalámbrica de otro punto de acceso o router inalámbrico. Los puntos de acceso y router inalámbrico (si existiese) debe estar dentro del alcance del otro. Asegúrese de que todos los clientes, puntos de acceso y el router inalámbrico utilizan el mismo SSID (nombre de red inalámbrica) y el mismo canal.





Modo Puente (Bridge)
En el modo de puente, el AP se conectan dos LAN separadas que no pueden ser fácilmente conectadas entre sí mediante un cable. Por ejemplo, si hay dos LANs cableadas separadas por un pequeño patio, sería costoso enterrar los cables para la conexión entre las dos partes. Una mejor solución es utilizar dos AP para conectar de forma inalámbrica las dos LAN. En el modo de puente, ambas unidades AP no actuan como puntos de acceso.

Nota: El modo de puente no se especifica en los estándares Wi-Fi o IEEE. Este modo sólo funciona con dos unidades idénticas que soporten este modo. La comunicación con otros puntos de acceso (incluso de la misma marca) no está garantizada.





Interconexión de dispositivos inalámbricos
Existen dos modos:

Modo ad hoc (no se utiliza AP)
Modo infraestructura
Modo ad hoc (no se utiliza AP)



Modo infraestructura



Routers inalámbricos
Actualmente en hogares y pequeñas oficinas se utiliza frecuentemente unos dispositivos de enrutamiento básico entre la red local e Internet. Son routers que disponen de varios puertos RJ45 dispuestos a modo de switch y una antena que hace la función de punto de acceso.

Actividades
Busca en Internet las siglas ISP e WISP. ¿Qué significan?
¿Qué significan las siglas WPAN, WLAN, WMAN y WWAN? Pon un ejemplo de tecnología empleada en cada una de ellas.
Busca 3 dispositivos que tengan soporte para Bluetooth 4 de baja energía. Escribir sus características, foto y sito web de venta.
Busca 3 teléfonos móviles con soporte 4G (LTE Advanced).
¿Por qué al estándar IEEE 802.15.1 se le conoce también como Bluetooth? ¿Quién le puso dicho nombre?
¿Por qué al estándar IEEE 802.11 se le conoce también como Wi-Fi? ¿Quién le puso dicho nombre?
Para redes WPAN, existe una tecnología conocida como UWB (UltraWideBand). Indica en que se diferencia de Bluetooth y qué aplicaciones tiene.
Explica cuáles son las ventajas e inconvenientes del uso de Wi-Fi frente a Ethernet.
Haz un esquema de una trama 802.11 y compárala con una trama 802.3.
Explica la técnica CSMA/CA y RTS/CTS.
Explica los distintos métodos de seguridad que implementan los puntos de acceso: cifrado, filtros, ...
Indica qué tipo y características de producto ofrecido en http://www.edimax.es/es/produce_detail.php?pd_id=348&pl1_id=3&pl2_id=73.
¿Qué es WPS referido a Wi-Fi?
Es posible configurar un punto de acceso como puente y punto de acceso simultáneamente. Explica la respuesta.
Realiza una configuración Ad-hoc entre dos equipos inalámbricos. Indicar los pasos seguidos y realizar algunas capturas de pantalla.
Imagina que te dan un punto de acceso y te piden que lo configures. Indica los pasos que debes seguir para tener acceso a él.
Visita la página http://www.tp-link.com/en/support/emulators/ y elige 3 puntos de acceso. Para cada uno de ellos indica qué características soporta de las vistas este tema.
Bibliografía y referencias
http://www.blogadder.info/2010/11/basic-guidelines-wireless-n-access.html
http://recursostic.educacion.es/observatorio/web/es/cajon-de-sastre/38-cajon-de-sastre/961-monografico-redes-wifi
http://www.xataka.com/moviles/que-es-lte
Tema 8



Tema 8: La capa de red.
Conceptos generales
Estándares
Dispositivos
Actividades
Bibliografía y referencias
Conceptos generales
Internet no es un nuevo tipo de red física, sino un conjunto de tecnologías que permiten interconectar redes muy distintas entre sí. Internet no es dependiente de la máquina ni del sistema operativo utilizado. De esta manera, podemos transmitir información entre un servidor Unix y un ordenador que utilice Windows. O entre plataformas completamente distintas como Macintosh, Alpha o Intel. Es más: entre una máquina y otra generalmente existirán redes distintas: redes Ethernet, redes Token Ring e incluso enlaces vía satélite. Como vemos, está claro que no podemos utilizar ningún protocolo que dependa de una arquitectura en particular. Lo que estamos buscando es un método de interconexión general que sea válido para cualquier plataforma, sistema operativo y tipo de red. La familia de protocolos que se eligieron para permitir que Internet sea una Red de redes es TCP/IP. Nótese aquí que hablamos de familia de protocolos ya que son muchos los protocolos que la integran, aunque en ocasiones para simplificar hablemos sencillamente del protocolo TCP/IP.

El protocolo TCP/IP tiene que estar a un nivel superior del tipo de red empleado y funcionar de forma transparente en cualquier tipo de red. Y a un nivel inferior de los programas de aplicación (páginas WEB, correo electrónico…) particulares de cada sistema operativo. Todo esto nos sugiere el siguiente modelo de referencia:



Capa de aplicación (HTTP, SMTP, FTP, TELNET...)
Capa de transporte (UDP, TCP)
Capa de red (IP)
Capa de acceso a la red (Ethernet, Token Ring...)
Capa física (cable coaxial, par trenzado...)
El nivel más bajo es la capa física. Aquí nos referimos al medio físico por el cual se transmite la información. Generalmente será un cable aunque no se descarta cualquier otro medio de transmisión como ondas o enlaces vía satélite.

La capa de acceso a la red determina la manera en que las estaciones (ordenadores) envían y reciben la información a través del soporte físico proporcionado por la capa anterior. Es decir, una vez que tenemos un cable, ¿cómo se transmite la información por ese cable? ¿Cuándo puede una estación transmitir? ¿Tiene que esperar algún turno o transmite sin más? ¿Cómo sabe una estación que un mensaje es para ella? Pues bien, son todas estas cuestiones las que resuelve esta capa.

Las dos capas anteriores quedan a un nivel inferior del protocolo TCP/IP, es decir, no forman parte de este protocolo. La capa de red define la forma en que un mensaje se transmite a través de distintos tipos de redes hasta llegar a su destino. El principal protocolo de esta capa es el IP aunque también se encuentran a este nivel los protocolos ARP, ICMP e IGMP. Esta capa proporciona el direccionamiento IP y determina la ruta óptima a través de los encaminadores (routers) que debe seguir un paquete desde el origen al destino.

La capa de transporte (protocolos TCP y UDP) ya no se preocupa de la ruta que siguen los mensajes hasta llegar a su destino. Sencillamente, considera que la comunicación extremo a extremo está establecida y la utiliza. Además añade la noción de puertos, como veremos más adelante.

Una vez que tenemos establecida la comunicación desde el origen al destino nos queda lo más importante, ¿qué podemos transmitir? La capa de aplicación nos proporciona los distintos servicios de Internet: correo electrónico, páginas Web, FTP, TELNET…

La familia de protocolos TCP/IP fue diseñada para permitir la interconexión entre distintas redes. El mejor ejemplo de interconexión de redes es Internet: se trata de un conjunto de redes unidas mediante encaminadores o routers. Un router es un dispositivo que separa 2 o más redes.

Concepto de capa de red
La capa de red se ocupa del control de la subred. La principal función de este nivel es la del encaminamiento, es decir, el tratamiento de cómo elegir la ruta más adecuada para que el bloque de datos del nivel de red (paquete) llegue a su destino. Cada destino está identificado univocamente en la subred por una dirección.

Otra función importante de esta capa es el tratamiento de la congestión. Cuando hay muchos paquetes en la red, unos obstruyen a los otros generando cuellos de botella en los puntos más sensibles. Un sistema de gestión de red avanzado evitará o paliará estos problemas de congestión.

Entre el emisor y el receptor se establecen comunicaciones utilizando protocolos determinados. El mismo protocolo debe estar representado tanto en el emisor como en el receptor.

El concepto de red está relacionado con las direcciones IP que se configuren en cada ordenador, no con el cableado. Es decir, si tenemos varias redes dentro del mismo cableado solamente los ordenadores que permanezcan a una misma red podrán comunicarse entre sí. Para que los ordenadores de una red puedan comunicarse con los de otra red es necesario que existan routers que interconecten las redes. Un router o encaminador no es más que un ordenador con varias direcciones IP, una para cada red, que permita el tráfico de paquetes entre sus redes.

La capa de red se encarga de fragmentar cada mensaje en paquetes de datos llamados datagramas IP y de enviarlos de forma independiente a través de la red de redes. Cada datagrama IP incluye un campo con la dirección IP de destino. Esta información se utiliza para enrutar los datagramas a través de las redes necesarias que los hagan llegar hasta su destino.

Nota: Cada vez que visitamos una página web o recibimos un correo electrónico es habitual atravesar un número de redes comprendido entre 10 y 20, dependiendo de la distancia de los hosts. El tiempo que tarda un datagrama en atravesar 20 redes (20 routers) suele ser inferior a 600 milisegundos.


La dirección IP es el identificador de cada host dentro de su red de redes. Cada host conectado a una red tiene una dirección IP asignada, la cual debe ser distinta a todas las demás direcciones que estén vigentes en ese momento en el conjunto de redes visibles por el host. En el caso de Internet, no puede haber dos ordenadores con 2 direcciones IP (públicas) iguales. Pero sí podríamos tener dos ordenadores con la misma dirección IP siempre y cuando pertenezcan a redes independientes entre sí (sin ningún camino posible que las comunique).

Las direcciones IP se clasifican en:

Direcciones IP públicas. Son visibles en todo Internet. Un ordenador con una IP pública es accesible (visible) desde cualquier otro ordenador conectado a Internet. Para conectarse a Internet es necesario tener una dirección IP pública.
Direcciones IP privadas (reservadas). Son visibles únicamente por otros hosts de su propia red o de otras redes privadas interconectadas por routers. Se utilizan en las empresas para los puestos de trabajo. Los ordenadores con direcciones IP privadas pueden salir a Internet por medio de un router (o proxy) que tenga una IP pública. Sin embargo, desde Internet no se puede acceder a ordenadores con direcciones IP privadas.
A su vez, las direcciones IP pueden ser:

Direcciones IP estáticas (fijas). Un host que se conecte a la red con dirección IP estática siempre lo hará con una misma IP. Las direcciones IP públicas estáticas son las que utilizan los servidores de Internet con objeto de que estén siempre localizables por los usuarios de Internet. Estas direcciones hay que contratarlas.
Direcciones IP dinámicas. Un host que se conecte a la red mediante dirección IP dinámica, cada vez lo hará con una dirección IP distinta. Las direcciones IP públicas dinámicas son las que se utilizan en las conexiones a Internet mediante un módem. Los proveedores de Internet utilizan direcciones IP dinámicas debido a que tienen más clientes que direcciones IP (es muy improbable que todos se conecten a la vez).
Las direcciones IP están formadas por 4 bytes (32 bits). Se suelen representar de la forma a.b.c.d donde cada una de estas letras es un número comprendido entre el 0 y el 255. Por ejemplo la dirección IP del servidor de IBM (www.ibm.com) es 129.42.18.99.


Las direcciones IP se pueden representar

en decimal (lo habitual), desde 0.0.0.0 hasta 255.255.255.255
en hexadecimal, desde la 00.00.00.00 hasta la FF.FF.FF.FF
o en binario, desde la 00000000.00000000.00000000.00000000 hasta la 11111111.11111111.11111111.11111111.
Las tres direcciones siguientes representan a la misma máquina (podemos utilizar una calculadora científica para realizar las conversiones).

(decimal) 128.10.2.30
(hexadecimal) 80.0A.02.1E
(binario) 10000000.00001010.00000010.00011110
Ejemplo
En una red TCP/IP es posible tener, por ejemplo, servidores web y servidores de correo para uso interno. Obsérvese que todos los servicios de Internet se pueden configurar en pequeñas redes internas TCP/IP.

A continuación veremos un ejemplo de interconexión de 3 redes. Cada host (ordenador) tiene una dirección física que viene determinada por su adaptador de red. Estas direcciones se corresponden con la capa de acceso al medio y se utilizan para comunicar dos ordenadores que pertenecen a la misma red. Para identificar globalmente un ordenador dentro de un conjunto de redes TCP/IP se utilizan las direcciones IP (capa de red). Observando una dirección IP sabremos si pertenece a nuestra propia red o a una distinta (todas las direcciones IP de la misma red comienzan con los mismos números, según veremos más adelante).





Host	Red	Dirección IP	Dirección física
A	Red 1	192.168.0.10	00-60-52-0B-B7-7D
R1	192.168.0.1	00-E0-4C-AB-9A-FF
Red 2	10.10.0.1	A3-BB-05-17-29-D0
B	10.10.0.7	00-E0-4C-33-79-AF
R2	10.10.0.2	B2-42-52-12-37-BE
Red 3	200.3.107.1	00-E0-89-AB-12-92
C	200.3.107.73	A3-BB-08-10-DA-DB
D	200.3.107.200	B2-AB-31-07-12-93

En el ejemplo anterior, supongamos que el ordenador 200.3.107.200 (D) envía un mensaje al ordenador con 200.3.107.73 (C). Como ambas direcciones comienzan con los mismos números, D sabrá que ese ordenador se encuentra dentro de su propia red y el mensaje se entregará de forma directa. Sin embargo, si el ordenador 200.3.107.200 (D) tuviese que comunicarse con 10.10.0.7 (B), D advertiría que el ordenador destino no pertenece a su propia red y enviaría el mensaje al router R2 (es el ordenador que le da salida a otras redes). El router entregaría el mensaje de forma directa porque B se encuentra dentro de una de sus redes (la Red 2).

Direcciones IP
¿Quién reparte las direcciones IP?
En un principio se encargó de ello el IANA (Internet Assigned Numbers Authority). Actualmente tanto las direcciones como los nombres son administrados por la ICANN.



La Corporación de Internet para la Asignación de Nombres y Números (en inglés: Internet Corporation for Assigned Names and Numbers; ICANN) es una organización sin fines de lucro creada el 18 de septiembre de 1998 con objeto de encargarse de cierto número de tareas realizadas con anterioridad a esa fecha por otra organización, la IANA. Su sede radica en California y está sujeta a las leyes de dicho Estado.

ICANN es una organización que opera a nivel multinacional/internacional) y es la responsable de asignar las direcciones del protocolo IP, de los identificadores de protocolo, de las funciones de gestión del sistema de dominio y de la administración del sistema de servidores raíz.


La ICANN (Corporación de Internet para la Asignación de Nombres y Números) delega los recursos de Internet a los RIRs, y a su vez los RIRs siguen sus políticas regionales para una posterior subdelegación de recursos a sus clientes, que incluyen Proveedores de servicios y organizaciones para uso propio.

Un Registro Regional de Internet o Regional Internet Registry (RIR) es una organización que supervisa la asignación y el registro de recursos de números de Internet dentro de una región particular del mundo. Los recursos incluyen direcciones IP (tanto IPv4 como IPv6) y números de sistemas autónomos (para su uso en encaminamiento BGP).

Hay actualmente 5 RIRs en funcionamiento:



American Registry for Internet Numbers (ARIN) para América Anglosajona.
RIPE Network Coordination Centre (RIPE NCC) para Europa, el Oriente Medio y Asia Central.
Asia-Pacific Network Information Centre (APNIC) para Asia y la Región Pacífica.
Latin American and Caribbean Internet Address Registry (LACNIC) para América Latina y el Caribe.
African Network Information Centre (AfriNIC) para África


¿Cómo se reparten las direcciones IPv4?
Existen un total de 3³² direcciones IP (4.294.967.296).

La mitad (2.147.483.648) están destinadas a redes de clase A: (16.777.216 IPs por cada una de las 128 redes de clase A).
Un cuarto (1.073.741.824) están destinadas a redes de clase B: (65.536 IPs por cada una de las 16.384 redes de clase B).
Un octavo (536.870.912) están destinadas a redes de clase C: (256 IPs por cada una de las 2.097.152 redes de clase C)
Un dieciseisavo (268.435.456) están destinadas la clase D (Multicast).
Otro dieciseisavo (268.435.456) están destinadas a la clase E (Experimental).
Tamaño relativo de cada clase.




Clase C: (256 IPs).Arriba

Clase B: (65.536 IPs). En medio

Clase A: (16.777.216 IPs). Abajo

Clases
¿Cuántas direcciones IP existen? Si calculamos 2 elevado a 32 obtenemos más de 4000 millones de direcciones distintas. Sin embargo, no todas las direcciones son válidas para asignarlas a hosts. Las direcciones IP no se encuentran aisladas en Internet, sino que pertenecen siempre a alguna red. Todas las máquinas conectadas a una misma red se caracterizan en que los primeros bits de sus direcciones son iguales. De esta forma, las direcciones se dividen conceptualmente en dos partes: el identificador de red y el identificador de host.

Dependiendo del número de hosts que se necesiten para cada red, las direcciones de Internet se han dividido en las clases primarias A, B y C. La clase D está formada por direcciones que identifican no a un host, sino a un grupo de ellos. Las direcciones de clase E no se pueden utilizar (están reservadas).



0	1	2	3	4	8	16	24	32
Clase A	0	red	host
Clase B	1	0	red	host
Clase C	1	1	0	red	host
Clase D	1	1	1	0	grupo de multicast (multidifusión)
Clase E	1	1	1	1	(direcciones reservadas: no se pueden utilizar)


Clase	Formato(r=red, h=host)	Nº de redes	Nº de hosts por red	Rango de direcciones de redes	Máscara de subred
A	r.h.h.h	128	16.777.214	0.0.0.0 127.0.0.0	255.0.0.0
B	r.r.h.h	16.384	65.534	128.0.0.0 191.255.0.0	255.255.0.0
C	r.r.r.h	2.097.152	254	192.0.0.0 223.255.255.0	255.255.255.0
D	grupo	-	-	224.0.0.0 239.255.255.255	-
E	no válidas	-	-	240.0.0.0 255.255.255.255	-
Nota: Las direcciones usadas en Internet están definidas en la RFC 1166

Difusión (broadcast) y multidifusión (multicast).-- El término difusión (broadcast) se refiere a todos los hosts de una red; multidifusión (multicast) se refiere a varios hosts (aquellos que se hayan suscrito dentro de un mismo grupo). Siguiendo esta misma terminología, en ocasiones se utiliza el término unidifusión para referirse a un único host.

Direcciones IP especiales y reservadas
No todas las direcciones comprendidas entre la 0.0.0.0 y la 223.255.255.255 son válidas para un host: algunas de ellas tienen significados especiales. Las principales direcciones especiales se resumen en la siguiente tabla. Su interpretación depende del host desde el que se utilicen.



Bits de red	Bits de host	Significado	Ejemplo
todos 0	Mi propio host	0.0.0.0
todos 0	host	Host indicado dentro de mi red	0.0.0.10
red	todos 0	Red indicada	192.168.1.0
todos 1	Difusión a internet. Se acota a mi red.	255.255.255.255
red	todos 1	Difusión a la red indicada	192.168.1.255
127	cualquier valor válido	Loopback (mi propio host)	127.0.0.1
OBSERVACIONES:

La red 0 y la red 127 (ambas de clase A) son especiales. Perdemos nada menos que 2*16.777.216 IPs que no pueden asignarse a ningún host concreto.
En cada red existen 2 direcciones especiales: la primera del rango (dirección de red) y la última del rango (dirección de broadcast). Por tanto si tenemos la red 192.168.0.x con 256 IPs, sólo pueden destinarse a hosts 254 direcciones (192.168.0.0 es la dirección de red y 192.168.0.255 es la dirección de broadcast)
Difusión o broadcasting es el envío de un mensaje a todos los ordenadores que se encuentran en una red. La dirección de loopback (normalmente 127.0.0.1) se utiliza para comprobar que los protocolos TCP/IP están correctamente instalados en nuestro propio ordenador. Lo veremos más adelante, al estudiar el comando PING.

Las direcciones de redes siguientes se encuentran reservadas para su uso en redes privadas (intranets). Una dirección IP que pertenezca a una de estas redes se dice que es una dirección IP privada.



Clase	Rango de direcciones privadas de redes
A	10.0.0.0
B	172.16.0.0 - 172.31.0.0
C	192.168.0.0 - 192.168.255.0
Los anteriores rangos vienen especificados en el RFC 1918.

Ademas según el RFC 3330, se reserva la red 169.254.0.0 para el uso de link-local, más conocido como APIPA (Automatic Private Internet Protocol Addressing - Direccionamiento Privado Automático del Protocolo de Internet). Este sistema es usado por sistemas Windows cuando no detectan la presencia de ningún servidor DHCP.

Por ejemplo, si estamos construyendo una red privada con un número de ordenadores no superior a 254 podemos utilizar una red reservada de clase C. Al primer ordenador le podemos asignar la dirección 192.168.23.1, al segundo 192.168.23.2 y así sucesivamente hasta la 192.168.23.254. Como estamos utilizando direcciones reservadas, tenemos la garantía de que no habrá ninguna máquina conectada directamente a Internet con alguna de nuestras direcciones. De esta manera, no se producirán conflictos y desde cualquiera de nuestros ordenadores podremos acceder a la totalidad de los servidores de Internet (si utilizásemos en un ordenador de nuestra red una dirección de un servidor de Internet, nunca podríamos acceder a ese servidor).


Definiciones

Intranet.-- Red privada que utiliza los protocolos TCP/IP. Puede tener salida a Internet o no. En el caso de tener salida a Internet, el direccionamiento IP permite que los hosts con direcciones IP privadas puedan salir a Internet pero impide el acceso a los hosts internos desde Internet. Dentro de una intranet se pueden configurar todos los servicios típicos de Internet (web, correo, mensajería instantánea, etc.) mediante la instalación de los correspondientes servidores. La idea es que las intranets son como "internets" en miniatura o lo que es lo mismo, Internet es una intranet pública gigantesca.

Extranet.-- Unión de dos o más intranets. Esta unión puede realizarse mediante líneas dedicadas (RDSI, X.25, frame relay, punto a punto, etc.) o a través de Internet.

Internet.-- La mayor red pública de redes TCP/IP.


CASO PRÁCTICO.- Una empresa dispone de una línea frame relay con direcciones públicas contratadas desde la 194.143.17.8 hasta la 194.143.17.15 (la dirección de la red es 194.143.17.8, su dirección de broadcasting 194.143.17.15 y su máscara de red 255.255.255.248). La línea frame relay está conectada a un router. Diseñar la red para:

3 servidores (de correo, web y proxy)
20 puestos de trabajo


Los 20 puestos de trabajo utilizan direcciones IP privadas y salen a Internet a través del Proxy. En la configuración de red de cada uno de estos 20 ordenadores se indicará la dirección "192.168.1.1" en el cuadro "Puerta de enlace". La puerta de enlace (puerta de salida o gateway) es el ordenador de nuestra red que nos permite salir a otras redes. El Proxy tiene dos direcciones IP, una de la red privada y otra de la red pública. Su misión es dar salida a Internet a la red privada, pero no permitir los accesos desde el exterior a la zona privada de la empresa.

Los 3 servidores y el router utilizan direcciones IP públicas, para que sean accesibles desde cualquier host de Internet. La puerta de enlace de Proxy, Correo y Web es 194.143.17.9 (Router).

Obsérvese que la primera y última dirección de todas las redes son direcciones IP especiales que no se pueden utilizar para asignarlas a hosts. La primera es la dirección de la red y la última, la dirección de difusión o broadcasting. La máscara de subred de cada ordenador se ha indicado dentro de su red después de una barra: PC1, PC2, ... , PC20 y Proxy (para su IP 192.168.1.1) tienen la máscara 255.255.255.0 y Router, Web, Correo y Proxy (para su IP 194.143.17.10), la máscara 255.255.255.248. El concepto de máscara de subred se estudia a continuación.

Máscara de red y subred
Una máscara de subred es aquella dirección que enmascarando nuestra dirección IP, nos indica si otra dirección IP pertenece a nuestra subred o no.

La siguiente tabla muestra las máscaras de subred correspondientes a cada clase:



Clase	Máscara de subred
A	255.0.0.0
B	255.255.0.0
C	255.255.255.0
Si expresamos la máscara de subred de clase A en notación binaria, tenemos:

11111111.00000000.00000000.00000000 
Los unos indican los bits de la dirección correspondientes a la red y los ceros, los correspondientes al host. Según la máscara anterior, el primer byte (8 bits) es la red y los tres siguientes (24 bits), el host. Por ejemplo, la dirección de clase A 35.120.73.5 pertenece a la red 35.0.0.0.

Supongamos una subred con máscara 255.255.0.0, en la que tenemos un ordenador con dirección 148.120.33.110. Si expresamos esta dirección y la de la máscara de subred en binario, tenemos:

148.120.33.110     10010100.01111000.00100001.01101110 (dirección de una máquina)
255.255.0.0        11111111.11111111.00000000.00000000 (dirección de su máscara de red)
148.120.0.0        10010100.01111000.00000000.00000000 (dirección de su subred) 
                   <-------RED-----> <-----HOST------>

Al hacer el producto binario de las dos primeras direcciones (donde hay dos 1 en las mismas posiciones ponemos un 1 y en caso contrario, un 0) obtenemos la tercera.


Si hacemos lo mismo con otro ordenador, por ejemplo el 148.120.33.89, obtenemos la misma dirección de subred. Esto significa que ambas máquinas se encuentran en la misma subred (la subred 148.120.0.0).



148.120.33.89    10010100.01111000.00100001.01011001 (dirección de una máquina)
255.255.0.0      11111111.11111111.00000000.00000000 (dirección de su máscara de red)
148.120.0.0      10010100.01111000.00000000.00000000 (dirección de su subred) 


En cambio, si tomamos la 148.115.89.3, observamos que no pertenece a la misma subred que las anteriores.



148.115.89.3    10010100.01110011.01011001.00000011 (dirección de una máquina)
255.255.0.0     11111111.11111111.00000000.00000000 (dirección de su máscara de red)
148.115.0.0     10010100.01110011.00000000.00000000 (dirección de su subred) 


Cálculo de la dirección de difusión.-- Ya hemos visto que el producto lógico binario (AND) de una IP y su máscara devuelve su dirección de red. Para calcular su dirección de difusión, hay que hacer la suma lógica en binario (OR) de la IP con el inverso (NOT) de su máscara.

En una red de redes TCP/IP no puede haber hosts aislados: todos pertenecen a alguna red y todos tienen una dirección IP y una máscara de subred (si no se especifica se toma la máscara que corresponda a su clase). Mediante esta máscara un ordenador sabe si otro ordenador se encuentra en su misma subred o en otra distinta. Si pertenece a su misma subred, el mensaje se entregará directamente. En cambio, si los hosts están configurados en redes distintas, el mensaje se enviará a la puerta de salida o router de la red del host origen. Este router pasará el mensaje al siguiente de la cadena y así sucesivamente hasta que se alcance la red del host destino y se complete la entrega del mensaje.


EJEMPLO.- Los proveedores de Internet habitualmente disponen de una o más redes públicas para dar acceso a los usuarios que se conectan por módem. El proveedor va cediendo estas direcciones públicas a sus clientes a medida que se conectan y liberándolas según se van desconectando (direcciones dinámicas). Supongamos que cierto ISP (proveedor de servicios de Internet) dispone de la red 63.81.0.0 con máscara 255.255.0.0. Para uso interno utiliza las direcciones que comienzan por 63.81.0 y para ofrecer acceso a Internet a sus usuarios, las direcciones comprendidas entre la 63.81.1.0 hasta la 63.81.1.254 (las direcciones 63.81.0.0 y 63.81.255.255 están reservadas).

Si un usuario conectado a la red de este ISP tiene la dirección 63.81.1.1 y quiere transferir un archivo al usuario con IP 63.81.1.2, el primero advertirá que el destinatario se encuentra en su misma subred y el mensaje no saldrá de la red del proveedor (no atravesará el router).





Las máscaras 255.0.0.0 (clase A), 255.255.0.0 (clase B) y 255.255.255.0 (clase C) suelen ser suficientes para la mayoría de las redes privadas. Sin embargo, las redes más pequeñas que podemos formar con estas máscaras son de 254 hosts y para el caso de direcciones públicas, su contratación tiene un coste muy alto. Por esta razón suele ser habitual dividir las redes públicas de clase C en subredes más pequeñas. A continuación se muestran las posibles divisiones de una red de clase C. La división de una red en subredes se conoce como subnetting.



Máscara de subred	Binario	Nº de subredes	Nº de hosts por subred	Ejemplos de subredes (x=a.b.c por ejemplo, 192.168.1)
255.255.255.0	00000000	1	254	x.0
255.255.255.128	10000000	2	126	x.0, x.128
255.255.255.192	11000000	4	62	x.0, x.64, x.128, x.192
255.255.255.224	11100000	8	30	x.0, x.32, x.64, x.96, x.128, ...
255.255.255.240	11110000	16	14	x.0, x.16, x.32, x.48, x.64, ...
255.255.255.248	11111000	32	6	x.0, x.8, x.16, x.24, x.32, x.40, ...
255.255.255.252	11111100	64	2	x.0, x.4, x.8, x.12, x.16, x.20, ...
255.255.255.254	11111110	128	0	ninguna posible
255.255.255.255	11111111	256	0	ninguna posible
Obsérvese que en el caso práctico que explicamos un poco más arriba se utilizó la máscara 255.255.255.248 para crear una red pública con 6 direcciones de hosts válidas (la primera y última dirección de todas las redes se excluyen). Las máscaras con bytes distintos a 0 o 255 también se pueden utilizar para particionar redes de clase A o de clase B. Por ejemplo, la máscara 255.255.192.0 dividiría una red de clase B en 4 subredes de 16382 hosts (2 elevado a 14, menos 2) cada una.



Configuración de clientes
Supongamos que deseamos configurar el soporte de red para el equipo que viene en el siguiente esquema. Para ello debemos de establecer los siguientes parámetros:

Dirección IP
Máscara de red
Puerta de enlace
Servidores de resolución de nombres (DNS)

Normalmente estos parámetros son configurados dinámicamente mediante DHCP por el Router de salida.

No obstante también es posible su configuración de forma manual.



Enrutamiento en el cliente
Un parámetro de importancia capital en una intranet es la configuración de la ruta por defecto en los clientes, que les permitirá salir a Internet. Para cada cliente deberemos establecer una puerta de enlace o gateway que es la dirección IP por la que el tráfico de red puede acceder a Internet. En el ejemplo anterior esta IP es 192.168.1.1.

Dicha IP suele ser la IP interna (a menudo privada) del router. Dicha dirección y la dirección de todos los equipos clientes deben hallarse dentro de la misma red (en este caso 192.168.1.0)

Si la puerta de enlace no se halla configurada o está incorrectamente configurada en los clientes, es imposible que los equipos puedan comunicarse con Internet.

A continuación mostramos como configurar, en el cliente, la puerta de enlace haciendo uso del terminal de texto. Tanto en Windows como en Linux se hace uso del comando route (aunque su sintaxis es ligeramente diferente en cada caso).

Ver puerta de enlace configurada
Windows logo - 2012 derivative.svg
route print 


route
Borrar o añadir puerta de enlace
Windows logo - 2012 derivative.svg
route delete 0.0.0.0 mask 0.0.0.0 192.168.1.1
      add 


route del default gw 192.168.1.1
      add 
Configuración del soporte básico de red
Visualización de configuración actual
Podemos ver los parámetros de la red con los siguientes comandos:

Windows logo - 2012 derivative.svg
ipconfig /all            (IP/Máscara, Puerta de enlace, DNS)    


ifconfig                 (IP/Máscara)
route                    (Puerta de enlace)
cat /etc/resolv.conf     (DNS)    
Configuración dinámica de IP/Máscara, Puerta de Enlace y servidores DNS
Windows logo - 2012 derivative.svg
ipconfig /release    (Liberamos)           
ipconfig /renew      (Renovamos)

 
dhclient -r eth0    (Liberamos)
dhclient eth0       (Renovamos)    
Configuración estática de IP/Máscara, Puerta de Enlace y servidores DNS
Windows logo - 2012 derivative.svg
netsh
interface
ip

set address “Conexión de área local” static   \     
        192.168.1.30                          \
        255.255.255.0                         \
        192.168.1.1                           \ 
        1

set dns “Conexión de área local” static       \  
            8.8.8.8

commit
exit

  
ifconfig eth0 192.168.1.30 netmask 255.255.255.0    

route add default gw 192.168.1.1

echo “nameserver 8.8.8.8” >> /etc/resolv.conf
Comprobación básica (Windows y Linux)
Una vez configurado el soporte de red procederemos a comprobar su correcto funcionamiento. Para ello deben seguirse los siguientes pasos en el orden indicado. Si alguno de los pasos falla, deberemos de corregir el error antes de proseguir.


1. Comprobamos la pila TCP/IP del Sistema Operativo

        ping 127.0.0.1  
2. Comprobamos la tarjeta de red

        ping 192.168.1.30
3. Comprobamos las tablas de rutas

        route print        (Windows) 
        route              (Linux) 
4. Comprobamos el cable

        ping 192.168.1.1 
5. Comprobamos la salida a Internet

        ping 8.8.8.8
6. Comprobamos la resolución de nombres

        ping www.google.es 
Utilidades de red (Windows y Linux)
Para examinar equipos de la red
ettercap
Para examinar puertos abiertos de nuestro equipo
netstat
Para examinar puertos abiertos de otros equipos
nmap
Para examinar tráfico en una red de difusión
wireshark
Estándares
Protocolo IP
IP es el principal protocolo de la capa de red. Este protocolo define la unidad básica de transferencia de datos entre el origen y el destino, atravesando toda la red de redes. Además, el software IP es el encargado de elegir la ruta más adecuada por la que los datos serán enviados. Se trata de un sistema de entrega de paquetes (llamados datagramas IP) que tiene las siguientes características:

Es no orientado a conexión debido a que cada uno de los paquetes puede seguir rutas distintas entre el origen y el destino. Entonces pueden llegar duplicados o desordenados.
Es no fiable porque los paquetes pueden perderse, dañarse o llegar retrasados.
Nota: El protocolo IP está definido en la RFC 791

Formato del datagrama IP
El datagrama IP es la unidad básica de transferencia de datos entre el origen y el destino. Viaja en el campo de datos de las tramas físicas (recuérdese la trama Ethernet) de las distintas redes que va atravesando. Cada vez que un datagrama tiene que atravesar un router, el datagrama saldrá de la trama física de la red que abandona y se acomodará en el campo de datos de una trama física de la siguiente red. Este mecanismo permite que un mismo datagrama IP pueda atravesar redes distintas: enlaces punto a punto, redes ATM, redes Ethernet, redes Token Ring, etc. El propio datagrama IP tiene también un campo de datos: será aquí donde viajen los paquetes de las capas superiores.



Encabezado deldatagrama	Área de datos del datagrama IP	
Encabezado dela trama	Área de datos de la trama	Final de la trama




0	10	20	30
0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1
VERS	HLEN	Tipo de servicio	Longitud total
Identificación	Bandrs	Desplazaiento de fragmento
TTL	Protocolo	CRC cabecera
Dirección IP origen
Dirección IP destino
Opciones IP (si las hay)	Relleno
Datos
...
Campos del datagrama IP:

VERS (4 bits). Indica la versión del protocolo IP que se utilizó para crear el datagrama. Actualmente se utiliza la versión 4 (IPv4) aunque ya se están preparando las especificaciones de la siguiente versión, la 6 (IPv6).
HLEN (4 bits). Longitud de la cabecera expresada en múltiplos de 32 bits. El valor mínimo es 5, correspondiente a 160 bits = 20 bytes.
Tipo de servicio (Type Of Service). Los 8 bits de este campo se dividen a su vez en:
Prioridad (3 bits). Un valor de 0 indica baja prioridad y un valor de 7, prioridad máxima.
Los siguientes tres bits indican cómo se prefiere que se transmita el mensaje, es decir, son sugerencias a los encaminadores que se encuentren a su paso los cuales pueden tenerlas en cuenta o no.
Bit D (Delay). Solicita retardos cortos (enviar rápido).
Bit T (Throughput). Solicita un alto rendimiento (enviar mucho en el menor tiempo posible).
Bit R (Reliability). Solicita que se minimice la probabilidad de que el datagrama se pierda o resulte dañado (enviar bien).
Los siguiente dos bits no tienen uso.
Longitud total (16 bits). Indica la longitud total del datagrama expresada en bytes. Como el campo tiene 16 bits, la máxima longitud posible de un datagrama será de 65535 bytes.

Identificación (16 bits). Número de secuencia que junto a la dirección origen, dirección destino y el protocolo utilizado identifica de manera única un datagrama en toda la red. Si se trata de un datagrama fragmentado, llevará la misma identificación que el resto de fragmentos.
Banderas o indicadores (3 bits). Sólo 2 bits de los 3 bits disponibles están actualmente utilizados. El bit de Más fragmentos (MF) indica que no es el último datagrama. Y el bit de No fragmentar (NF) prohíbe la fragmentación del datagrama. Si este bit está activado y en una determinada red se requiere fragmentar el datagrama, éste no se podrá transmitir y se descartará.
Desplazamiento de fragmentación (13 bits). Indica el lugar en el cual se insertará el fragmento actual dentro del datagrama completo, medido en unidades de 64 bits. Por esta razón los campos de datos de todos los fragmentos menos el último tienen una longitud múltiplo de 64 bits. Si el paquete no está fragmentado, este campo tiene el valor de cero.
Tiempo de vida o TTL (8 bits). Número máximo de segundos que puede estar un datagrama en la red de redes. Cada vez que el datagrama atraviesa un router se resta 1 a este número. Cuando llegue a cero, el datagrama se descarta  y se devuelve un mensaje ICMP de tipo "tiempo excedido" para informar al origen de la incidencia.
Protocolo (8 bits). Indica el protocolo utilizado en el campo de datos: 1 para ICMP, 2 para IGMP, 6 para TCP y 17 para UDP.
CRC cabecera (16 bits). Contiene la suma de comprobación de errores sólo para la cabecera del datagrama. La verificación de errores de los datos corresponde a las capas superiores.
Dirección origen (32 bits). Contiene la dirección IP del origen.
Dirección destino (32 bits). Contiene la dirección IP del destino.
Opciones IP. Este campo no es obligatorio y especifica las distintas opciones solicitadas por el usuario que envía los datos (generalmente para pruebas de red y depuración).
Relleno. Si las opciones IP (en caso de existir) no ocupan un múltiplo de 32 bits, se completa con bits adicionales hasta alcanzar el siguiente múltiplo de 32 bits (recuérdese que la longitud de la cabecera tiene que ser múltiplo de 32 bits).
Fragmentación
Ya hemos visto que las tramas físicas tienen un campo de datos y que es aquí donde se transportan los datagramas IP. Sin embargo, este campo de datos no puede tener una longitud indefinida debido a que está limitado por el diseño de la red. El MTU de una red es la mayor cantidad de datos que puede transportar su trama física. El MTU de las redes Ethernet es 1500 bytes y el de las redes Token-Ring, 8192 bytes. Esto significa que una red Ethernet nunca podrá transportar un datagrama de más de 1500 bytes sin fragmentarlo.

Un encaminador (router) fragmenta un datagrama en varios si el siguiente tramo de la red por el que tiene que viajar el datagrama tiene un MTU inferior a la longitud del datagrama. Veamos con el siguiente ejemplo cómo se produce la fragmentación de un datagrama.



Supongamos que el host A envía un datagrama de 1400 bytes de datos (1420 bytes en total) al host B. El datagrama no tiene ningún problema en atravesar la red 1 ya que 1420 < 1500. Sin embargo, no es capaz de atravesar la red 2 (1420 >= 620). El router R1 fragmenta el datagrama en el menor número de fragmentos posibles que sean capaces de atravesar la red 2. Cada uno de estos fragmentos es un nuevo datagrama con la misma Identificación pero distinta información en el campo de Desplazamiento de fragmentación y el bit de Más fragmentos (MF). Veamos el resultado de la fragmentación:

Fragmento 1: Long. total = 620 bytes; Desp = 0; MF=1 (contiene los primeros 600 bytes de los datos del datagrama original)Fragmento 2: Long. total = 620 bytes; Desp = 600; MF=1 (contiene los siguientes 600 bytes de los datos del datagrama original)Fragmento 3: Long. total = 220 bytes; Desp = 1200; MF=0 (contiene los últimos 200 bytes de los datos del datagrama original)

El router R2 recibirá los 3 datagramas IP (fragmentos) y los enviará a la red 3 sin reensamblarlos. Cuando el host B reciba los fragmentos, recompondrá el datagrama original. Los encaminadores intermedios no reensamblan los fragmentos debido a que esto supondría una carga de trabajo adicional, a parte de memorias temporales. Nótese que el ordenador destino puede recibir los fragmentos cambiados de orden pero esto no supondrá ningún problema para el reensamblado del datagrama original puesto que cada fragmento guarda suficiente información.

Si el datagrama del ejemplo hubiera tenido su bit No fragmentar (NF) a 1, no hubiera conseguido atravesar el router R1 y, por tanto, no tendría forma de llegar hasta el host B. El encaminador R1 descartaría el datagrama.

CIDR ( Classless Inter-Domain Routing)
Encaminamiento Inter-Dominios sin Clases

Pronunciado como "cider" or "cedar", se introdujo en 1993 y representa la última mejora en el modo como se interpretan las direcciones IP. Su introducción permitió una mayor flexibilidad al dividir rangos de direcciones IP en redes separadas. De esta manera permitió:

Un uso más eficiente de las cada vez más escasas direcciones IPv4.
Un mayor uso de la jerarquía de direcciones ('agregación de prefijos de red'), disminuyendo la sobrecarga de los enrutadores principales de Internet para realizar el encaminamiento.
Los bloques CIDR IPv4 se identifican usando una sintaxis similar a la de las direcciones IPv4: cuatro números decimales separados por puntos, seguidos de una barra de división y un número de 0 a 32; A.B.C.D/N. El número tras la barra es la longitud de prefijo, contando desde la izquierda, y representa el número de bits comunes a todas las direcciones incluidas en el bloque CIDR.

Decimos que una dirección IP está incluida en un bloque CIDR, y que encaja con el prefijo CIDR, si los N bits iniciales de la dirección y el prefijo son iguales. Por tanto, para entender CIDR es necesario visualizar la dirección IP en binario. Dado que la longitud de una dirección IPv4 es fija, de 32 bits, un prefijo CIDR de N-bits deja 32 − N bits sin encajar, y hay 2(32 − N) combinaciones posibles con los bits restantes. Esto quiere decir que 2(32 − N) direcciones IPv4 encajan en un prefijo CIDR de N-bits.

Nótese que los prefijos CIDR cortos (números cercanos a 0) permiten encajar un mayor número de direcciones IP, mientras que prefijos CIDR largos (números cercanos a 32) permiten encajar menos direcciones IP. CIDR también se usa con direcciones IPv6, en las que la longitud del prefijo varia desde 0 a 128, debido a la mayor longitud de bit en las direcciones, con respecto a IPv4. En el caso de IPv6 se usa una sintaxis similar a la comentada: el prefijo se escribe como una dirección IPv6, seguida de una barra y el número de bits significativos.

CIDR usa máscaras de subred de longitud variable (VLSM) para asignar direcciones IP a subredes de acuerdo a las necesidades de cada subred. De esta forma, la división red/host puede ocurrir en cualquier bit de los 32 que componen la dirección IP. Este proceso puede ser recursivo, dividiendo una parte del espacio de direcciones en porciones cada vez menores, usando máscaras que cubren un mayor número de bits.

Las direcciones de red CIDR/VLSM se usan a lo largo y ancho de la Internet pública, y en muchas grandes redes privadas. El usuario normal no ve este uso puesto en práctica, al estar en una red en la que se usarán, por lo general, direcciones de red privadas recogidas en el RFC 1918. El término VLSM (Variable Lenght Subnet Mask - Máscara de Subred de Longitud Variable) se usa generalmente cuando se habla de redes privadas, mientras que CIDR se usa cuando se habla de Internet (red pública).

Tabla de conversión de prefijos CIDR
CIDR	Clase	Hosts*	Máscara
/32	1/256 C	1	255.255.255.255
/31	1/128 C	2	255.255.255.254
/30	1/64 C	4	255.255.255.252
/29	1/32 C	8	255.255.255.248
/28	1/16 C	16	255.255.255.240
/27	1/8 C	32	255.255.255.224
/26	1/4 C	64	255.255.255.192
/25	1/2 C	128	255.255.255.128
/24	1 C	256	255.255.255.000
/23	2 C	512	255.255.254.000
/22	4 C	1024	255.255.252.000
/21	8 C	2048	255.255.248.000
/20	16 C	4096	255.255.240.000
/19	32 C	8192	255.255.224.000
/18	64 C	16384	255.255.192.000
/17	128 C	32768	255.255.128.000
/16	256 C, 1 B	65536	255.255.000.000
/15	512 C, 2 B	131072	255.254.000.000
/14	1024 C, 4 B	262144	255.252.000.000
/13	2048 C, 8 B	524288	255.248.000.000
/12	4096 C, 16 B	1048576	255.240.000.000
/11	8192 C, 32 B	2097152	255.224.000.000
/10	16384 C, 64 B	4194304	255.192.000.000
/9	32768 C, 128B	8388608	255.128.000.000
/8	65536 C, 256B, 1 A	16777216	255.000.000.000
/7	131072 C, 512B, 2 A	33554432	254.000.000.000
/6	262144 C, 1024 B, 4 A	67108864	252.000.000.000
/5	524288 C, 2048 B, 8 A	134217728	248.000.000.000
/4	1048576 C, 4096 B, 16 A	268435456	240.000.000.000
/3	2097152 C, 8192 B, 32 A	536870912	224.000.000.000
/2	4194304 C, 16384 B, 64 A	1073741824	192.000.000.000
/1	8388608 C, 32768 B, 128 A	2147483648	128.000.000.000
(*) En la práctica hay que restar 2 a este número. La dirección menor (más baja - todos los bits de host a 0) del bloque se usa para identificar a la propia red (toda la red), y la dirección mayor (la más alta - todos los bits de host a 1) se usa como dirección de broadcast. Por tanto, en un bloque CIDR /24 podríamos disponer de 28 − 2 = 254 direcciones IP para asignar a dispositivos.


Otro beneficio de CIDR es la posibilidad de agregar prefijos de encaminamiento, un proceso conocido como "supernetting". Una dirección IP puede encajar en varios prefijos CIDR de longitudes diferentes. Por ejemplo, dieciséis redes /24 contíguas pueden ser agregadas y publicadas en los enrutadores de Internet como una sola ruta /20 (si los primeros 20 bits de sus respectivas redes coinciden). Dos redes /20 contiguas pueden ser agregadas en una /19, etc...

Esto permite una reducción significativa en el número de rutas que los enrutadores en Internet tienen que conocer (y una reducción de memoria, recursos, etc...) y previene una explosión de tablas de encaminamiento, que podría sobrecargar a los routers e impedir la expansión de Internet en el futuro.

Superredes
Para muchas organizaciones una dirección de red de clase C es poco.

Solución: Agrupar direcciones consecutivas (tienen un prefijo común) de redes de clase C para asignarlas a una organización.

Esto permite asignar espacio de direcciones a organizaciones con redes de tamaño medio, evitando utilizar direcciones de clase B.

Ejemplo de agrupamiento:

193.40.128.0 = 11000001 00101000 10000000 00000000
193.40.129.0 = 11000001 00101000 10000001 00000000
...          = ...                                 
193.40.142.0 = 11000001 00101000 10001110 00000000
193.40.143.0 = 11000001 00101000 10001111 00000000
La dirección de red/máscara sería 193.40.128.0/20 ( 255.255.240.0)

Máscara en binario: 11111111  11111111  11110000  00000000.     

Existen 212-2 (4096-2) direcciones IP para hosts

Protocolo ARP
Dentro de una misma red, las máquinas se comunican enviándose tramas físicas. Las tramas Ethernet contienen campos para las direcciones físicas de origen y destino (6 bytes cada una):



8 bytes	6 bytes	6 bytes	2 bytes	64-1500 bytes	4 bytes
Preámbulo	Dirección físicadestino	Dirección físicaorigen	Tipo de trama	Datos de la trama	CRC
El problema que se nos plantea es cómo podemos conocer la dirección física de la máquina destino. El único dato que se indica en los datagramas es la dirección IP de destino. ¿Cómo se pueden entregar entonces estos datagramas? Necesitamos obtener la dirección física de un ordenador a partir de su dirección IP. Esta es justamente la misión del protocolo ARP (Address Resolution Protocol, protocolo de resolución de direcciones).

ARP se utiliza en redes con mecanismos de difusión (Ethernet, FDDI, Token-Ring, etc.)

Nota: El protocolo ARP está definido en RFC 826, RFC 1042 y RFC 1390



Host	Red	Dirección IP	Dirección física
A	Red 1	192.168.0.10	00-60-52-0B-B7-7D
R1	192.168.0.1	00-E0-4C-AB-9A-FF
Red 2	10.10.0.1	A3-BB-05-17-29-D0
B	10.10.0.7	00-E0-4C-33-79-AF
R2	10.10.0.2	B2-42-52-12-37-BE
Red 3	200.3.107.1	00-E0-89-AB-12-92
C	200.3.107.73	A3-BB-08-10-DA-DB
D	200.3.107.200	B2-AB-31-07-12-93

Vamos a retomar el ejemplo introductorio de este Capítulo. El host A envía un datagrama con origen 192.168.0.10 y destino 10.10.0.7 (B). Como el host B se encuentra en una red distinta al host A, el datagrama tiene que atravesar el router 192.168.0.1 (R1). Se necesita conocer la dirección física de R1.

Es entonces cuando entra en funcionamiento el protocolo ARP: A envía un mensaje ARP a todas las máquinas de su red preguntando "¿Cuál es la dirección física de la máquina con dirección IP 192.168.0.1?". La máquina con dirección 192.168.0.1 (R1) advierte que la pregunta está dirigida a ella y responde a A con su dirección física (00-E0-4C-AB-9A-FF). Entonces A envía una trama física con origen 00-60-52-0B-B7-7D y destino 00-E0-4C-AB-9A-FF conteniendo el datagrama (origen 192.168.0.10 y destino 10.10.0.7). Al otro lado del router R2 se repite de nuevo el proceso para conocer la dirección física de B y entregar finalmente el datagrama a B. El mismo datagrama ha viajado en dos tramas físicas distintas, una para la red 1 y otra para la red 2.

Observemos que las preguntas ARP son de difusión (se envían a todas las máquinas). Estas preguntas llevan además la dirección IP y dirección física de la máquina que pregunta. La respuesta se envía directamente a la máquina que formuló la pregunta.



Tabla ARP (caché ARP)
Cada ordenador almacena una tabla de direcciones IP y direcciones físicas. Cada vez que formula una pregunta ARP y le responden, inserta una nueva entrada en su tabla. La primera vez que C envíe un mensaje a D tendrá que difundir previamente una pregunta ARP, tal como hemos visto. Sin embargo, las siguientes veces que C envíe mensajes a D ya no será necesario realizar nuevas preguntas puesto que C habrá almacenado en su tabla la dirección física de D. Sin embargo, para evitar incongruencias en la red debido a posibles cambios de direcciones IP o adaptadores de red, se asigna un tiempo de vida de cierto número de segundos a cada entrada de la tabla. Cuando se agote el tiempo de vida de una entrada, ésta será eliminada de la tabla.

Las tablas ARP reducen el tráfico de la red al evitar preguntas ARP innecesarias. Pensemos ahora en distintas maneras para mejorar el rendimiento de la red. Después de una pregunta ARP, el destino conoce las direcciones IP y física del origen. Por lo tanto, podría insertar la correspondiente entrada en su tabla. Pero no sólo eso, sino que todas las estaciones de la red escuchan la pregunta ARP: podrían insertar también las correspondientes entradas en sus tablas. Como es muy probable que otras máquinas se comuniquen en un futuro con la primera, habremos reducido así el tráfico de la red aumentando su rendimiento.

Esto que hemos explicado es para comunicar dos máquinas conectadas a la misma red. Si la otra máquina no estuviese conectada a la misma red, sería necesario atravesar uno o más routers hasta llegar al host destino. La máquina origen, si no la tiene en su tabla, formularía una pregunta ARP solicitando la dirección física del router y le transferiría a éste el mensaje. Estos pasos se van repitiendo para cada red hasta llegar a la máquina destino.

Protocolo ICMP
Debido a que el protocolo IP no es fiable, los datagramas pueden perderse o llegar defectuosos a su destino. El protocolo ICMP (Internet Control Message Protocol, protocolo de mensajes de control y error) se encarga de informar al origen si se ha producido algún error durante la entrega de su mensaje. Pero no sólo se encarga de notificar los errores, sino que también transporta distintos mensajes de control.

El protocolo ICMP únicamente informa de incidencias en la red pero no toma ninguna decisión. Esto será responsabilidad de las capas superiores. Los mensajes ICMP viajan en el campo de datos de un datagrama IP, como se puede apreciar en el siguiente esquema:



Tipo	Datos ICMP	
Encabezado del datagrama	Área de datos del datagrama IP	
Encabezado de la trama	Área de datos de la trama	Final de la trama
Debido a que el protocolo IP no es fiable puede darse el caso de que un mensaje ICMP se pierda o se dañe. Si esto llega a ocurrir no se creará un nuevo mensaje ICMP sino que el primero se descartará sin más.

Los mensajes ICMP comienzan con un campo de 8 bits que contiene el tipo de mensaje, según se muestra en la tabla siguiente. El resto de campos son distintos para cada tipo de mensaje ICMP.

Nota: El formato y significado de cada mensaje ICMP está documentado en la RFC 792



Campo de tipo	Tipo de mensaje ICMP
0
Respuesta de eco (Echo Reply)
3
Destino inaccesible (Destination Unreachable)
4
Disminución del tráfico desde el origen (Source Quench)
5
Redireccionar (cambio de ruta) (Redirect)
8
Solicitud de eco (Echo)
11
Tiempo excedido para un datagrama (Time Exceeded)
12
Problema de Parámetros (Parameter Problem)
13
Solicitud de marca de tiempo (Timestamp)
14
Respuesta de marca de tiempo (Timestamp Reply)
15
Solicitud de información (obsoleto) (Information Request)
16
Respuesta de información (obsoleto) (Information Reply)
17
Solicitud de máscara (Addressmask)
18
Respuesta de máscara (Addressmask Reply)
Solicitud y respuesta de eco
Los mensajes de solicitud y respuesta de eco, tipos 8 y 0 respectivamente, se utilizan para comprobar si existe comunicación entre 2 hosts a nivel de la capa de red. Estos mensajes comprueban que las capas física (cableado), acceso al medio (tarjetas de red) y red (configuración IP) están correctas. Sin embargo, no dicen nada de las capas de transporte y de aplicación las cuales podrían estar mal configuradas; por ejemplo, la recepción de mensajes de correo electrónico puede fallar aunque exista comunicación IP con el servidor de correo.



La orden PING envía mensajes de solicitud de eco a un host remoto e informa de las respuestas. Veamos su funcionamiento, en caso de no producirse incidencias en el camino.
A envía un mensaje ICMP de tipo 8 (Echo) a B
B recibe el mensaje y devuelve un mensaje ICMP de tipo 0 (Echo Reply) a A
A recibe el mensaje ICMP de B y muestra el resultado en pantalla


C:\>ping 172.20.9.7 -n 1
Haciendo ping a 172.20.9.7 con 32 bytes de datos:
Respuesta desde 172.20.9.7: bytes=32 tiempo<10ms TDV=128

En la orden anterior hemos utilizado el parámetro "-n 1" para que el host A únicamente envíe 1 mensaje de solicitud de eco. Si no se especifica este parámetro se enviarían 4 mensajes (y se recibirían 4 respuestas).

Si el host de destino no existiese o no estuviera correctamente configurado recibiríamos un mensaje ICMP de tipo 11 (Time Exceeded).

C:\>ping 192.168.0.6 -n 1
Haciendo ping a 192.168.0.6 con 32 bytes de datos:
Tiempo de espera agotado. 

Si tratamos de acceder a un host de una red distinta a la nuestra y no existe un camino para llegar hasta él, es decir, los routers no están correctamente configurados o estamos intentando acceder a una red aislada o inexistente, recibiríamos un mensaje ICMP de tipo 3 (Destination Unreachable).

C:\>ping 1.1.1.1 -n 1
Haciendo ping a 1.1.1.1 con 32 bytes de datos:
Respuesta desde 192.168.0.1: Host de destino inaccesible. 

Utilización de PING para diagnosticar errores en una red aislada
C:\>ping 192.168.1.12

Respuesta. El cableado entre A y B, las tarjetas de red de A y B, y la configuración IP de A y B están correctos.
Tiempo de espera agotado. Comprobar el host B y el cableado entre A y B.
Host de destino inaccesible. Comprobar las direcciones IP y máscaras de subred de A y B porque no pertenecen a la misma red.
Error. Probablemente estén mal instalados los protocolos TCP/IP del host A. Probar C:\>ping 127.0.0.1 para asegurarse.
Nota: El comando ping 127.0.0.1 informa de si están correctamente instalados los protocolos TCP/IP en nuestro host. No informa de si la tarjeta de red de nuestro host está correcta.

Utilización de PING para diagnosticar errores en una red de redes.
A continuación veremos un ejemplo para una red de redes formada por dos redes (1 solo router). La idea es la misma para un mayor número de redes y routers.



C:\>ping 10.100.5.1

Respuesta. El cableado entre A y B, las tarjetas de red de A, R1 y B, y la configuración IP de A, R1 y B están correctos. El router R1 permite el tráfico de datagramas IP en los dos sentidos.
Tiempo de espera agotado. Comprobar el host B y el cableado entre R1 y B. Para asegurarnos que el router R1 está funcionando correctamente haremos C:\>ping 192.168.1.1
Host de destino inaccesible. Comprobar el router R1 y la configuración IP de A (probablemente la puerta de salida no sea 192.168.1.1). Recordemos que la puerta de salida (gateway) de una red es un host de su propia red que se utiliza para salir a otras redes.
Error. Probablemente estén mal instalados los protocolos TCP/IP del host A. Probar C:\>ping 127.0.0.1 para asegurarse.
En el caso producirse errores de comunicación en una red de redes con más de un router (Internet es el mejor ejemplo), se suele utilizar el comando PING para ir diagnosticando los distintos routers desde el destino hasta el origen y descubrir así si el fallo es responsabilidad de la red de destino, de una red intermedia o de nuestra red.

Nota: Algunos hosts en Internet tienen deshabilitadas las respuestas de eco (mensajes ICMP tipo 0) como medida de seguridad. En estos casos hay que utilizar otros mecanismos para detectar si responde (por ejemplo, la apertura de conexión a un puerto)

Mensajes ICMP de tiempo excedido
Los datagramas IP tienen un campo TTL (tiempo de vida) que impide que un mensaje esté dando vueltas indefinidamente por la red de redes. El número contenido en este campo disminuye en una unidad cada vez que el datagrama atraviesa un router. Cuando el TTL de un datagrama llega a 0, éste se descarta y se envía un mensaje ICMP de tipo 11 (Time Exceeded) para informar al origen.

Los mensajes ICMP de tipo 11 se pueden utilizar para hacer una traza del camino que siguen los datagramas hasta llegar a su destino. ¿Cómo? Enviando una secuencia de datagramas con TTL=1, TTL=2, TTL=3, TTL=4, etc... hasta alcanzar el host o superar el límite de saltos (30 si no se indica lo contrario). El primer datagrama caducará al atravesar el primer router y se devolverá un mensaje ICMP de tipo 11 informando al origen del router que descartó el datagrama. El segundo datagrama hará lo propio con el segundo router y así sucesivamente. Los mensajes ICMP recibidos permiten definir la traza.



La orden TRACERT (traceroute en entornos Unix) hace una traza a un determinado host. TRACERT funciona enviando mensajes ICMP de solicitud de eco con distintos TTL; traceroute, en cambio, envía mensajes UDP. Si la comunicación extremo a extremo no es posible, la traza nos indicará en qué punto se ha producido la incidencia. Existen algunas utilidades en Internet, como Visual Route, que conocen la localización geográfica de los principales routers de Internet. Esto permite dibujar en un mapamundi el recorrido que siguen los datagramas hasta llegar a un host.
C:\>tracert 130.206.1.2

Traza a la dirección sun.rediris.es [130.206.1.2]
sobre un máximo de 30 saltos:

 1   1 ms   1 ms   1 ms PROXY [192.168.0.1]
 2 122 ms 118 ms 128 ms MADR-X27.red.retevision.es [62.81.1.102]
 3 143 ms 232 ms 147 ms MADR-R2.red.retevision.es [62.81.1.92]
 4 130 ms 124 ms 246 ms MADR-R16.red.retevision.es [62.81.3.8]
 5 590 ms 589 ms 431 ms MADR-R12.red.retevision.es [62.81.4.101]
 6 612 ms 640 ms 124 ms MADR-R10.red.retevision.es [62.81.8.130]
 7 259 ms 242 ms 309 ms 193.149.1.28
 8 627 ms 752 ms 643 ms 213.0.251.42
 9 137 ms 117 ms 118 ms 213.0.251.142
10 109 ms 105 ms 110 ms A1-2-1.EB-Madrid00.red.rediris.es [130.206.224.81]
11 137 ms 119 ms 122 ms A0-0-0-1.EB-Madrid3.red.rediris.es [130.206.224.86]
12 109 ms 135 ms 115 ms sun.rediris.es [130.206.1.2]

Traza completa. 

Ejemplo de Visual Route a una dirección IP de Taiwan (203.69.112.12):



IPv6
Diseñado por Steve Deering de Xerox PARC y Craig Mudge, IPv6 está destinado a sustituir al estándar IPv4, cuyo límite en el número de direcciones de red admisibles está empezando a restringir el crecimiento de Internet y su uso, especialmente en China, India, y otros países asiáticos densamente poblados. Pero el nuevo estándar mejorará el servicio globalmente; por ejemplo, proporcionando a futuras celdas telefónicas y dispositivos móviles con sus direcciones propias y permanentes. Al día de hoy se calcula que las dos terceras partes de las direcciones que ofrece IPv4 ya están asignadas.

IPv4 soporta 4.294.967.296 (232) direcciones de red diferentes, un número inadecuado para dar una dirección a cada persona del planeta, y mucho menos para cada coche, teléfono, PDA o tostadora; mientras que IPv6 soporta 340.282.366.920.938.463.463.374.607.431.768.211.456 (2128 ó 340 sextillones) direcciones —cerca de 4,3 × 1020 (430 trillones) direcciones por cada pulgada cuadrada (6,7 × 1017 ó 670 mil billones direcciones/mm2) de la superficie de La Tierra.

Adoptado por el Internet Engineering Task Force (IETF) en 1994 (cuando era llamado "IP Next Generation" o IPng), IPv6 cuenta con un pequeño porcentaje de las direcciones públicas de Internet, que todavía están dominadas por IPv4. La adopción de IPv6 ha sido frenada por la traducción de direcciones de red (NAT), que alivia parcialmente el problema de la falta de direcciones IP. Pero NAT hace difícil o imposible el uso de algunas aplicaciones P2P, como son la voz sobre IP (VoIP) y juegos multiusuario. Además, NAT rompe con la idea originaria de Internet donde todos pueden conectarse con todos. Actualmente, el gran catalizador de IPv6 es la capacidad de ofrecer nuevos servicios, como la movilidad, Calidad de Servicio (QoS), privacidad, etc. El gobierno de los Estados Unidos ha ordenado el despliegue de IPv6 por todas sus agencias federales para el año 2008.

Se espera que IPv4 se siga soportando hasta por lo menos el 2025, dado que hay muchos dispositivos heredados que no se migrarán a IPv6 nunca y que seguirán siendo utilizados por mucho tiempo.

IPv6 es la segunda versión del Protocolo de Internet que se ha adoptado para uso general. También hubo un IPv5, pero no fue un sucesor de IPv4; mejor dicho, fue un protocolo experimental orientado al flujo de streaming que intentaba soportar voz, video y audio.

Direccionamiento IPv6
El cambio más drástico de IPv4 a IPv6 es la longitud de las direcciones de red. Las direcciones IPv6, definidas en el RFC 2373 y RFC 2374, son de 128 bits; esto corresponde a 32 dígitos hexadecimales, que se utilizan normalmente para escribir las direcciones IPv6, como se describe en la siguiente sección.

El número de direcciones IPv6 posibles es de 2128 ≈ 3.4 x 1038. Este número puede también representarse como 1632, con 32 dígitos hexadecimales, cada uno de los cuales puede tomar 16 valores (véase combinatoria).

En muchas ocasiones las direcciones IPv6 están compuestas por dos partes lógicas: un prefijo de 64 bits y otra parte de 64 bits que corresponde al identificador de interfaz, que casi siempre se genera automáticamente a partir de la dirección MAC de la interfaz a la que está asignada la dirección.

Notación para las direcciones IPv6
Las direcciones IPv6, de 128 bits de longitud, se escriben como ocho grupos de cuatro dígitos hexadecimales.

Por ejemplo,

2001:0db8:85a3:08d3:1319:8a2e:0370:7334
es una dirección IPv6 válida.

Si un grupo de cuatro dígitos es nulo (es decir, toma el valor "0000"), puede ser comprimido. Por ejemplo,

2001:0db8:85a3:0000:1319:8a2e:0370:7344  
es la misma dirección que

2001:0db8:85a3::1319:8a2e:0370:7344
Siguiendo esta regla, si más de dos grupos consecutivos son nulos, pueden comprimirse como "::". Si la dirección tiene más de una serie de grupos nulos consecutivos la compresión solo en uno de ellos. Así,

2001:0DB8:0000:0000:0000:0000:1428:57ab
2001:0DB8:0000:0000:0000::1428:57ab
2001:0DB8:0:0:0:0:1428:57ab
2001:0DB8:0::0:1428:57ab
2001:0DB8::1428:57ab
son todas válidas y significan lo mismo, pero

2001::25de::cade
es inválido porque no queda claro cuantos grupos nulos hay en cada lado.

Los ceros iniciales en un grupo pueden ser omitidos. Así,

2001:0DB8:02de::0e13
es lo mismo que

2001:DB8:2de::e13 
Si la dirección es una dirección IPv4 camuflada, los últimos 32 bits pueden escribirse en base decimal; así,

::ffff:192.168.89.9 es lo mismo que  
::ffff:c0a8:5909, pero no lo mismo que 
::192.168.89.9 o 
::c0a8:5909. 
El formato ::ffff:1.2.3.4 se denomina dirección IPv4 mapeada, y el formato ::1.2.3.4 dirección IPv4 compatible.

Las direcciones IPv4 pueden ser transformadas fácilmente al formato IPv6. Por ejemplo, si la dirección decimal IPv4 es 135.75.43.52 (en hexadecimal, 0x874B2B34), puede ser convertida a 0000:0000:0000:0000:0000:0000:874B:2B34 o ::874B:2B34. Entonces, uno puede usar la notación mixta dirección IPv4 compatible, en cuyo caso la dirección debería ser ::135.75.43.52. Este tipo de dirección IPv4 compatible casi no está siendo utilizada en la práctica, aunque los estándares no la han declarado obsoleta.

Tipos de direcciones
IPv6 tiene tres tipos de direcciones, que se pueden clasificar según el tipo y alcance:



Las direcciones UNICAST. Se envía un paquete a una interfaz.
Las direcciones de MULTICAST (multidifusión). Se envía un paquete de múltiples interfaces.
Las direcciones ANYCAST. Se envía un paquete a la más cercana de múltiples interfaces (en términos de distancia de enrutamiento).
No hay direcciones de broadcast en IPv6. Las direcciones de multidifusión han reemplazado esta función.


Las direcciones Unicast y Anycast en IPv6 tienen los siguientes ámbitos (para las direcciones multicast, el ámbito está integrado en la estructura de dirección):



De enlace local. El ámbito es el enlace local (nodos de la misma subred).
Global. El alcance es global (direcciones de Internet IPv6).
Además, IPv6 tiene direcciones especiales como la dirección de bucle invertido. El ámbito de una dirección especial depende del tipo de dirección especial.

Gran parte del espacio de direcciones IPv6 está sin asignar.

Tabla muy resumida de la asignación por tipo de dirección.



Tipo de dirección	Prefijo binario	Notación IPv6
Sin especificar	00 . . . 0 (128 bits)	 ::/128
Loopback	00 . . . 1 (128 bits)	 ::1/128
Multicast	11111111 . . .	FF00::/8
Link-local unicast	1111111010 . . .	FE80::/10
Site-local unicast (obsoleto)	1111111011 . . .	FEC0::/10
Local unicast	1111110 . . .	FC00::/7
Global unicast	001 . . .	2000::/3
Paquetes IPv6
Un paquete en IPv6 está compuesto principalmente de dos partes: la cabecera y los datos.

La cabecera está en los primeros 40 bytes del paquete y contiene las direcciones de origen y destino (128 bits cada una), la versión de IP (4 bits), la clase de tráfico (8 bits, Prioridad del Paquete), etiqueta de flujo (20 bits, manejo de la Calidad de Servicio), longitud del campo de datos (16 bits), cabecera siguiente (8 bits), y límite de saltos (8 bits, Tiempo de Vida). Después viene el campo de datos, con los datos que transporta el paquete, que puede llegar a 64k de tamaño en el modo normal, o más con la opción "jumbo payload".

Despliegue de IPv6
Mecanismos de transición a IPv6

El cambio de IPv4 a IPv6 ya ha comenzado. Durante 20 años se espera que convivan ambos protocolos y que la implantación de IPv6 sea paulatina. Existe una serie de mecanismos que permitirán la convivencia y la migración progresiva tanto de las redes como de los equipos de usuario. En general, los mecanismos de transición pueden clasificarse en tres grupos:

Pila dual
Túneles
Traducción
Pila dual

La pila dual hace referencia a una solución de nivel IP con pila dual (RFC 2893), que implementa las pilas de ambos protocolos, IPv4 e IPv6, en cada nodo de la red. Cada nodo de pila dual en la red tendrá dos direcciones de red, una IPv4 y otra IPv6.

Pros: Fácil de desplegar y extensamente soportado.
Contras: La topología de red requiere dos tablas de encaminamiento y dos procesos de encaminamiento. Cada nodo en la red necesita tener actualizadas las dos pilas.
TúnelesLos túneles permiten conectarse a redes IPv6 "saltando" sobre redes IPv4. Estos túneles trabajan encapsulando los paquetes IPv6 en paquetes IPv4 teniendo como siguiente capa IP el protocolo número 41, y de ahí el nombre proto-41. De esta manera, los paquetes IPv6 pueden ser enviados sobre una infraestructura IPv4. Hay muchas tecnologías de túneles disponibles. La principal diferencia está en el método que usan los nodos encapsuladores para determinar la dirección a la salida del túnel.

Estas tecnologías incluyen túneles 6to4, ISATAP, y Teredo que proporcionan la asignación de direcciones y túnel automático para el tráfico IPv6 Unicast host-to-host cuando los hosts de IPv6 deben atravesar redes IP4 para llegar a otras redes IPv6.

Teredo es una tecnología de transición que proporciona conectividad IPv6 a hosts que soportan IPv6 pero que se encuentran conectados a Internet mediante una red IPv4. Comparado con otros protocolos similares, la característica que lo distingue es que es capaz de realizar su función incluso detrás de dispositivos NAT, como los routers domésticos.

Teredo opera usando un protocolo de túneles independiente de la plataforma diseñado para proporcionar conectividad IPv6 encapsulando los datagramas IPv6 dentro de datagramas UDP IPv4. Estos datagramas pueden ser encaminados en Internet IPv4 y a través de dispositivos NAT. Otros nodos Teredo, también llamados Teredo relays, que tienen acceso a la red IPv6, reciben los paquetes, los desencapsulan y los encaminan.

Teredo está diseñado como una tecnología de transición con el objetivo de ser una medida temporal. En el largo plazo, todos los hosts IPv6 deberían usar la conectividad IPv6 nativa y desactivar Teredo cuando la conectividad IPv6 esté disponible.

Teredo fue desarrollado por Christian Huitema en Microsoft y fue estandarizado por la IETF como RFC 4380. El servidor teredo escucha en el puerto UDP 3544.

El protocolo de túneles IPv6 sobre IPv4 más común, 6to4, requiere que el final del túnel tenga una dirección IPv4 pública. Sin embargo, actualmente muchos hosts se conectan a Internet IPv4 a través de uno o varios dispositivos NAT, por lo general por el agotamiento de las direcciones IPv4. En esta situación, la única dirección IPv4 pública se asigna al dispositivo NAT y es necesario que el protocolo 6to4 esté implementado en este dispositivo. Muchos de los dispositivos NAT usados actualmente no pueden ser actualizados para implementar 6to4 por razones técnicas o económicas.

Teredo soluciona este problema encapsulando paquetes IPv6 dentro de datagramas UDP IPv4, los cuales pueden ser reenviados correctamente por NATs. Por lo tanto los hosts IPv6 que se encuentran detrás de dispositivos NAT pueden usar los túneles Teredo incluso si no disponen de una dirección IPv4 pública. Un host que implemente Teredo puede tener conectividad IPv6 sin cooperación por parte de la red local o del dispositivo NAT.

Teredo pretende ser una medida temporal. En el largo plazo todos los hosts deberían usar la conectividad nativa IPv6. El protocolo Teredo incluye una disposición para el proceso de extinción del protocolo: "Una implementación Teredo debería proporcionar una forma para dejar de usar la conectividad Teredo cuando IPv6 haya madurado y la conectividad esté disponible usando un mecanismo menos frágil".

Miredo es un cliente libre de túneles Teredo diseñado para permitir conectividad IPv6 a ordenadores que se encuentran en redes IPv4 y que no tienen acceso directo a una red IPv6.

Miredo está incluido en muchas distribuciones Linux y BSD y también está disponible para las versiones recientes de Mac OS X.

Incluye implementaciones de los tres componentes de especificación Teredo: cliente, relay y servidor.

Está liberado bajo los términos de la licencia GNU General Public License, Miredo es software libre.


Traducción

La traducción es necesaria cuando un nodo solo IPv4 intenta comunicar con un nodo solo IPv6.

Actualmente el protocolo IPv6 está soportado en la mayoría de los sistemas operativos modernos, en algunos casos como una opción de instalación. Linux, Solaris, Mac OS, OpenBSD, FreeBSD, Windows (2k, CE) y Symbian (dispositivos móviles) son sólo algunos de los sistemas operativos que pueden funcionar con IPv6.

Dispositivos
Routers
Un router —también conocido enrutador o encaminador de paquetes—es un dispositivo que proporciona conectividad a nivel de red o nivel tres en el modelo OSI. Su función principal consiste en enviar o encaminar paquetes de datos de una red a otra, es decir, interconectar subredes, entendiendo por subred un conjunto de máquinas IP que se pueden comunicar sin la intervención de un encaminador.





Conexiones
Los tres tipos básicos de conexiones de un router son:

interfaces LAN
interfaces WAN
puertos de gestión
Las interfaces LAN permiten que el router pueda conectarse a la red de área local. Esto es por lo general algún tipo de Ethernet. Sin embargo, podría haber alguna otra tecnología LAN tales como Token Ring o modo de transferencia asíncrono (ATM).

Las conexiones de red de área amplia proporcionan conexiones a través de un proveedor de servicio a un sitio lejano o con Internet. Estos pueden ser conexiones en serie o cualquier número de otras interfaces WAN. Con algunos tipos de interfaces WAN, se requiere un dispositivo externo, para conectar el router a la conexión local del proveedor de servicios. Con otros tipos de conexiones WAN, el router puede estar conectado directamente al proveedor de servicios.

La función de los puertos de gestión es diferente de las demás conexiones. Las conexiones LAN y WAN proporcionan conexiones de red a través del cual se transmiten los paquetes. El puerto de gestión proporciona una conexión basada en texto para la configuración y solución de problemas del enrutador. Las interfaces de administración comunes son la consola y el puerto auxiliar. Estos son puertos serie asíncronos EIA- 232. Se conectan a un puerto de comunicaciones en un ordenador. El equipo debe ejecutar un programa de emulación de terminal para proporcionar una sesión basada en texto con el router. A través de esta sesión el administrador de red puede administrar el dispositivo.

Almacenamiento
ROM

La memoria de solo lectura (ROM) se utiliza para almacenar de forma permanente el código de diagnóstico de inicio (Monitor de ROM). Las tareas principales de la ROM son el diagnóstico del hardware durante el arranque del router y la carga del software IOS de Cisco desde la memoria flash a la RAM. Algunos routers también tienen una versión más básica del IOS que puede usarse como fuente alternativa de arranque. Las memorias ROM no se pueden borrar. Sólo pueden actualizarse reemplazando los chips de ROM.

RAM

La memoria de acceso aleatorio (RAM) se usa para la información de las tablas de enrutamiento, el caché de conmutación rápida, la configuración actual y las colas de paquetes. En la mayoría de los routers, la RAM proporciona espacio de tiempo de ejecución para el software IOS de Cisco y sus subsistemas. Por lo general, la RAM se divide de forma lógica en memoria del procesador principal y memoria compartida de entrada / salida (I/O). Las interfaces de almacenamiento temporal de los paquetes comparten la memoria de I/O compartida. El contenido de la RAM se pierde cuando se apaga la unidad. En general, la RAM es una memoria de acceso aleatorio dinámica (DRAM) y puede actualizarse agregando más módulos de memoria en línea doble (DIMM).

Memoria flash

La memoria flash se utiliza para almacenar una imagen completa del software IOS de Cisco. Normalmente el router adquiere el IOS por defecto de la memoria flash. Estas imágenes pueden actualizarse cargando una nueva imagen en la memoria flash. El IOS puede estar comprimido o no. En la mayoría de los routers, una copia ejecutable del IOS se transfiere a la RAM durante el proceso de arranque*. En otros routers, el IOS puede ejecutarse directamente desde la memoria flash. Agregando o reemplazando los módulos de memoria en línea simples flash (SIMMs) o las tarjetas PCMCIA se puede actualizar la cantidad de memoria flash.

NVRAM

La memoria de acceso aleatorio no volátil (NVRAM) se utiliza para guardar la configuración de inicio. En algunos dispositivos, la NVRAM se implementa utilizando distintas memorias de solo lectura programables, que se pueden borrar electrónicamente (EEPROM).En otros dispositivos, se implementa en el mismo dispositivo de memoria flash desde donde se argó el código de arranque. En cualquiera de los casos, estos dispositivos retienen sus contenidos cuando se apaga la unidad.

Proceso de arranque de un router
El proceso de arranque está conformado por cuatro etapas principales:

1. Ejecución de la POST

La prueba de autocomprobación de encendido (POST) es un proceso común que ocurre en casi todas las computadoras durante el arranque. El proceso de POST se utiliza para probar el hardware del router. Cuando se enciende el router, el software en el chip de la ROM ejecuta el POST. Durante esta autocomprobación, el router ejecuta diagnósticos desde la ROM a varios componentes de hardware, entre ellos la CPU, la RAM y la NVRAM. Después de completarse la POST, el router ejecuta el programa bootstrap.

2. Carga del programa bootstrap

Después de la POST, el programa bootstrap se copia de la ROM a la RAM. Una vez en la RAM, la CPU ejecuta las instrucciones del programa bootstrap. La tarea principal del programa bootstrap es ubicar al IOS y cargarlo en la RAM.

3. Ubicación y carga del IOS

El IOS normalmente se almacena en la memoria flash, pero también puede almacenarse en otros lugares como un servidor TFTP (Trivial File Transfer Protocol).

Si no se puede encontrar una imagen IOS completa, se copia una versión más básica del IOS de la ROM a la RAM. Esta versión del IOS se usa para ayudar a diagnosticar cualquier problema y puede usarse para cargar una versión completa del IOS en la RAM.

Algunos de los routers más antiguos ejecutan el IOS directamente desde la memoria flash, pero los modelos actuales copian el IOS en la RAM para que la CPU lo ejecute.

4. Ubicación y carga del archivo de configuración

Ubicación del archivo de configuración de inicio. Después de cargar el IOS, el programa bootstrap busca en la NVRAM el archivo de configuración de inicio, conocido como startup-config. El archivo contiene los parámetros y comandos de configuración previamente guardados, entre ellos:

direcciones de interfaz
información de enrutamiento
contraseñas
cualquier otra configuración guardada por el administrador de red
Si el archivo de configuración de inicio, startup-config, se encuentra en la NVRAM, se copia en la RAM como el archivo de configuración en ejecución, running-config.

A partir de aquí podemos conectar al router y según la plataforma y el IOS, el router podrá realizar diferentes tareas.

Actividades
Actividades de conceptos básicos
Imagina que te dan un router y te piden que lo configures. Indica los pasos que debes seguir para tener acceso a él.
Visita la página http://www.tp-link.com/en/support/emulators/ y elige 1 router. Haz un pequeño manual donde se explique las distintas opciones de estado y configuración de las que dispone.
Hemos contratado un ADSL con PepePhone. Nos sale más barato que la competencia, además si disponemos de router podemos utilizarlo. Realiza la configuración del router tal como nos indica la empresa:
Parámetros obligatorios (en la sección WAN)
-------------------------------------------
ATM PVC VPI: 0
ATM PVC VCI: 33
PROTOCOLO DE RED: PPPoE
MODO DE ENCAPSULACIÓN: LLC
USER NAME (PPP): pepephone@pepephone
Password NAME (PPP): < pepephone > o puedes dejarlo vacio. 

Direcciones IPv4. Tacha las direcciones IP inválidas.
a) 1.1.1.1
b) 2.2.2.200
c) 200.260.0.3
d) 4.4.4.4.4
i) 255.255.255.255
e) 5.0.0.300
f) 256.244.244.4
g) 700.1000.100
h) 0.0.0.0
i) 255.255.255.255
Direcciones IPv4 especiales. ¿Qué significado tienen las siguientes direcciones?
a) 127.0.0.1
b) 127.1.1.0
c) 127.127.127.127
d) 127.3.3.4
e) 0.0.0.0
f) 255.255.255.255
g) 10.255.255.255
h) 192.168.1.255
i) 172.16.255.255
j) 10.0.0.0
k) 172.16.0.0
l) 192.168.0.0
Direcciones IP reservadas. Máscaras. Para las siguientes direcciones indicar máscara y si son o no reservadas para redes privadas.
a) 127.0.0.1
b) 8.8.8.8
c) 10.2.2.2
d) 169.254.254.254
e) 169.254.3.2
f) 192.168.1.254
g) 172.16.55.55
h) 10.0.0.1
i) 2.2.3.0
j) 2.1.0.0
k) 172.16.1.0
l) 192.168.0.1
m) 198.164.2.3
n) 1.0.0.1
¿Cuántas redes privadas de clase A tenemos? ¿Cuántos equipos tiene cada una?
¿Cuántas redes privadas de clase B tenemos? ¿Cuántos equipos tiene cada una?
¿Cuántas redes privadas de clase C tenemos? ¿Cuántos equipos tiene cada una?
Direcciones IPv6. Tacha las direcciones IP inválidas para Unicast global.
a) 2001:0db8:85a3:0000:0000:8a2e:0370:7334
b) 2001:db8:85a3:8d3:1319:8a2e:370:7348
c) 2001::1
d) 2001:af:3::1
e) 2001:0:0:0:0:0:0:1
f) 2001::12a6::1
g) 2002::3:abcd:2
h) 3333:ffff::1
i) 3777:ada:fea::34
Busca información acerca de qué es el EUI-64 y el EUI-64 modificado. Para la siguiente MAC (00:11:22:33:44:55) ¿cómo quedaría su EUI-64 y su EUI-64 modificado?
EUI-64 modificado. ¿Cuál es la MAC de tu tarjeta de red? Basándote en la dirección MAC de tu tarjeta calcula la dirección IPv6 automática de enlace local (fe80:1111:2222:3333::/10).
EUI-64 modificado. ¿Cuál es la MAC de tu tarjeta de red? Basándote en la dirección MAC de tu tarjeta calcula la dirección IPv6 automática global unicast (2001::/32).
En un instituto tenemos 2 líneas ADSL de distintos proveedores cada una con su router. Si realizamos balanceo de carga, ¿cuáles serán los beneficios obtenidos?
Actividades de Packet Tracer
Elabora un esquema donde aparezcan 2 PC conectados entre sí con IP estática privada en la red 10.0.0.0.
Elabora un esquema donde aparezcan 4 PC conectados a un switch con IP estática privada en la red 172.16.0.0.
Elabora un esquema donde aparezcan 4 PC conectados a un switch con IP dinámica privada en la red 192.168.30.0. Debes poner en la red un servidor DHCP que asigne direcciones en dicho rango.
Añade al ejercicio anterior un servidor web y comprueba que los clientes pueden acceder a él.
Añade al ejercicio anterior un servidor DNS y configura en él el nombre www.mired.es para el servidor web. Comprueba que los PC pueden acceder al servidor web mediante su nombre.
Elabora un esquema donde existan 3 redes de 4 equipos cada una conectadas a un router. Cada red debe tener direcciones privadas dinámicas (una red de clase A, otra de clase B y la otra de clase C). Comprueba que hay comunicación entre ellas.
Añade al ejercicio anterior un servidor DNS y un servidor web en la red de clase A. Configura todos los PCs para que puedan acceder al servidor web mediante el nombre dado de alta en el servidor DNS.
Actividades resueltas de subnetting
Calcular la dirección de red y dirección de broadcasting (difusión) de las máquinas con las siguientes direcciones IP y máscaras de subred (si no se especifica, se utiliza la máscara por defecto):
18.120.16.250:
máscara 255.0.0.0
red 18.0.0.0
broadcasting 18.255.255.255
18.120.16.255 / 255.255.0.0:
red 18.120.0.0
broadcasting 18.120.255.255
155.4.220.39:
máscara 255.255.0.0
red 155.4.0.0
broadcasting 155.24.255.255
194.209.14.33:
máscara 255.255.255.0
red 194.209.14.0
broadcasting 194.209.14.255
190.33.109.133 / 255.255.255.0:
red 190.33.109.0
broadcasting 190.33.109.255
Suponiendo que nuestro ordenador tiene la dirección IP 192.168.5.65 con máscara 255.255.255.0, indicar qué significan las siguientes direcciones especiales:
0.0.0.0: nuestro ordenador
0.0.0.29: 192.168.5.29
192.168.67.0: la red 192.168.67.0
255.255.255.255: broadcasting a la red 192.168.5.0 (la nuestra)
192.130.10.255: broadcasting a la red 192.130.10.0
127.0.0.1: 192.168.5.65 (loopback)
Calcular la dirección de red y dirección de broadcasting (difusión) de las máquinas con las siguientes direcciones IP y máscaras de subred:
190.33.109.133 / 255.255.255.128:
red 190.33.109.128
broadcasting 190.33.109.255
(133=10000101, 128=10000000, 127=01111111)
192.168.20.25 / 255.255.255.240:
red 192.168.20.16
broadcasting 192.168.20.31
(25=00011001, 240=11110000, 16=00010000, 31=00011111)
192.168.20.25 / 255.255.255.224:
red 192.168.20.0
broadcasting 192.168.20.31
(25=00011001, 224=11100000, 31=00011111)
192.168.20.25 / 255.255.255.192:
red 192.168.20.0
broadcasting 192.168.20.63
(25=00011001, 192=11000000, 63=00111111)
140.190.20.10 / 255.255.192.0:
red 140.190.0.0
broadcasting 140.190.63.255
(020=00010100, 192=11000000, 063=00111111)
140.190.130.10 / 255.255.192.0:
red 140.190.128.0
broadcasting 140.190.191.255
(130=10000010, 192=11000000, 128=10000000, 063=00111111, 191=10111111)
140.190.220.10 / 255.255.192.0:
red 140.190.192.0
broadcasting 140.190.255.255
(220=11011100, 192=11000000, 063=00111111, 255=11111111)
Viendo las direcciones IP de los hosts públicos de una empresa observamos que todas están comprendidas entre 194.143.17.145 y 194.143.17.158, ¿Cuál es (probablemente) su dirección de red, broadcasting y máscara?
Pasamos a binario las dos direcciones. La primera tiene que estar próxima a la dirección de red y la última, a la dirección de broadcasting:
194.143.017.145     11000010.10001111.00010001.10010001
194.143.017.158     11000010.10001111.00010001.10011110 

Podemos suponer que la dirección de red es 194.143.17.144 y la de broadcasting, 194.143.17.159:
194.143.017.144     11000010.10001111.00010001.10010000
194.143.017.159     11000010.10001111.00010001.10011111
                    <-----------------------------><-->
                                 RED               HOST

Entonces la máscara será:
255.255.255.240     11111111.11111111.11111111.11110000
                    <-----------------------------><-->
                                  RED              HOST 

Un equipo tiene la IP 194.100.129.120. Si existen 8 subredes, indicar:
a) clase y máscara por defecto
b) máscara cuando dividimos la red en 8 subredes
c) dirección de inicio (dirección de subred) y fin (dirección de difusión) de cada subred
d) subred a la que pertenece la dirección IP
e) número de IPs destinadas a equipos en cada subred
IP 194.100.129.120. Existen 8 subredes
a) IP de clase C. Máscara por defecto: 255.255.255.0.
b) Subred
Para obtener 8 subredes debemos ampliar la máscara anterior en 3 bits (23=8)
            Red                    Host
     11111111.11111111.11111111.11100000 = 255.255.255.224 = \27

c) Las direcciones de subred son:
 11000010.01100100.10000001.00000000 = 194.100.129.0
 11000010.01100100.10000001.00100000 = 194.100.129.32
 11000010.01100100.10000001.01000000 = 194.100.129.64
→11000010.01100100.10000001.01100000 = 194.100.129.96
 11000010.01100100.10000001.10000000 = 194.100.129.128
 11000010.01100100.10000001.10100000 = 194.100.129.160
 11000010.01100100.10000001.11000000 = 194.100.129.192
 11000010.01100100.10000001.11100000 = 194.100.129.224

Las direcciones de broadcast son:
 11000010.01100100.10000001.00011111 = 194.100.129.31
 11000010.01100100.10000001.00111111 = 194.100.129.63
 11000010.01100100.10000001.01011111 = 194.100.129.95
→11000010.01100100.10000001.01111111 = 194.100.129.127
 11000010.01100100.10000001.10011111 = 194.100.129.159
 11000010.01100100.10000001.10111111 = 194.100.129.191
 11000010.01100100.10000001.11011111 = 194.100.129.223
 11000010.01100100.10000001.11111111 = 194.100.129.255

d) Nuestra IP
 11000010.01100100.10000001.01111000 = 194.100.129.120

se halla en la subred
 11000010.01100100.10000001.01100000 = 194.100.129.96

e) Como existen 5 bits de hosts, el número total de IPs para hosts es 25-2
Un equipo tiene la IP 172.10.130.4. Si existen 4 subredes, indicar:
a) clase y máscara por defecto
b) máscara cuando dividimos la red en 4 subredes
c) dirección de inicio (dirección de subred) y fin (dirección de difusión) de cada subred
d) subred a la que pertenece la dirección IP
e) número de IPs destinadas a equipos en cada subred
IP 172.10.130.4. Existen 4 subredes
a) IP de clase B. Máscara por defecto: 255.255.0.0.
b) Subred
Para obtener 4 subredes debemos ampliar la máscara anterior en 2 bits (22=4)
          Red               Host
 11111111.11111111.11000000.00000000 = 255.255.192.0 = \18



c) Las direcciones de subred son:
 10101100.00001010.00000000.00000000 = 172.10.0.0
 10101100.00001010.01000000.00000000 = 172.10.64.0
→10101100.00001010.10000000.00000000 = 172.10.128.0
 10101100.00001010.11000000.00000000 = 172.10.192.0

Las direcciones de broadcast son:
 10101100.00001010.00111111.11111111 = 172.10.63.255
 10101100.00001010.01111111.11111111 = 172.10.127.255
→10101100.00001010.10111111.11111111 = 172.10.191.255
 10101100.00001010.11111111.11111111 = 172.10.255.255

d) Nuestra IP
 10101100.00001010.10000010.00000100 = 172.10.130.4

se halla en la subred
 10101100.00001010.10000000.00000000 = 172.10.128.0

e) Como existen 14 bits de hosts, el número total de IPs para hosts es 214-2


Actividades a resolver de subnetting
¿Cuál de las siguientes opciones representa la máscara 255.255.240.0?
/26
/18
/192
/20
/224
/22
/240
/16
/24
/27
¿Qué máscaras de las siguientes son inválidas?
255.128.255.0
128.255.0.0
255.0.0.255
255.255.0.0
255.254.0.0
255.252.0.0
255.248.0.0
255.240.0.0
255.224.0.0
255.192.0.0
255.128.0.0
Para las siguientes máscaras, indicar su formato corto en forma de longitud de prefijo.
255.255.0.0
255.0.0.0
255.255.255.0
255.128.0.0
255.255.0.0
255.254.0.0
255.252.0.0
255.248.0.0
255.240.0.0
255.224.0.0
255.192.0.0
255.128.0.0
¿A qué subredes pertenecen estos hosts?
192.168.10.104/27
192.168.10.144/28
192.176.12.242/26
122.122.239.12/19
Dada la dirección 134.141.7.11 y la máscara 255.255.255.0, ¿Cuál es el número de subred?
Dada la dirección 193.193.7.7 y la máscara 255.255.255.0 ¿cuál es el número de subred y cuál es la dirección de broadcast?
Dada la dirección 200.1.1.130 y la máscara 255.255.255.224 ¿cuál es el número de subred y cuál es la dirección de broadcast?
Dada la IP 220.8.7.100/28, ¿Cuál es la dirección de subred y cuál es la dirección de broadcast?
Dada la dirección IP 10.141.7.11/24 ¿Cuál es la dirección de subred y cuál es la dirección de broadcast?
Dada la dirección 134.141.7.11/24 ¿Cuáles son las direcciones IP válidas?
Dada la dirección 200.2.1.130/27 ¿Cuáles son las direcciones IP válidas?
Dada la IP 134.141.7.7/24, ¿cuáles son las números de subred válidos?
Dada la IP 220.8.7.100 y la máscara 255.255.255.240, ¿cuáles son las subredes válidas?
¿Cuántas direcciones IP serán asignadas en cada subred de 134.141.0.0/24?
¿Cuántas direcciones IP serán asignadas en cada subred de 220.8.7.0/28?
¿Cuántas direcciones IP serán asignadas en cada subred de 10.0.0.0/14?
¿Cuántas direcciones IP serán asignadas en cada subred de 11.0.0.0 255.192.0.0?
Un equipo tiene la IP 10.10.4.4. Si existen 256 subredes, indicar:
clase y máscara por defecto
máscara cuando dividimos la red en 256 subredes
dirección de inicio (dirección de subred) y fin (dirección de difusión) de cada subred (sólo las tres primeras)
subred a la que pertenece la dirección IP
número de IPs destinadas a equipos en cada subred
Diseñas una red para un cliente, y el cliente te pide que utilices la misma máscara de subred para todas las subredes. El cliente utiliza la red 10.0.0.0 y necesita 200 subredes, con 200 hosts como máximo en cada subred. ¿Qué máscara trabajará mejor y permitirá mayor crecimiento en el número de host por subred a futuro?
Actividades resueltas de VLSM
Subnetting
A partir de la red 192.168.100.0/24 hacer la subredes necesarias para obtener las mostradas en la siguiente figura.



Paso 0: ¿Cuantas IPs necesitamos?

Red A: 52. (50 + 2 -de red y broadcast-)
Red B: 29. (27 + 2 -de red y broadcast-)
Red C: 14. (12 + 2 -de red y broadcast-)
Red D: 14. (12 + 2 -de red y broadcast-)
Red E: 4. (2 + 2 -de red y broadcast-)
Red F: 4. (2 + 2 -de red y broadcast-)
Red G: 4. (2 + 2 -de red y broadcast-)
Red H: 4. (2 + 2 -de red y broadcast-)
Total: 52+29+14+14+4+4+4+4


Paso 1: ¿Tenemos espacio suficiente?

Comprobamos que disponemos de suficiente espacio de direcciones. Como una la red 192.168.100.0/24 dispone de 8 bits para hosts, tenemos 28 = 256 IPs (muchas más de las que necesitamos).


Paso 2: ¿Como las distribuimos?

Para la red A: Necesitamos un bloque de 64 IPs (26) >= 52

Para la red B: Necesitamos un bloque de 32 IPs (25) >= 29

Para la red C: Necesitamos un bloque de 16 IPs (24) >= 14

Para la red D: Necesitamos un bloque de 16 IPs (24) >= 14

Para la red E: Necesitamos un bloque de 4 IPs (22) >= 4

Para la red F: Necesitamos un bloque de 4 IPs (22) >= 4

Para la red G: Necesitamos un bloque de 4 IPs (22) >= 4

Para la red H: Necesitamos un bloque de 4 IPs (22) >= 4


Red A: 6 bits para hosts. Por tanto 2 bits para subred. Máscara: /26.

Red B: 5 bits para hosts. Por tanto 3 bits para subred. Máscara: /27.

Red C: 4 bits para hosts. Por tanto 4 bits para subred. Máscara: /28.

Red D: 4 bits para hosts. Por tanto 4 bits para subred. Máscara: /28.

Red E: 2 bits para hosts. Por tanto 6 bits para subred. Máscara: /30.

Red F: 2 bits para hosts. Por tanto 6 bits para subred. Máscara: /30.

Red G: 2 bits para hosts. Por tanto 6 bits para subred. Máscara: /30.

Red H: 2 bits para hosts. Por tanto 6 bits para subred. Máscara: /30.


Paso 3: Realizamos distribución

A continuación se muestra un cuadro de cómo hemos distribuido las subredes. No es la única solución. Podríamos haber escogido otra forma de distribuirlas, siempre que respetemos la máscara que debemos asignar a cada una y el número de IPs por subred.


x=192.168.100



Las redes quedan de la siguiente forma:

Red A:192.168.100.64/26
Red B: 192.168.100.128/27
Red C: 192.168.100.160/28
Red D: 192.168.100.176/28
Red E:192.168.100.0/30
Red F:192.168.100.4/30
Red G: 192.168.100.8/30
Red H: 192.168.100.12/30
Supernetting. Resumen de rutas
Resumen de Huelva

172.16.64.0 = 10101100.00010000.01000000.00000000

172.16.65.0 = 10101100.00010000.01000001.00000000

172.16.66.0 = 10101100.00010000.01000010.00000000

172.16.67.0 = 10101100.00010000.01000011.00000000

22 bits son comunes.

Por tanto la ruta resumida es 172.16.64.0/22


Resumen de Cádiz

172.16.68.0 = 10101100.00010000.01000100.00000000

172.16.69.0 = 10101100.00010000.01000101.00000000

172.16.70.0 = 10101100.00010000.01000110.00000000

172.16.71.0 = 10101100.00010000.01000111.00000000

22 bits son comunes.

Por tanto la ruta resumida es 172.16.68.0/22


Resumen de Málaga

172.16.72.0 = 10101100.00010000.01001000.00000000

172.16.73.0 = 10101100.00010000.01001001.00000000

172.16.74.0 = 10101100.00010000 01001010.00000000

172.16.75.0 = 10101100.00010000 01001011.00000000

172.16.76.0 = 10101100.00010000.01001100.00000000

172.16.77.0 = 10101100.00010000.01001101.00000000

172.16.78.0 = 10101100.00010000.01001110.00000000

172.16.79.0 = 10101100.00010000.01001111.00000000

21 bits son comunes.

Por tanto la ruta resumida es 172.16.72.0/21


Resumen de Sevilla

172.16.64.0 = 10101100.00010000.01000000.00000000

172.16.68.0 = 10101100.00010000.01000100.00000000

172.16.72.0 = 10101100.00010000.01001000.00000000

20 bits son comunes.

Por tanto la ruta resumida es 172.16.64.0/20





Resultado final



Actividades a resolver de VLSM
Dada la red 192.168.0.0/24, desarrolle un esquema de direccionamiento que cumpla con los siguientes requerimientos. Use VLSM, es decir, optimice el espacio de direccionamiento tanto como sea posible.
Una subred de 50 hosts para ser asignada a los Profesores
Una subred de 80 hosts para ser asignada a los Estudiantes
Una subred de 20 hosts para ser asignada a los Invitados
Tres subredes de 2 hosts para ser asignada a los enlaces entre routers.




Usted es el administrador de la red para una escuela primaria local. Su primera tarea es hacer que la correcta distribución de IPs en la red. El ISP le ha dado a usted la dirección de red 177.19.156.0 y máscara 255.255.252.0. Realice el subnetting necesario según el esquema que se muestra más abajo. Comience las asignaciones de direcciones con el 177.19.157.0.






Sumarización de rutas. Tenemos esta red VLSM con subnetting y debemos averiguar cuál va a ser la dirección que va a publicar en Internet el router A.




Bibliografía y referencias
http://www.cisco.com/web/learning/netacad/demos/CCNA2v3Demo/ch1/1_1_2/index.html
http://www.suarezdefigueroa.es/manuel/PAR
https://www.youtube.com/watch?v=IvVv-BaIiLk
Tipos de direcciones IPv6
Tema 9



Tema 9: Redes locales virtuales.
Introducción
Conceptos generales
Protocolos
Caso práctico
Actividades
Bibliografía y referencias
Introducción
Una VLAN (acrónimo de virtual LAN, «red de área local virtual») es un método para crear redes lógicas independientes dentro de una misma red física. Varias VLAN pueden coexistir en un único conmutador físico o en una única red física. Son útiles para reducir el tamaño del dominio de difusión y ayudan en la administración de la red, separando segmentos lógicos de una red de área local (los departamentos de una empresa, por ejemplo) que no deberían intercambiar datos usando la red local (aunque podrían hacerlo a través de un enrutador o un conmutador de capa 3).



Tipos de VLAN
Las dos aproximaciones más habituales para la asignación de miembros de una VLAN son las siguientes:

VLAN estáticas
VLAN dinámicas.
Las VLAN estáticas también se denominan VLAN basadas en el puerto. Las asignaciones en una VLAN estática se crean mediante la asignación de los puertos de un switch o conmutador a dicha VLAN. Cuando un dispositivo entra en la red, automáticamente asume su pertenencia a la VLAN a la que ha sido asignado el puerto. Si el usuario cambia de puerto de entrada y necesita acceder a la misma VLAN, el administrador de la red debe cambiar manualmente la asignación a la VLAN del nuevo puerto de conexión en el switch.

En las VLAN dinámicas, el administrador de la red puede asignar los puertos que pertenecen a una VLAN de manera automática basándose en información tal como la dirección MAC del dispositivo que se conecta al puerto o el nombre de usuario utilizado para acceder al dispositivo. En este procedimiento, el dispositivo que accede a la red, hace una consulta a la base de datos de miembros de la VLAN.

Características
Las VLANs permiten dividir la red local en redes virtuales
Los equipos de la red que pertenecen a la misma VLAN pueden comunicarse entre ellos como si estuvieran conectados al mismo switch
La comunicación entre estaciones de diferentes VLANs requiere un dispositivo de nivel 3
A cada VLAN se le asigna un identificador de distinto color:
Los puertos de los switches quedan coloreados
Los puertos que unen switches se considera que pertenecen a la unión de los colores de los dos switches
Sólo se envía una trama por un puerto cuando la LAN origen y destino tienen el mismo color (es decir, ambos puertos pertenecen a la misma VLAN)
Ventajas
Permiten reconfigurar si hay un cambio sin tocar cables ni switches
Aumenta la seguridad
Aumenta el rendimiento de la red al separar dominios de difusión
La organización de la red se basa en las tareas de los usuarios y no en su localización física.
Conceptos generales
Tipos de puertos
En un switch, atendiendo a su función dentro de la VLAN, existirán dos tipos de puertos:

Puertos de acceso (access)
Puertos troncales (trunk)
Los puertos de acceso son aquellos a los que se conectan directamente los equipos terminales (ordenadores o periféricos). Por ellos solo viajan tramas pertenecientes a una única VLAN.

Los puertos troncales son aquellos por los que circulan tramas de una o más VLANs. Para distinguir el tráfico de las distinta VLANs es necesario etiquetar las tramas indicando que VLAN pertenecen.

Enlaces troncales (trunk)
Los enlaces troncales o trunks, son enlaces capaces de transportar el tráfico de más de una VLAN y se suele utilizar para interconectar dos switches, un switch y un router, incluso interconectar un switch y un servidor al cual se le ha instalado una NIC especial capaz de soportar trunking. Los enlaces troncales nos permiten transportar de forma lógica las VLANs utilizando un enlace físico.



Un enlace troncal (trunk) puede ser un único enlace físico o estar conformado por varios de ellos usando la técnica de agregación (link agregation) que permite combinar varios enlaces físicos en un enlace lógico que funciona como un único puerto de mayor ancho de banda.

Otras denominaciones para la agregación de enlaces son Trunking o Bonding. Cisco lo denomina EtherChannel (Modos: ON, PAgP o LACP).



Etiquetado
Los puertos de un switch pueden estar etiquetados (tagged) o no etiquetados (untagged).

En un enlace troncal es necesario diferenciar el tráfico de cada una de las VLANs, de tal forma que se le asigna a cada trama entrante un identificador llamado VLAN-ID. Para poder identificar el tráfico en un enlace troncal existen dos tipos de etiquetado:

ISL (Inter-Switch Link Protocol)
IEEE 802.1Q
ISL (Inter-Switch Link Protocol)
ISL es un protocolo propietario de Cisco que está en desuso. Este protocolo no altera la trama original, porque éste encapsula la trama Ethernet con una nueva cabecera de 26 bytes, que contiene al identificador VLAN (VLAN ID), y además añade un campo de secuencia de chequeo de trama (FCS ó CRC) de 4 bytes al final de la trama, como se muestra en la figura. Por lo tanto, como la trama ha sido encapsulada por ISL con nueva información, solamente los dispositivos que conozcan ISL podrán leer estas nuevas tramas.


VLAN - Trama ISL
IEEE 802.1Q
El estándar IEEE 802.1Q (también llamado dot1q) especifica el etiquetado de tramas como un método para implementar VLANs. Insertando un campo de 4 bytes dentro de la trama Ethernet para identificar a que VLAN pertenece la información que se está transportando entre dispositivos de capa 2.




VLAN - Trama 802.1Q



El proceso de insertar el campo IEEE 802.1Q dentro de la trama Ethernet provoca que el campo FCS sea inválido, debido a que se ha alterado la trama, por lo tanto es esencial que un nuevo FCS sea recalculado, basado en la nueva trama que contiene al campo IEEE 802.1Q. Este proceso es automáticamente desarrollado por el switch antes de que la trama sea enviada por el enlace troncal.

Este método es el más popular por ser empleado por switches de diferentes fabricantes, ofreciendo compatibilidad entre equipos. Incluso los switches Cisco pueden manejar este estándar.

VLAN nativa
Normalmente un puerto de switch configurado como un puerto troncal envía y recibe tramas Ethernet etiquetadas con IEEE 802.1q. Si un switch recibe tramas Ethernet sin etiquetar en su puerto troncal, se remiten a la VLAN que se configura en el switch como VLAN nativa. Ambos lados del enlace troncal deben configurarse para estar en la misma VLAN nativa.


La VLAN nativa es la vlan a la que pertenecía un puerto en un switch antes de ser configurado como trunk. Sólo se puede tener una VLAN nativa por puerto. En los equipos de Cisco Systems la VLAN nativa por defecto es la VLAN 1. Por la VLAN 1 además de datos, se manda información sobre PAgP, CDP, VTP.

Para establecer un trunking 802.1Q a ambos lados debemos tener la misma VLAN nativa porque la encapsulación todavía no se ha establecido y los dos switches deben hablar sobre un link sin encapsulación (usan la native VLAN) para ponerse de acuerdo en estos parámetros.

Protocolos
DTP
DTP (Dynamic Trunking Protocol) es un protocolo propietario creado por Cisco Systems que opera entre switches Cisco, el cual automatiza la configuración de trunking (etiquetado de tramas de diferentes VLAN's con ISL o 802.1Q) en enlaces Ethernet.

DTP se habilita automáticamente en un puerto del switch cuando se configura un modo de trunking adecuado en dicho puerto. Para ello el administrador debe ejecutar el comando switchport mode adecuado al configurar el puerto: switchport mode {access | trunk | dynamic auto | dynamic desirable}. Con el comando switchport nonegotiate se desactiva DTP.

En switches Catalyst 2960 de Cisco el modo dynamic auto es el modo por defecto. El puerto aguardará pasivamente la indicación del otro extremo del enlace para pasar a modo troncal. Para ello envía periódicamente tramas DTP al puerto en el otro lado del enlace indicando que es capaz de establecer un enlace troncal. Esto no quiere decir que lo solicita, sino que sólo lo informa. Si el puerto remoto está configurado en modo on o dynamic desirable se establece el enlace troncal correctamente. Sin embargo, si los dos extremos están en modo dynamic auto no se establecerá el enlace como troncal, sino como acceso.

VTP
VTP son las siglas de VLAN Trunking Protocol, un protocolo de mensajes de nivel 2 usado para configurar y administrar VLANs en equipos Cisco. Permite centralizar y simplificar la administración en un domino de VLANs, pudiendo crear, borrar y renombrar las mismas, reduciendo así la necesidad de configurar la misma VLAN en todos los nodos. El protocolo VTP nace como una herramienta de administración para redes de cierto tamaño, donde la gestión manual se vuelve inabordable.

VTP opera en 3 modos distintos:

Servidor
Cliente
Transparente
Servidor:

Es el modo por defecto. Desde él se pueden crear, eliminar o modificar VLANs. Su cometido es anunciar su configuración al resto de switches del mismo dominio VTP y sincronizar dicha configuración con la de otros servidores, basándose en los mensajes VTP recibidos a través de sus enlaces trunk. Debe haber al menos un servidor. Se recomienda autenticación MD5.

Cliente:

En este modo no se pueden crear, eliminar o modificar VLANs, tan sólo sincronizar esta información basándose en los mensajes VTP recibidos de servidores en el propio dominio. Un cliente VTP sólo guarda la información de la VLAN para el dominio completo mientras el switch está activado. Un reinicio del switch borra la información de la VLAN.

Transparente:

Desde este modo tampoco se pueden crear, eliminar o modificar VLANs que afecten a los demás switches. La información VLAN en los switches que trabajen en este modo sólo se puede modificar localmente. Su nombre se debe a que no procesa las actualizaciones VTP recibidas, tan sólo las reenvía a los switches del mismo dominio.

Los administradores cambian la configuración de las VLANs en el switch en modo servidor. Después de realizar cambios, estos son distribuidos a todos los demás dispositivos en el dominio VTP a través de los enlaces permitidos en el trunk (VLAN 1, por defecto), lo que minimiza los problemas causados por las configuraciones incorrectas y las inconsistencias. Los dispositivos que operen en modo cliente, automáticamente aplicarán la configuración que reciban del dominio VTP. En este modo no se podrán crear VLANs, sino que sólo se podrá aplicar la información que reciba de las publicaciones VTP.

El modo por defecto de los swicthes es el de servidor VTP. Se recomienda el uso de este modo para redes de pequeña escala en las que la información de las VLANs es pequeña y por tanto de fácil almacenamiento en las NVRAMs de los switches.

En redes de mayor tamaño, el administrador debe elegir qué switches actúan como servidores, basándose en las capacidades de éstos (los mejor equipados serán servidores y los demás, clientes).

El VTP sólo aprende sobre las VLAN de rango normal (ID de VLAN 1 a 1005). Las VLAN de rango extendido (ID mayor a 1005) no son admitidas por el VTP.

Caso práctico
Uso del módulo HWIC-4ESW (4 puertos de switch).
El HWIC-4ESW es el equivalente de un conmutador de capa 2 por lo que no se le puede asignar direcciones IP a los puertos físicos. Lo que se puede hacer es crear un SVI L3 (SVI: Interfaz Virtual del Switch) y asignar el puerto dentro de la VLAN.

Comandos IOS básicos
Router>?
Router>enable

Crear una VLAN
Router#vlan database
Router(vlan)#vlan 10
Router(vlan)#exit

Asignar una IP a la VLAN
Router#configure terminal
Router(config)#interface vlan 10
Router(config-if)#ip address 192.168.5.1 255.255.255.0
Router(config-if)#exit

Y asignar las interfaces dentro de esa VLAN
Router(config)#interface FastEthernet0/1/x
Router(config-if)#switchport access vlan 10
Router(config-if)#exit

Actividades
¿Qué tipos de VLAN existen más frecuentemente? Explicar.
En referencia a las VLAN, ¿qué tipos de puertos existen?. Explicar.
En los enlaces troncales, ¿es aconsejable utilizar agregación de enlaces? ¿Por qué?
¿Qué tipos de etiquetado se utilizan en las tramas para distinguirlas unas de otras como pertenecientes a alguna VLAN? Explicar.
Rellena la siguiente tabla.


Protocolo	Propietario de CISCO	Nivel OSI	Función
CDP			
STP			
DTP			
VTP			
¿Qué significan las siglas de cada protocolo?
Actividades de Packet Tracer
Configura un switch con 3 VLANs (Alumnos, Profesores, Gestión), según el esquema que se muestra a continuación. Todos los ordenadores deben estar en la misma red IP privada, pero sólo deberán verse entre sí los que se hallen en la misma VLAN.


Habilitando módulo HWIC-4ESW (4 port switch)
Asignar una IP a la VLAN
Router#configure terminal
Router(config)#interface vlan 10
Router(config-if)#ip address 192.168.5.1 255.255.255.0
Router(config-if)#exit
Asignar interfaces dentro de esa VLAN
Router(config)#interface range FastEthernet0/1/x-y
Router(config-if-range)#switchport access vlan 10
Router(config-if-range)#exit

Utilizando la misma red IP privada anterior, con las mismas VLANs, realizar el siguiente esquema. Las conexiones de los switches al router son enlaces troncales. Comprobar que existe comunicación entre los equipos de la misma VLAN.


Comandos para agregación de enlaces
Switch(config)#interface range FastEthernet0/x-y
Switch(config-if-range)# switchport mode trunk
Switch(config-if-range)# channel-group z mode on
Switch(config-if-range)#exit

Modifica el esquema anterior para añadir agregación de enlaces de la siguiente forma. Comprueba el correcto funcionamiento. ¿Por qué se han desactivado dos enlaces? ¿Qué protocolo es responsable de ello? ¿Por qué crees que se han desactivado esos y no otros enlaces?




Modifica el esquema anterior para que la agregación de enlaces sea como la que se muestra a continuación. Sustituye el router por un switch. Comprueba el correcto funcionamiento. ¿Por qué crees que se han desactivado esos y no otros enlaces?


Comandos para uso de VTP
En el switch principal
Switch(config)#vtp mode server
Switch(config)# vtp domain prueba
Switch(config)# vlan 10
Switch(config-vlan)# name alumnos
Switch(config-vlan)#exit
Switch(config)# vlan 20
Switch(config-vlan)# name profesores
Switch(config-vlan)#exit
En los switches secundarios
Switch(config)#vtp mode client

Elimina todas las VLANs que has creado en el esquema anterior y vuelve a crearlas haciendo uso de VTP. Para ello configura el switch principal como VTP mode server y los switches secundarios como VTP mode client. Comprueba el correcto funcionamiento.


Bibliografía y referencias
VLAN en Cisco
VLAN Trunks
Tema 10



Tema 10: Encaminamiento.
Introducción
Clasificación
Aplicación práctica
Protocolos interiores y exteriores
Estructura jerárquica de internet
Actividades
Bibliografía y referencias
Introducción
Encaminamiento (o enrutamiento, ruteo) es la función de buscar un camino entre todos los posibles en una red de paquetes cuyas topologías poseen una gran conectividad. Dado que se trata de encontrar la mejor ruta posible, lo primero será definir qué se entiende por mejor ruta y en consecuencia cuál es la métrica que se debe utilizar para medirla.

La métrica de la red puede ser por ejemplo de saltos necesarios para ir de un nodo a otro. Aunque ésta no se trata de una métrica óptima ya que supone “1” para todos los enlaces, es sencilla y suele ofrecer buenos resultados.

Otro tipo es la medición del retardo de tránsito entre nodos vecinos, en la que la métrica se expresa en unidades de tiempo y sus valores no son constantes sino que dependen del tráfico de la red.


Atendiendo al número de equipos a los que va destinado un datagrama, la comunicación se considera:

Unicast
Multicast
Anycast
Broadcast
Geocast

Unicast es el envío de información desde un único emisor a un único receptor. Se contrapone a multicast (envío a ciertos destinatarios específicos, más de uno), broadcast (radiado o difusión, donde los destinatarios son todas las estaciones en la red) y anycast (el destinatario es único, uno cualquiera no especificado).

Broadcast, difusión en español, es una forma de transmisión de información donde un nodo emisor envía información a una multitud de nodos receptores de manera simultánea, sin necesidad de reproducir la misma transmisión nodo por nodo.

Multicast, multidifusión en español, es el envío de la información en múltiples redes a múltiples destinos simultáneamente. Antes del envío de la información, deben establecerse una serie de parámetros. Para poder recibirla, es necesario establecer lo que se denomina "grupo multicast". Ese grupo multicast tiene asociado una dirección de internet. La versión actual del protocolo de internet, conocida como IPv4, reserva las direcciones de tipo D para la multidifusión.

Anycast es una forma de direccionamiento en la que la información es enrutada al mejor destino desde el punto de vista de la topología de la red. En la red internet, una dirección IP se puede anunciar desde varios puntos diferentes. Los routers intermedios encaminan el paquete hasta el destino más cercano. Un paquete enviado a una dirección anycast es entregado a la máquina más próxima desde el punto de vista del tiempo de latencia.

Geocast se refiere a la entrega de información a un grupo de destinos en una red identificada por su ubicación geográfica. Es una forma especializada de direccionamiento de multidifusión utilizado por algunos protocolos de enrutamiento para redes móviles ad hoc.

Clasificación
Los métodos de encaminamiento los podemos clasificar en función de:

El procedimiento de encaminamiento.
Las tablas de encaminamiento empleadas.
En función del procedimiento.
Los procedimientos de encaminamiento pueden ser:

Determinísticos o Estáticos
En los encaminamientos estático y cuasi-estático la información necesaria se recoge y envía mediante gestión (al crear la red y en operaciones de mantenimiento).

Estático
Las tablas de encaminamiento de los nodos se configuran de forma manual y permanecen inalterables hasta que no se vuelve a actuar sobre ellas. La adaptación a cambios es nula. Tanto la recogida como la distribución de información se realiza por gestión (se realiza de manera externa a la red), sin ocupar capacidad de red. El calculo de ruta se realiza off-line (en una maquina especifica),y las rutas pueden ser las óptimas al no estar sometido al requisito de tiempo real.

Este tipo de encaminamiento es el óptimo para topologías en los que solo hay una posibilidad de encaminamiento (topología en estrella).

Cuasiestático
Este encaminamiento, es igual que el estático pero en vez de dar una sola ruta fija, se dan además varias alternativas en caso de que la principal no funcione, de ahí que tenga una adaptabilidad reducida.

Este tipo de encaminamiento puede dar lugar a situaciones incoherentes, ya que no se enteran todos los nodos de los problemas de la red, sino sólo los adyacentes a los problemas.

Adaptativos o Dinámicos
En este tipo de procedimientos de encaminamiento la información se recoge y envía de forma periódica con el fin de detectar cambios en la red.

Centralizado
En este tipo de encaminamiento, todos los nodos son iguales salvo el nodo central, que recoge la información de control de todos los nodos y calcula la FIB (tabla de encaminamiento) para cada nodo, es decir, el nodo central decide la tabla de encaminamiento de cada nodo en función de la información de control que éstos le mandan. El inconveniente de este método es que consumimos recursos de la red, y se harían necesaria rutas alternativas para comunicarse con el nodo central. La adaptación a cambios es perfecta siempre y cuando las notificaciones de los cambios lleguen antes de iniciar los cálculos de las rutas.

Aislado
Se basa en que cada vez que un nodo recibe un paquete que tiene que reenviar (porque no es para él) lo reenvía por todos los enlaces salvo por el que le llegó.

Distribuido
En este tipo de encaminamiento todos los nodos son iguales, todos envían y reciben información de control y todos calculan, a partir de su RIB (base de información de encaminamiento) sus tablas de encaminamiento. La adaptación a cambios es optima siempre y cuando estos sean notificados.

Hay dos familias de procedimientos distribuidos:

Vector de distancias

Cada nodo informa a sus nodos vecinos de todas las distancias conocidas por él, mediante vectores de distancias (de longitud variable según los nodos conocidos). El vector de distancias es un vector de longitud variable que contiene un par (nodo:distancia al nodo) por cada nodo conocido por el nodo que lo envía, por ejemplo (A:0;B:1;D:1) que dice que el nodo que lo manda dista "0" de A,"1" de B y "1" de D, y de los demás no sabe nada (ésta es la forma en la que un nodo dice lo que sabe en cada momento). El nodo solo conoce la distancia a los distintos nodos de la red pero no conoce la topología.

Con todos los vectores recibidos, cada nodo monta su tabla de encaminamiento ya que al final conoce qué nodo vecino tiene la menor distancia al destino del paquete, pues se lo han dicho con el vector de distancias.

Estado de enlaces

Cada nodo difunde a todos los demás nodos de la red sus distancias con sus enlaces vecinos, es decir, cada nodo comunica su entorno local a todos los nodos. Así cada nodo es capaz de conocer la topología de la red. La clave y dificultad de este método es la difusión.

A continuación se muestra una tabla comparativa de todos los tipos de encaminamiento vistos.



Clasificación de los métodos de encaminamiento
Tipos de encaminamiento	Recepción de información de control	Envío de información de control	Decisión de encaminamiento	Adaptación a los cambios
Estático	NO	NO	OFF-LINE	NO
Cuasi - estático	NO	NO	OFF-LINE	Reducida
Centralizado	Nodos-Nodo central	Nodo central-Nodos	Nodo central	SI
Aislado	NO	NO	Inundación, por ejemplo	SI
Distribuido	Todos los nodos	Todos los nodos	Todos los nodos	SI


Comparación Vector de distancias – Estado del Enlaces.
Haremos una comparación entre los algortitmos de vector de distancias y de estado de enlaces, ambos del tipo distribuido:

Consumo de capacidad.

Lo ideal es que el tráfico de control sea lo más pequeño posible. Con vectores de distancia se transmiten vectores cuyo tamaño es del orden del número de nodos de la red pues cada nodo comunica a su vecino todas las distancias que conoce; con procedimientos de estado de enlace, el tamaño del tráfico enviado es siempre el mismo independientemente del tamaño de la red. En consecuencia, consume más capacidad un vector de distancias.

Consumo de memoria

El encaminamiento basado en estado de enlace hace que cada nodo almacene toda la topología de la red, sin embargo con vectores de distancias sólo ha de almacenar distancias con el resto de los nodos. Luego consume más memoria en los nodos un procedimiento basado en estado de enlace.

Adaptabilidad a los cambios

El método de vector de distancia es más sencillo, pero se adapta peor a los cambios que el de estado de enlace. Esto es porque mientras que este último tiene información de toda la red, el primero sólo sabe a quién tiene que reenviar un paquete, pero no tiene información de la topología. Luego se adapta mejor un encaminamiento de estado de enlaces.


No obstante, el encaminamiento basado en vector de distancias es mucho menos complejo que el de estado de enlaces, cosa que en algunos casos prácticos puede llegar a ser muy importante.

En función de las tablas de encaminamiento empleadas.
Los nodos manejan tablas de encaminamiento, en las que aparece la ruta que deben seguir los paquetes con destino a un nodo determinado de la red.

Podemos distinguir entre encaminamiento salto a salto y encaminamiento fijado en origen. Nosotros veremos con detalle sólo el primer tipo (salto a salto).

Encaminamiento salto a salto
En la literatura inglesa, este tipo de encaminamiento se denomina como hop by hop. Se basa en que cada nodo no tiene que conocer la ruta completa hasta el destino, sino que sólo debe saber cuál es el siguiente nodo al que tiene que mandar el paquete: las tablas dan el nodo siguiente en función del destino. Como ejemplo, tomemos la siguiente red:

Red de ejemplo




Las tablas de encaminamiento de los nodos A y B serán:

Tabla 1. Tablas de encaminamiento para la red de laFigura 1



Tabla de encaminamiento del nodo A	Tabla de encaminamiento del nodo B
Destino	Siguiente nodo	Destino	Siguiente nodo
B	B	A	A
C	B	C	C
D	B	D	C
E	H	E	C
F	H	F	C
G	H	G	G
H	H	H	A
En la tabla de encaminamiento de cada nodo deberá aparecer una entrada en el campo destino por cada nodo que se pueda alcanzar desde el citado nodo, y en el campo siguiente nodo aparecerá el nodo vecino al que se deberá enviar los datos para alcanzar el citado nodo destino. Las soluciones propuestas no son únicas, pudiendo elegir otros caminos que minimicen el tiempo de retardo, el número de saltos, etc. La única condición que se impone es que debe haber consistencia: si, por ejemplo, para ir de A a B pasamos por C, entonces para ir de B a C no podremos pasar por A, porque entonces se formaría un bucle y el paquete mandado estaría continuamente viajando entre los nodos B y A, como puede comprobarse fácilmente.

Encaminamiento fijado en origen.
En inglés este encaminamiento se llama source routing. En él, son los sistemas finales los que fijan la ruta que ha de seguir cada paquete. Para ello, cada paquete lleva un campo que especifica su ruta(campo RI: Routing Information), y los nodos sólo se dedican a reenviar los paquetes por esas rutas ya especificadas. Así pues, son los sistemas finales los que tienen las tablas de encaminamiento y no se hace necesaria la consulta o existencia de tablas de encaminamiento en los nodos intermedios. Este tipo de encaminamiento suele ser típico de las redes de IBM.


Tabla 2. Tablas de encaminamiento para la red de laFigura 1



Tabla de encaminamiento del nodo A	Tabla de encaminamiento del nodo B
Destino	Ruta a seguir	Destino	Ruta a seguir
B	B	A	A
C	B-C	C	C
D	B-C-D	D	C-D
E	H-G-E	E	C-F-E
F	H-G-F	F	C-F
G	H-G	G	G
H	H	H	A-H
Comparación entre ambos tipos de encaminamiento.
Lo veremos por medio de la siguiente tabla:

Tabla 3. Comparación entre encaminamiento salto a salto y fijado en origen



Fijado en Origen	Salto a Salto
Conocimiento	Los sistemas finales han de tener un conocimiento completo de la red	SIMPLICIDAD: Los nodos han de tener un conocimiento parcial de la red (saber qué rutas son las mejores)
Complejidad	Recae toda en los sistemas finales	En los sistemas intermedios ya que son los que tienen que encaminar
Problemas de Bucles	No hay bucles: el sistema final fija la ruta (ROBUSTEZ).	Sí pueden ocurrir: no se tiene una visión completa de la red (INCONSISTENCIA)
Los bucles (situación que se da cuando los paquetes pasan más de una vez por un nodo) ocurren porque los criterios de los nodos no son coherentes, generalmente debido a que los criterios de encaminamiento o no han convergido después de un cambio en la ruta de un paquete; cuando por cualquier causa un paquete sufre un cambio de encaminamiento, la red tarda en adaptarse a ese cambio pues la noticia del cambio tiene que llegar a todos los nodos. Es en ese transitorio cuando se pueden dar los bucles, ya que unos nodos se han adaptado y otros no. El objetivo de los algoritmos de encaminamiento es detener el curso de los paquetes antes de que se produzcan bucles. Esto es importante sobre todo cuando se envían los paquete s por varias rutas simultáneamente (técnicas de inundación, etc...).

Aplicación práctica
Una red de redes está formada por redes interconectadas mediante routers o encaminadores. Cuando enviamos un datagrama desde un ordenador hasta otro, éste tiene que ser capaz de encontrar la ruta más adecuada para llegar a su destino. Esto es lo que se conoce como encaminamiento.

Los routers (encaminadores) son los encargados de elegir las mejores rutas. Estas máquinas pueden ser ordenadores con varias direcciones IP o bien, aparatos específicos.

Los routers deben conocer, al menos parcialmente, la estructura de la red que les permita encaminar de forma correcta cada mensaje hacia su destino. Esta información se almacena en las llamadas tablas de encaminamiento.

Observemos que debido al sistema de direccionamiento IP esta misión no es tan complicada. Lo único que necesitamos almacenar en las tablas son los prefijos de las direcciones (que nos indican la red). Por ejemplo, si el destino es la máquina 149.33.19.4 con máscara 255.255.0.0, nos basta con conocer el encaminamiento de la red 149.33.0.0 ya que todas las que empiecen por 149.33 se enviarán hacia el mismo sitio.

La orden Route muestra y modifica la tabla de encaminamiento de un host. Todos los hosts (y no sólo los routers) tienen tablas de encaminamientos. A continuación se muestra una tabla sencilla para un host con IP 192.168.0.2 / 255.255.255.0 y puerta de salida 192.168.0.1.

C:\>route print
Rutas activas:
Dirección de red Máscara de red    Puerta de enlace  Interfaz      Métrica
0.0.0.0          0.0.0.0           192.168.0.1       192.168.0.2   1    (7)
127.0.0.0        255.0.0.0         127.0.0.1         127.0.0.1     1    (6)
192.168.0.0      255.255.255.0     192.168.0.2       192.168.0.2   1    (5)
192.168.0.2      255.255.255.255   127.0.0.1         127.0.0.1     1    (4)
192.168.0.255    255.255.255.255   192.168.0.2       192.168.0.2   1    (3)
224.0.0.0        224.0.0.0         192.168.0.2       192.168.0.2   1    (2)
255.255.255.255  255.255.255.255   192.168.0.2       0.0.0.0       1    (1)
Estas tabla se lee de abajo a arriba. La línea (1) indica que los datagramas con destino "255.255.255.255" (dirección de difusión a la red del host) deben ser aceptados. La línea (2) representa un grupo de multidifusión (multicasting). La dirección "224.0.0.0" es una dirección de clase D que se utiliza para enviar mensajes a una colección de hosts registrados previamente. Estas dos líneas se suelen pasar por alto: aparecen en todas las tablas de rutas.

La línea (3) indica que todos los mensajes cuyo destinatario sea "192.168.0.255" deben ser aceptados (es la dirección de difusión a la red del host). La línea (4) se encarga de aceptar todos los mensajes que vayan destinados a la dirección del host "192.168.0.2".

La línea (5) indica que los mensajes cuyo destinatario sea una dirección de la red del host "192.168.0.0 / 255.255.255.0" deben salir del host por su tarjeta de red para que se entreguen directamente en su subred. La línea (6) es la dirección de loopback: todos los paquetes con destino "127.0.0.0 / 255.0.0.0" serán aceptados por el propio host.

Finalmente, la línea (7) representa a "todas las demás direcciones que no se hayan indicado anteriormente". En concreto son aquellas direcciones remotas que no pertenecen a la red del host. ¿A dónde se enviarán? Se enviarán a la puerta de salida (gateway) de la red "192.168.0.1".

Nótese que la tabla de rutas es la traducción de la configuración IP del host que habitualmente se escribe en las ventanas de Windows.



Gestión del encaminamiento IP
No existe un único protocolo para actualizar las tablas de encaminamiento IP, pudiendo elegirse el más adecuado dependiendo de los requisitos internos de las redes a interconectar y las preferencias de cada administrador.

A lo largo del tiempo, se han impuesto distintas soluciones, tanto abiertas como propietarias. Todas ellas operan con estrategias Adaptativas Salto a Salto.


¿Cómo pueden convivir todas ellas? Mediante los Dominios de Encaminamiento o Sistemas Autónomos (SA). Un SA es un conjunto de redes gestionadas por una administración común y que comparten una estrategia de encaminamiento común. En inglés sus siglas son AS.

Cada sistema autónomo:

Elige su arquitectura y protocolos de encaminamiento internos.
Es responsable de la consistencia de sus rutas internas.
Debe recolectar información sobre todas sus redes y designar uno a más routers para pasar la información a otros sistemas autónomos.
Será por tanto necesario definir dos tipos de encaminamiento:

Intradominio o IGP (Internal Gateway Protocol): Es el utilizado dentro del SA. Ejemplos: RIP, OSPF, IGRP, EIGRP, ...
Interdominio o EGP (External Gateway Protocol): Encamina entre Sistemas Autónomos. Ejemplos: BGP, IDPR, ...
Los routers frontera ejecutan el encaminamiento EGP para cambiar información con routers de otros sistemas autónomos, y el IGP para cambiar información con otros routers de su SA:





Sistemas participantes
La función de encaminamiento se realiza principalmente en los routers, aunque en algunas situaciones los hosts también deben participar en la toma de decisiones (para seleccionar el router de su red al que envía el datagrama):

Estrategia básica de envío

Si el host destino se encuentra en la misma red, se encapsula el datagrama IP en una trama de subred, se obtiene la dirección física (mediante ARP) y se envía (entrega directa)
Si no está en la misma subred, se envía el datagrama a un router, éste lo reenvía al siguiente, y así sucesivamente, hasta alcanzar un router conectado a la misma subred que la máquina destino (entrega indirecta)
Para conocer si el host destino se encuentra en la misma subred que el origen, éste compara el prefijo de red de ambas direcciones. Si coinciden, se encuentran en la misma subred.

Para los envíos será necesario llevar a cabo la conversión entre direcciones IP y de subred (física) del destinatario (host o router). Esta función puede desempeñarla el protocolo ARP.

El encaminador sólo modifica los campos TTL y checksum del datagrama, no las direcciones IP origen o destino. Aunque debe obtener la dirección IP del siguiente salto y, a partir de ella, la de subred donde enviará el datagrama.

Tablas de encaminamiento
El encaminamiento IP hace uso de tablas de encaminamiento que se encuentran en cada máquina (hosts y routers, puesto que ambos encaminan datagramas) y almacenan información sobre los posibles destinos y cómo alcanzarlos.

La estrategia es siempre salto a salto (next-hop routing): las tablas almacenan el siguiente salto para las direcciones IP destino. Las direcciones son siempre IP, no físicas, debido a que se facilita su gestión y se ocultan los detalles de las subredes.

Para acelerar el proceso y reducir el consumo de recursos, las tablas sólo necesitan los prefijos de subred de las direcciones IP y no la dirección IP completa.

En un entorno de interconexión total, como el de Internet, no es posible que las tablas contengan la información sobre todas las posibles direcciones destino; se utiliza el principio de información oculta, que permite tomar decisiones de encaminamiento con la información mínima necesaria:

Se aísla la información de hosts dentro del entorno local (subred) donde se encuentran; un host remoto puede enviar datagramas sin conocer al detalle la subred. El esquema de direccionamiento IP está diseñado para ayudar a conseguir éste objetivo.
Se agrupan múltiples entradas de la tabla en una sola, la ruta por defecto.
Nota: Todos los routers listados en la tabla de encaminamiento de un nodo deben de encontrarse en subredes a las que dicho nodo esté conectado directamente (estrategia salto a salto).

Métricas
Una métrica es un valor utilizado por los protocolos de enrutamiento para asignar costos a fin de alcanzar las redes remotas.

La identificación de la mejor ruta de un router implica la evaluación de múltiples rutas hacia la misma red de destino y la selección de la ruta óptima o "la más corta" para llegar a esa red. Cuando existen múltiples rutas para llegar a la misma red, cada ruta usa una interfaz de salida diferente en el router para llegar a esa red. La mejor ruta es elegida por un protocolo de enrutamiento en función del valor o la métrica que usa para determinar la distancia para llegar a esa red.

Las métricas utilizadas en los protocolos de enrutamiento IP incluyen:

Conteo de saltos: una métrica simple que cuenta la cantidad de routers que un paquete tiene que atravesar
Ancho de banda: influye en la selección de rutas al preferir la ruta con el ancho de banda más alto
Carga: considera la utilización de tráfico de un enlace determinado
Retardo: considera el tiempo que tarda un paquete en atravesar una ruta
Confiabilidad: evalúa la probabilidad de una falla de enlace calculada a partir del conteo de errores de la interfaz o las fallas de enlace previas
Costo: un valor determinado ya sea por el IOS o por el administrador de red para indicar la preferencia hacia una ruta. El costo puede representar una métrica, una combinación de las mismas o una política.
Algunos protocolos de enrutamiento, como RIP, usan un conteo de saltos simple, que consiste en el número de routers entre un router y la red de destino. Otros protocolos de enrutamiento, como OSPF, determinan la ruta más corta al analizar el ancho de banda de los enlaces y al utilizar dichos enlaces con el ancho de banda más rápido desde un router hacia la red de destino. Los protocolos de enrutamiento dinámico generalmente usan sus propias reglas y métricas para construir y actualizar las tablas de enrutamiento. Una métrica es un valor cuantitativo que se usa para medir la distancia hacia una ruta determinada. La mejor ruta a una red es la ruta con la métrica más baja. Por ejemplo, un router preferirá una ruta que se encuentra a 5 saltos antes que una ruta que se encuentra a 10 saltos.

El objetivo principal del protocolo de enrutamiento es determinar las mejores trayectorias para cada ruta a fin de incluirlas en la tabla de enrutamiento. El algoritmo de enrutamiento genera un valor, o una métrica, para cada ruta a través de la red. Las métricas se pueden calcular sobre la base de una sola característica o de varias características de una ruta. Algunos protocolos de enrutamiento pueden basar la elección de la ruta en varias métricas, combinándolas en un único valor métrico. Cuanto menor es el valor de la métrica, mejor es la ruta.

Cuando un router tiene múltiples rutas hacia una red de destino y el valor de esa métrica (conteo de saltos, ancho de banda, etc.) es el mismo, esto se conoce como métrica de mismo costo, y el router realizará un balanceo de carga de mismo costo.

La métrica para cada protocolo de enrutamiento es:

RIP: conteo de saltos: la mejor ruta se elige según la ruta con el menor conteo de saltos.
IGRP e EIGRP: ancho de banda, retardo, confiabilidad y carga; la mejor ruta se elige según la ruta con el valor de métrica compuesto más bajo calculado a partir de estos múltiples parámetros. Por defecto, sólo se usan el ancho de banda y el retardo.
IS-IS y OSPF: costo; la mejor ruta se elige según la ruta con el costo más bajo. . La implementación de OSPF de Cisco usa el ancho de banda
Distancia administrativa
Aunque es menos común, puede implementarse más de un protocolo de enrutamiento dinámico en la misma red. En algunas situaciones, posiblemente sea necesario enrutar la misma dirección de red utilizando múltiples protocolos de enrutamiento como RIP y OSPF. Debido a que diferentes protocolos de enrutamiento usan diferentes métricas, RIP usa el conteo de saltos y OSPF usa el ancho de banda, no es posible comparar las métricas para determinar la mejor ruta.

La distancia administrativa (AD) define la preferencia de un origen de enrutamiento. A cada origen de enrutamiento, entre ellas protocolos de enrutamiento específicos, rutas estáticas e incluso redes conectadas directamente, se le asigna un orden de preferencia de la más preferible a la menos preferible utilizando el valor de distancia administrativa. Los routers Cisco usan la función de AD para seleccionar la mejor ruta cuando aprende sobre la misma red de destino desde dos o más orígenes de enrutamiento diferentes.

La distancia administrativa es un valor entero entre 0 y 255. Cuanto menor es el valor, mayor es la preferencia del origen de ruta. Una distancia administrativa de 0 es la más preferida. Solamente una red conectada directamente tiene una distancia administrativa igual a 0 que no puede cambiarse. Cada protocolo tiene AD predeterminada: OSPF 110, EIGRP 90, IGRP 100, RIP 120 que aparecen en las tablas de enrutamiento precediendo a la métrica. La AD de 0 se reserva para las redes conectadas directamente y la de 1 para las redes estáticas.

Ojo, si agregamos una ruta estática que también haya sido aprendida por un protocolo dinámico, la ruta estática tendrá preferencia al tener una distancia administrativa de 1.

Protocolos de enrutamiento con clase y sin clase
Los protocolos de enrutamiento con clase no envían información de la máscara de subred en las actualizaciones de enrutamiento. Los primeros protocolos de enrutamiento tales como el RIP, fueron con clase. En aquel momento, las direcciones de red se asignaban en función de las clases; clase A, B o C. No era necesario que un protocolo de enrutamiento incluyera una máscara de subred en la actualización de enrutamiento porque la máscara de red podía determinarse en función del primer octeto de la dirección de red. Los protocolos de enrutamiento con clase no pueden usarse cuando una red se divide en subredes utilizando más de una máscara de subred; en otras palabras, los protocolos de enrutamiento con clase no admiten máscaras de subred de longitud variable (VLSM).

Los protocolos de enrutamiento sin clase incluyen la máscara de subred con la dirección de red en las actualizaciones de enrutamiento. Las redes de la actualidad ya no se asignan en función de las clases y la máscara de subred no puede determinarse según el valor del primer octeto. La mayoría de las redes de la actualidad requieren protocolos de enrutamiento sin clase porque admiten VLSM, redes no contiguas y otras funciones. Los protocolos de enrutamiento sin clase son RIPv2, EIGRP, OSPF, IS-IS y BGP.

Resumen de rutas
La creación de tablas de enrutamiento más pequeñas hace que el proceso de búsqueda en la tabla de enrutamiento sea más eficiente ya que existen menos rutas para buscar. Si se puede utilizar una ruta estática en lugar de múltiples rutas estáticas, el tamaño de la tabla de enrutamiento se reducirá. En muchos casos, una sola ruta estática puede utilizarse para representar docenas, cientos o incluso miles de rutas.

Podemos utilizar una sola dirección de red para representar múltiples subredes. Por ejemplo, las redes 10.0.0.0/16, 10.1.0.0/16, 10.2.0.0/16, 10.3.0.0/16, 10.4.0.0/16, 10.5.0.0/16, hasta 10.255.0.0/16, pueden representarse con una sola dirección de red: 10.0.0.0/8.

Las múltiples rutas estáticas pueden resumirse en una sola ruta estática si:

las redes de destino pueden resumirse en una sola dirección de red, y
todas las múltiples rutas estáticas utilizan la misma interfaz de salida o dirección IP del siguiente salto.
Protocolos interiores y exteriores
Protocolos interiores (IGP)
Routing Information Protocol (RIP)
Protocolo IGP. RFC 1095. Muy simple y extendido, gracias a que fue incluido en la distribución UNIX BSD (routed)

Características generales:

Vector distancia.
Métrica = número de saltos (de 1 a 15). 16 es infinito.
Dos tipos de participantes: activos (sólo pueden ser routers) y pasivos.
Cada 30 segundos los participantes activos difunden su vector de distancias: duplas de (prefijo IP, distancia).
Utiliza UDP como protocolo de transporte (puerto 520).
Todos los participantes (activos y pasivos) escuchan los mensajes RIP y actualizan sus tablas.
Existe un proceso de borrado de rutas (cada 180 segundos), para mantener las tablas fiables y para recuperarse ante caídas de routers, por ejemplo.
Dos tipos de paquetes. REQUEST: enviados por los routers o hosts que acaban de conectarse o su información ha caducado. RESPONSE: enviados periódicamente, en respuesta a un REQUEST o cuando cambia algún coste.
Actualmente existen dos versiones del protocolo: RIPv1 y RIPv2 (aporta subnetting y autenticación).
Limitaciones:

Existen diferencias entre implementaciones debido a que la RFC tardó un poco en aparecer.
Convergencia lenta (inconsistencias transitorias provocan bucles de encaminamiento). Se han propuesto algunas soluciones, pero son parciales o no sirven para todas las topologías.
Carga las redes innecesariamente. Todos los routers hacen broadcast periódicamente.
Permite 15 saltos como máximo.
Métrica de saltos. No contempla otras posibilidades (caudal, probabilidad de error, etc.)
Open Shortest Path First (OSPF)
Primero el Camino Abierto más Corto. Protocolo IGP. RFC 1247. Presentado en 1990 como sustituto de RIP. Recomendado por la IETF para redes IP.

Características generales:

Escalable: admite redes con miles de encaminadores
Estado de Enlaces
Soporta subnetting: prefijos + máscaras.
Los mensajes OSPF se encapsulan directamente dentro de datagramas IP: no utilizan ningún protocolo de transporte.
Encaminamiento multimétrica. Distinto camino dependiendo del campo TOS de la cabecera IP. También soporta balanceado de carga entre rutas de igual coste.
Encaminamiento jerárquico. Divide el sistema autónomo en áreas. Cada área esconde su topología. El encaminador OSPF sólo necesita conocer la topología de su área.
Tipos de encaminadores: Internal, Area Border, Backbone y AS Boundary.
Tipos de Redes: Point to Point, Broadcast y Non-Broadcast
Inyección de rutas externas: uno o varios encaminadores aprenden rutas externas y las propagan.
Descubrimiento dinámico de encaminadores.
Adaptación a redes locales: aprovecha las redes con difusión hardware para disminuir el número de mensajes OSPF.
Soporte para autentificación, lo que proporciona mayor seguridad y evita ataques.
Protocolos exteriores (EGP)
BGP
Border Gateway Protocol es un protocolo mediante el cual se intercambia información de encaminamiento entre sistemas autónomos.

Entre los sistemas autónomos de los ISP se intercambian sus tablas de rutas a través del protocolo BGP. Este intercambio de información de encaminamiento se hace entre los routers externos de cada sistema autónomo. Estos routers deben soportar BGP. Se trata del protocolo más utilizado para redes con intención de configurar un EGP (external gateway protocol)

Es el protocolo principal de publicación de rutas utilizado por las compañías más importantes de ISP en Internet. BGP4 es la primera versión que admite encaminamiento entre dominios sin clase (CIDR) y agregado de rutas. A diferencia de los protocolos de Gateway internos (IGP), como RIP, OSPF y EIGRP, no usa métricas como número de saltos, ancho de banda, o retardo. En cambio, BGP toma decisiones de encaminamiento basándose en políticas de la red, o reglas que utilizan varios atributos de ruta BGP.

Con BGP los encaminadores en la frontera de un sistema autónomo intercambian prefijos de redes hacia las que saben encaminar. Las rutas aprendidas son inyectadas en el IGP para distribuirlas entre los encaminadores interiores al AS.


Relaciones entre Sistemas Autónomos

Las relaciones que existen entre distintos sistemas autónomos son principalmente de peering y de tránsito. Básicamente una relación de tránsito es la que existe entre un proveedor y un cliente, de modo que el cliente pague por los recursos de Internet que le puede suministrar su proveedor. Las relaciones de peering no suelen se pagadas y consisten en un enlace para comunicar dos sistemas autónomos con el fin de reducir costes, latencia, pérdida de paquetes y obtener caminos redundantes. Se suele hacer peering con sistemas autónomos potencialmente similares, es decir, no se hace peering con un cliente potencial ya que saldría uno de los dos sistemas autónomos beneficiado.



Curiosidad

Durante las protestas de Egipto de 2011 el gobierno de Hosni Mubarak ordenó a todos los proveedores de acceso que operan en el país árabe el corte de las conexiones internacionales. Como consecuencia de los cortes y bloqueos en la noche del 27 al 28 de enero los enrutadores egipcios dejaron de anunciar hasta 3.500 rutas de BGP, dejando al resto de enrutadores sin la información necesaria para intercambiar tráfico con los servidores egipcios.

Fuente y más información:

http://internacional.elpais.com/internacional/2011/01/28/actualidad/1296169207_850215.html

Estructura jerárquica de internet
NOTA: Tier es una palabra inglesa que puede traducirse por nivel.

Una red Tier 1 (Tier 1 ISPs o Internet backbone networks) es capaz de alcanzar cualquier red de Internet sin tener que pagar por tránsito (por enviar sus bits a través de otras redes.)

Grandes proveedores internacionales (AT&T, Deutsche Telekom,
AOL, Telefónica y algunos más)
Conectados directamente a cada uno de los demás Tier 1 ISPs
Conectados a un gran número de Tier 2 ISPs
Cobertura internacional
Los Tier 2 ISPs suelen ser regionales o nacionales y son los

ISPs más comunes.

Se conectan sólo a algunos Tier 1 ISPs (pagando por el uso de sus redes).
También se conectan a muchos otros Tier 2 ISPs (mediante acuerdos de peering), de forma que el tráfico fluye entre ambas redes sin necesidad de usar una red Tier 1.
Pero para alcanzar una gran cantidad de redes necesitan encaminar su tráfico a través de los ISP de nivel 1 a los que están conectados (ellos son los clientes y el Tier 1 el proveedor de tránsito).
Los Tier 3 ISPs son ISPs locales de acceso

Para alcanzar internet solamente contratan tránsito IP (normalmente a ISPs Tier2) ¿Cómo se conectan los ISPs?
Point of Presence (PoP): es un interfaz entre dos ISPs. Pueden estar en las propias instalaciones de un ISP o en un IX.
Internet eXchange point: infraestructura en la que los ISPs intercambian tráfico entre sus redes.
Reducen la cantidad de tráfico que deben enviar a los ISPs superiores → reducción de costes
Aprenden nuevas rutas → mayor eficiencia y tolerancia a fallos
Mantienen el tráfico local → mejor latencia
Actividades
Actividades de teoría
Atendiendo al número de receptores de un paquete, ¿qué tipos de encaminamiento existen? Explicar.
¿En qué se diferencian el encaminamiento estático del encaminamiento dinámico?
¿Qué comando utilizamos para ver la tabla de rutas en un equipo terminal Windows? ¿Y en Linux?
En Windows, desde un terminal de texto, elimina la ruta por defecto con el comando route. Prueba a hacer un ping al equipo 8.8.8.8. Vuelve a añadir la ruta. Vuelve a probar el ping. (Realiza dos capturas de pantalla)
En Linux, desde un terminal de texto, elimina la ruta por defecto con el comando route. Prueba a hacer un ping al equipo 8.8.8.8. Vuelve a añadir la ruta. Vuelve a probar el ping. (Realiza dos capturas de pantalla)
En un equipo terminal, ¿por qué es tan importante la puerta de enlace o ruta por defecto?
Haz un esquema de los distintos protocolos de encaminamiento dinámico que existen, atendiendo a externos o internos. Y en estos últimos según se basen en el vector de distancia o en el estado del enlace.
¿Qué protocolos admiten encaminamiento sin clase?
¿Qué es la distancia administrativa y cuándo es necesaria?
De los protocolos de encaminamiento, ¿cuáles son propietarios?
¿Cómo está organizada Internet? ¿Qué niveles existen?
¿Qué son y por qué son importantes los Internet eXchange points?


Actividades de Packet Tracer
Inicio (comandos básicos)

Router>ping IP
Router>show ip route
Router>enable
Router#configure terminal
Router(config)#no ip domain-lookup

<Aquí ponemos los comandos de enrutamiento>

Fin
Router0(config-router)#exit
Router0(config)#exit
Router0#copy running-config startup-config


Enrutamiento estático
Añadimos rutas estáticas

Router(config)#ip route   RED   MASCARA    SIGUIENT_SALTO
Router(config)#ip route ...
Conecta 2 routers entre sí y comprueba que tienen comunicación entre ellos (utiliza el comando ping). Router1 (11.0.0.1/30), Router2 (11.0.0.2/30). ¿Es necesario configurar tablas de rutas? ¿Por qué? Muestra la tabla de rutas con el comando show ip route.




Añade al Router1 un módulo HWIC-4ESW (4 ports switch). Configura el módulo HWIC-4ESW como se vio en el tema anterior. Añade 4 PC y configura una red diferente para ellos (192.168.1.0/24). Configura la puerta de enlace de cada uno de los PC. Añade una entrada a la tabla de rutas en el Router2 para alcanzar la red 192.168.1.0. Comprueba que hay comunicación entre los PC y el Router2. Muestra la tabla de rutas del Router2 con el comando show ip route.


Router2(config)#ip route 192.168.1.0   255.255.255.0   11.0.0.1




Añade un switch y 4 PC más en otra red. Configura Router1 para alcanzar la red2 (192.168.2.0). Configura Router2 para alcanzar la red1 (192.168.1.0). Comprueba que hay comunicación entre los PC del Router1 y los del Router2. Muestra la tabla de rutas del Router1 con el comando show ip route.
Router1(config)#ip route 192.168.2.0   255.255.255.0   11.0.0.2
Router2(config)#ip route 192.168.1.0   255.255.255.0   11.0.0.1




Añade el Router3 (12.0.0.0/30 hacia Router1; 13.0.0.0/30 hacia Router2). Configura su tabla de rutas. Modifica la tabla de rutas del Router2 para que los envíos que vayan a la red local del Router1 pasen por el Router3. Configura el Router3. Muestra las tablas de rutas de los Router2 y Router3 con el comando show ip route.
Router1(config)#ip route 192.168.2.0   255.255.255.0   11.0.0.2
Router1(config)#ip route 192.168.2.0   255.255.255.0   12.0.0.2
Router2(config)#ip route 192.168.1.0   255.255.255.0   11.0.0.1
Router2(config)#ip route 192.168.1.0   255.255.255.0   13.0.0.2
Router3(config)#ip route 192.168.1.0   255.255.255.0   12.0.0.1
Router3(config)#ip route 192.168.2.0   255.255.255.0   13.0.0.1




Añade un Router4 (con IP 14.0.0.0/30 y 15.0.0.0/30, por ejemplo) con un módulo HWIC-2T para 2 líneas serie. Añade a los Router3 y Router1 otro módulo HWIC-2T. Recuerda Guardar la configuración en ejecución a la NVRAM (Save Running Configuration to NVRAM) antes de apagar los routers si no quieres perderla. Modifica la tabla de rutas de Router3 para que los paquetes que vayan a la red local del Router1 pasen por Router4. Muestra las tablas de rutas de los Router3 y Router4 con el comando show ip route.
Router3(config)#ip route 192.168.1.0   255.255.255.0   12.0.0.1
Router3(config)#ip route 192.168.1.0   255.255.255.0   15.0.0.2
Router4(config)#ip route 192.168.1.0   255.255.255.0   14.0.0.1
Router4(config)#ip route 192.168.2.0   255.255.255.0   15.0.0.1




Añade un Router5 (16.0.0.0/30). Elimina todas las entradas de las tablas de rutas de los Router1 y Router2. Añade a Router1 una entrada para alcanzar la red2 a través del Router2. Añade a Router2 una entrada para alcanzar la red1 a través del Router1. Añade a ambos routers, una ruta por defecto (para enviar datos a cualquier otra red) a través de Router3. Configura Router3 y Router4 para que sus rutas por defecto se encaminen hacia Router5. Muestra las tablas de rutas de los Router3 y Router4 con el comando show ip route.
Router1(config)#ip route 192.168.2.0   255.255.255.0 11.0.0.2
Router1(config)#ip route 0.0.0.0       0.0.0.0       12.0.0.2
Router2(config)#ip route 192.168.1.0   255.255.255.0 11.0.0.1
Router2(config)#ip route 0.0.0.0       0.0.0.0       13.0.0.2
...
Router5(config)#ip route 0.0.0.0       0.0.0.0       16.0.0.1


Enrutamiento dinámico (RIP)
Habilitamos RIP 2 y publicamos rutas adyacentes

Router0(config)#router rip
Router0(config-router)#version 2
Router0(config-router)#network  RED
Router0(config-router)#network  RED


Crea un esquema con 3 routers tal como se muestra. Configura RIP versión 2 en cada uno de ellos. Comprueba que hay comunicación entre PC0 y PC1. ¿Cuáles son las tablas de rutas de Router0 y Router2?
Router0(config)#router rip
Router0(config-router)#version 2
Router0(config-router)#network 10.0.0.0
Router0(config-router)#network 11.0.0.0 
]



Haz que Router1 se publique como ruta por defecto. Cualquier paquete con IP destino que no se halle en las redes mostradas se enviará a Router1, que a su vez lo enviará hacia fuera. Mostrar tabla de rutas de Router0.
Router1(config-router)#default-information originate




Enrutamiento dinámico (OSPF)
Habilitamos OSPF y publicamos rutas adyacentes

Router(config)#router ospf x
Router(config-router)#network  RED   WILDCARD  area 0 
Router(config-router)#network  RED   WILDCARD  area 0

x:        número de proceso (puede tomar un valor entre 1 y 65535)
WILDCARD: inverso binario de la máscara de red.
area 0:   núm. área (aconsejable poner 0 para área única en todos los routers de la misma)


Crea un esquema con 3 routers tal como se muestra. Configura OSPF en cada uno de ellos. Comprueba que hay comunicación entre PC0 y PC1. ¿Cuáles son las tablas de rutas de Router0 y Router2?
Router0(config-router)#network  10.0.0.0   0.255.255.255   area 0
Router0(config-router)#network  11.0.0.0   0.255.255.255   area 0


Haz que Router1 se publique como ruta por defecto. Cualquier paquete con IP destino que no se halle en las redes mostradas se enviará a Router1, que a su vez lo enviará hacia fuera. Mostrar tabla de rutas de Router0.
Router1(config-router)#ip route   0.0.0.0   0.0.0.0   200.0.0.1
Router1(config-router)#default-information originate


Enrutamiento dinámico (BGP)
Habilitamos BGP 

Router(config)#router bgp  x
Router(config-router)#neighbor   IP   remote-as  y
   
Redes detrás del router BGP 
Router(config-router)#network  RED  mask MASK
Router(config-router)#network  RED  mask MASK
Router(config-router)#network  RED  mask MASK
...
 
x, y: números de sistemas autónomos.


Crear el siguiente esquema. Tenemos 2 sistemas autónomos (AS): uno funcionando internamente con RIP (AS=10) y otro con OSPF (AS=20). Como routers frontera tenemos Router1 y Router-1. Configurar BGP en Router1 y Router-1. Mostrar ambas tablas de rutas.
Router-1(config)#router bgp 20
Router-1(config-router)#neighbor  200.0.0.1   remote-as 10
Router-1(config-router)#network   20.0.0.0    mask 255.0.0.0
Router-1(config-router)#network   21.0.0.0    mask 255.0.0.0
Router-1(config-router)#network   22.0.0.0    mask 255.0.0.0
Router-1(config-router)#network   23.0.0.0    mask 255.0.0.0


No olvides crear las rutas por defecto, tanto en Router1 como en Router-1

Router1(config-router)#default-information originate
Router-1(config-router)#ip route   0.0.0.0   0.0.0.0   200.0.0.1
Router-1(config-router)#default-information originate


Añadir a Router1 una red exterior. Configurar la ruta BGP por defecto en Router1. Debes configurar además el equipo exterior 100.0.0.2 con soporte de BGP. Mostrar tablas de rutas de Router-1.
Router1(config-router)#neighbor 100.0.0.2   default-originate




Actividad práctica (Opcional)
Instalar en el ordenador de casa los servicios:
XAMPP (servidor de páginas web)
VNC (servidor de acceso remoto gráfico)
En el router hacer DNAT estático (es decir, abrir y redirigir puertos o port forwarding):
80 (a ordenador de casa)
5800-5810, 5900-5910 (a ordenador de casa)
Hacer DDNS (DNS dinámico), es decir, registrar un nombre de dominio en dyndns, no-ip, o similar.
Bibliografía y referencias
Conceptos generales de enrutamiento
Enrutamiento estático en Cisco
Enrutamiento dinámico (Parte 1) en Cisco
Enrutamiento dinámico (Parte 2) en Cisco
Como funciona la Red: peering & transit (en inglés)
Tema 11



Tema 11: La capa de transporte.
Conceptos generales
Estándares
Técnicas
Herramientas
Actividades
Bibliografía y referencias
Conceptos generales
La capa de red transfiere datagramas entre dos ordenadores a través de la red utilizando como identificadores las direcciones IP. La capa de transporte añade la noción de puerto para distinguir entre los muchos destinos dentro de un mismo host. No es suficiente con indicar la dirección IP del destino, además hay que especificar la aplicación que recogerá el mensaje. Cada aplicación que esté esperando un mensaje utiliza un número de puerto distinto; más concretamente, la aplicación está a la espera de un mensaje en un puerto determinado (escuchando un puerto).

Pero no sólo se utilizan los puertos para la recepción de mensajes, también para el envío: todos los mensajes que envíe un ordenador debe hacerlo a través de uno de sus puertos. El siguiente diagrama representa una transmisión entre el ordenador 194.35.133.5 y el 135.22.8.165. El primero utiliza su puerto 1256 y el segundo, el 80.



La capa de transporte transmite mensajes entre las aplicaciones de dos ordenadores. Por ejemplo, entre nuestro navegador de páginas web y un servidor de páginas web, o entre nuestro programa de correo electrónico y un servidor de correo.



Puertos
Un ordenador puede estar conectado con distintos servidores a la vez; por ejemplo, con un servidor de noticias y un servidor de correo. Para distinguir las distintas conexiones dentro de un mismo ordenador se utilizan los puertos.

Un puerto es un número de 16 bits, por lo que existen 65536 puertos en cada ordenador. Las aplicaciones utilizan estos puertos para recibir y transmitir mensajes.

La asignación de puertos puede obtenerse desde el IANA

Se pueden clasificar en

Puertos bien conocidos (Known Ports: 0 hasta 1023).
Puertos registrados (Registered Ports: 1024 hasta 49151)
Puertos dinámicos y/o privados (Dynamic and/or Private Ports: 49152 hasta 65535)
A continuación se muestra una lista de los puertos más importantes.

Puertos bien conocidos
Puerto/ protocolo	Descripción
0/udp	Reservado
20/tcp	FTP File Transfer Protocol (Protocolo de Transferencia de Ficheros) - datos
21/tcp	FTP File Transfer Protocol (Protocolo de Transferencia de Ficheros) - control
22/tcp	SSH, scp, SFTP
23/tcp	Telnet manejo remoto de equipo, inseguro
25/tcp	SMTP Simple Mail Transfer Protocol (Protocolo Simple de Transferencia de Correo)
53/tcp	DNS Domain Name System (Sistema de Nombres de Dominio)
53/udp	DNS Domain Name System (Sistema de Nombres de Dominio)
67/udp	BOOTP BootStrap Protocol (Server), también usado por DHCP
68/udp	BOOTP BootStrap Protocol (Client), también usado por DHCP
69/udp	TFTP Trivial File Transfer Protocol (Protocolo Trivial de Transferencia de Ficheros)
80/tcp	HTTP HyperText Transfer Protocol (Protocolo de Transferencia de HiperTexto) (WWW)
88/tcp	Kerberos Agente de autenticación
110/tcp	POP3 Post Office Protocol (E-mail)
123/udp	NTP Protocolo de sincronización de tiempo
123/tcp	NTP Protocolo de sincronización de tiempo
137/tcp	NetBIOS Servicio de nombres
137/udp	NetBIOS Servicio de nombres
138/tcp	NetBIOS Servicio de envío de datagramas
138/udp	NetBIOS Servicio de envío de datagramas
139/tcp	NetBIOS Servicio de sesiones
139/udp	NetBIOS Servicio de sesiones
143/tcp	IMAP4 Internet Message Access Protocol (E-mail)
161/tcp	SNMP Simple Network Management Protocol
161/udp	SNMP Simple Network Management Protocol
389/tcp	LDAP Protocolo de acceso ligero a Bases de Datos
389/udp	LDAP Protocolo de acceso ligero a Bases de Datos
443/tcp	HTTPS/SSL para la transferencia segura de páginas web
445/tcp	Microsoft-DS (Active Directory, compartición en Windows, gusano Sasser, Agobot)
445/udp	Microsoft-DS compartición de ficheros
465/tcp	SMTP Sobre SSL. Envío de correo electrónico (E-mail)
631/tcp	CUPS sistema de impresión de Unix
993/tcp	IMAP4 sobre SSL (E-mail)
995/tcp	POP3 sobre SSL (E-mail)
1023/tcp	Reservado
1023/udp	Reservado
Puertos registrados
Puerto/ protocolo	Descripción
1024/tcp/	Reservado
1024/udp	Reservado
1433/tcp	Microsoft-SQL-Server
1512/tcp	WINS Windows Internet Naming Service
2049/tcp	NFS Archivos del sistema de red
3128/tcp	HTTP web cache y por defecto en Squid cache
3306/tcp	MySQL sistema de gestión de bases de datos
3389/tcp	RDP (Remote Desktop Protocol) Terminal Server
4662/tcp	eMule (aplicación de compartición de ficheros)
4672/udp	eMule (aplicación de compartición de ficheros)
4899/tcp	RAdmin (Remote Administrator), herramienta de administración remota (normalmente troyanos)
5432/tcp	PostgreSQL sistema de gestión de bases de datos
5631/tcp	PC-Anywhere protocolo de escritorio remoto
5632/udp	PC-Anywhere protocolo de escritorio remoto
5400/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5500/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5600/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5700/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5800/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5900/tcp	VNC protocolo de escritorio remoto (conexión normal)
6881/tcp	BitTorrent puerto por defecto
6969/tcp	BitTorrent puerto de tracker
8080/tcp	HTTP alternativo. Proxy Web el servidor de almacenamiento en caché. Tomcat.
8118/tcp	privoxy
10000/tcp	Webmin (Administración remota web)
31337/tcp	Back Orifice herramienta de administración remota (por lo general troyanos)
49151/tcp	Reservado
49151/udp	Reservado
Puede encontrarse las lista completa con el servicio asociado en http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml

Estándares
Protocolo UDP
El protocolo UDP (User Datagram Protocol, protocolo de datagrama de usuario) proporciona una comunicación muy sencilla entre las aplicaciones de dos ordenadores. Al igual que el protocolo IP, UDP es:

No orientado a conexión. No se establece una conexión previa con el otro extremo para transmitir un mensaje UDP. Los mensajes se envían sin más y éstos pueden duplicarse o llegar desordenados al destino.
No fiable. Los mensajes UDP se pueden perder o llegar dañados.
UDP utiliza el protocolo IP para transportar sus mensajes. Como vemos, no añade ninguna mejora en la calidad de la transferencia; aunque sí incorpora los puertos origen y destino en su formato de mensaje. Las aplicaciones (y no el protocolo UDP) deberán programarse teniendo en cuenta que la información puede no llegar de forma correcta.



Encabezado UDP	Área de datos UDP	
Encabezado del datagrama	Área de datos del datagrama IP	
Encabezado de la trama	Área de datos de la trama	Final de la trama
Formato del mensaje UDP
0	10	20	30
0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1
Puerto UDP origen	Puerto UDP destino
Longitud mensaje UDP	Suma verificación UDP
Datos
...
Puerto UDP de origen (16 bits, opcional). Número de puerto de la máquina origen.
Puerto UDP de destino (16 bits). Número de puerto de la máquina destino.
Longitud del mensaje UDP (16 bits). Especifica la longitud medida en bytes del mensaje UDP incluyendo la cabecera. La longitud mínima es de 8 bytes.
Suma de verificación UDP (16 bits, opcional). Suma de comprobación de errores del mensaje. Para su cálculo se utiliza una pseudo-cabecera que también incluye las direcciones IP origen y destino. Para conocer estos datos, el protocolo UDP debe interactuar con el protocolo IP.
Datos. Aquí viajan los datos que se envían las aplicaciones. Los mismos datos que envía la aplicación origen son recibidos por la aplicación destino después de atravesar toda la Red de redes.
Protocolo TCP
El protocolo TCP (Transmission Control Protocol, protocolo de control de transmisión) está basado en IP que es no fiable y no orientado a conexión, y sin embargo es:



Orientado a conexión. Es necesario establecer una conexión previa entre las dos máquinas antes de poder transmitir ningún dato. A través de esta conexión los datos llegarán siempre a la aplicación destino de forma ordenada y sin duplicados. Finalmente, es necesario cerrar la conexión.
Fiable. La información que envía el emisor llega de forma correcta al destino.
El protocolo TCP permite una comunicación fiable entre dos aplicaciones. De esta forma, las aplicaciones que lo utilicen no tienen que preocuparse de la integridad de la información: dan por hecho que todo lo que reciben es correcto.

El flujo de datos entre una aplicación y otra viajan por un circuito virtual. Sabemos que los datagramas IP pueden seguir rutas distintas, dependiendo del estado de los encaminadores intermedios, para llegar a un mismo sitio. Esto significa que los datagramas IP que transportan los mensajes siguen rutas diferentes aunque el protocolo TCP logré la ilusión de que existe un único circuito por el que viajan todos los bytes uno detrás de otro (algo así como una tubería entre el origen y el destino). Para que esta comunicación pueda ser posible es necesario abrir previamente una conexión. Esta conexión garantiza que los todos los datos lleguen correctamente de forma ordenada y sin duplicados. La unidad de datos del protocolo es el byte, de tal forma que la aplicación origen envía bytes y la aplicación destino recibe estos bytes.

Sin embargo, cada byte no se envía inmediatamente después de ser generado por la aplicación, sino que se espera a que haya una cierta cantidad de bytes, se agrupan en un segmento y se envía el segmento completo. Para ello son necesarias unas memorias intermedias o buffers. Cada uno de estos segmentos viaja en el campo de datos de un datagrama IP. Si el segmento es muy grande será necesario fragmentar el datagrama, con la consiguiente pérdida de rendimiento; y si es muy pequeño, se estarán enviando más cabeceras que datos. Por consiguiente, es importante elegir el mayor tamaño de segmento posible que no provoque fragmentación.



Encabezado TCP	Área de datos TCP	
Encabezado del datagrama	Área de datos del datagrama IP	
Encabezado de la trama	Área de datos de la trama	Final de la trama
El protocolo TCP envía un flujo de información no estructurado. Esto significa que los datos no tienen ningún formato, son únicamente los bytes que una aplicación envía a otra. Ambas aplicaciones deberán ponerse de acuerdo para comprender la información que se están enviando.

Cada vez que se abre una conexión, se crea un canal de comunicación bidireccional en el que ambas aplicaciones pueden enviar y recibir información, es decir, una conexión es full-dúplex.



Formato del segmento TCP
Ya hemos comentado que el flujo de bytes que produce una determinada aplicación se divide en uno o más segmentos TCP para su transmisión. Cada uno de estos segmentos viaja en el campo de datos de un datagrama IP. Para facilitar el control de flujo de la información los bytes de la aplicación se numeran. De esta manera, cada segmento indica en su cabecera el primer byte que transporta. Las confirmaciones o acuses de recibo (ACK) representan el siguiente byte que se espera recibir (y no el número de segmento recibido, ya que éste no existe).



0	10	20	30
0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1
Puerto TCP origen	Puerto TCP destino
Número de secuencia
Número de acuse de recibo
HLEN	Reservado	Bits código	Ventana
Suma de verificación	Puntero de urgencia
Opciones (si las hay)	Relleno
Datos
...
Puerto fuente (16 bits). Puerto de la máquina origen. Al igual que el puerto destino es necesario para identificar la conexión actual.
Puerto destino (16 bits). Puerto de la máquina destino.
Número de secuencia (32 bits). Indica el número de secuencia del primer byte que trasporta el segmento.
Número de acuse de recibo (32 bits). Indica el número de secuencia del siguiente byte que se espera recibir. Con este campo se indica al otro extremo de la conexión que los bytes anteriores se han recibido correctamente.
HLEN (4 bits). Longitud de la cabecera medida en múltiplos de 32 bits (4 bytes). El valor mínimo de este campo es 5, que corresponde a un segmento sin datos (20 bytes).
Reservado (6 bits). Bits reservados para un posible uso futuro.
Bits de código o indicadores (6 bits). Los bits de código determinan el propósito y contenido del segmento. A continuación se explica el significado de cada uno de estos bits (mostrados de izquierda a derecha) si está a 1.
URG. El campo Puntero de urgencia contiene información válida.
ACK. El campo Número de acuse de recibo contiene información válida, es decir, el segmento actual lleva un ACK. Observemos que un mismo segmento puede transportar los datos de un sentido y las confirmaciones del otro sentido de la comunicación.
PSH. La aplicación ha solicitado una operación push (enviar los datos existentes en la memoria temporal sin esperar a completar el segmento).
RST. Interrupción de la conexión actual.
SYN. Sincronización de los números de secuencia. Se utiliza al crear una conexión para indicar al otro extremo cual va a ser el primer número de secuencia con el que va a comenzar a transmitir (veremos que no tiene porqué ser el cero).
FIN. Indica al otro extremo que la aplicación ya no tiene más datos para enviar. Se utiliza para solicitar el cierre de la conexión actual.
Ventana (16 bits). Número de bytes que el emisor del segmento está dispuesto a aceptar por parte del destino.
Suma de verificación (24 bits). Suma de comprobación de errores del segmento actual. Para su cálculo se utiliza una pseudo-cabecera que también incluye las direcciones IP origen y destino.
Puntero de urgencia (8 bits). Se utiliza cuando se están enviando datos urgentes que tienen preferencia sobre todos los demás e indica el siguiente byte del campo Datos que sigue a los datos urgentes. Esto le permite al destino identificar donde terminan los datos urgentes. Nótese que un mismo segmento puede contener tanto datos urgentes (al principio) como normales (después de los urgentes).
Opciones (variable). Si está presente únicamente se define una opción: el tamaño máximo de segmento que será aceptado.
Relleno. Se utiliza para que la longitud de la cabecera sea múltiplo de 32 bits.
Datos. Información que envía la aplicación.
Fiabilidad
¿Cómo es posible enviar información fiable basándose en un protocolo no fiable? Es decir, si los datagramas que transportan los segmentos TCP se pueden perder, ¿cómo pueden llegar los datos de las aplicaciones de forma correcta al destino?

La respuesta a esta pregunta es sencilla: cada vez que llega un mensaje se devuelve una confirmación (acknowledgement) para que el emisor sepa que ha llegado correctamente. Si no le llega esta confirmación pasado un cierto tiempo, el emisor reenvía el mensaje.

Veamos a continuación la manera más sencilla (aunque ineficiente) de proporcionar una comunicación fiable. El emisor envía un dato, arranca su temporizador y espera su confirmación (ACK). Si recibe su ACK antes de agotar el temporizador, envía el siguiente dato. Si se agota el temporizador antes de recibir el ACK, reenvía el mensaje. Los siguientes esquemas representan este comportamiento:


TCP - Confirmaciones positivas (ACK)



TCP - Temporizador

Este esquema es perfectamente válido aunque muy ineficiente debido a que sólo se utiliza un sentido de la comunicación a la vez y el canal está desaprovechado la mayor parte del tiempo. Para solucionar este problema se utiliza un protocolo de ventana deslizante, que se resume en el siguiente esquema. Los mensajes y las confirmaciones van numerados y el emisor puede enviar más de un mensaje antes de haber recibido todas las confirmaciones anteriores.


TCP - Ventana deslizante
Conexiones
Una conexión son dos pares dirección IP:puerto. No puede haber dos conexiones iguales en un mismo instante en toda la Red. Aunque bien es posible que un mismo ordenador tenga dos conexiones distintas y simultáneas utilizando un mismo puerto. El protocolo TCP utiliza el concepto de conexión para identificar las transmisiones. En el siguiente ejemplo se han creado tres conexiones. Las dos primeras son al mismo servidor Web (puerto 80) y la tercera a un servidor de FTP (puerto 21).



Host 1	Host 2
194.35.133.5:1256	135.22.8.165:80
184.42.15.16:1305	135.22.8.165:80
184.42.15.16:1323	135.22.10.15:21


Para que se pueda crear una conexión, el extremo del servidor debe hacer una apertura pasiva del puerto (escuchar su puerto y quedar a la espera de conexiones) y el cliente, una apertura activa en el puerto del servidor (conectarse con el puerto de un determinado servidor).

Nota: El comando NetStat muestra las conexiones abiertas en un ordenador, así como estadísticas de los distintos protocolos de Internet.

Establecimiento de una conexión
Antes de transmitir cualquier información utilizando el protocolo TCP es necesario abrir una conexión. Un extremo hace una apertura pasiva y el otro, una apertura activa. El mecanismo utilizado para establecer una conexión consta de tres vías.


TCP - Establecimiento de una conexión


La máquina que quiere iniciar la conexión hace una apertura activa enviando al otro extremo un mensaje que tenga el bit SYN activado. Le informa además del primer número de secuencia que utilizará para enviar sus mensajes.
La máquina receptora (un servidor generalmente) recibe el segmento con el bit SYN activado y devuelve la correspondiente confirmación. Si desea abrir la conexión, activa el bit SYN del segmento e informa de su primer número de secuencia. Deja abierta la conexión por su extremo.
La primera máquina recibe el segmento y envía su confirmación. A partir de este momento puede enviar datos al otro extremo. Abre la conexión por su extremo.
La máquina receptora recibe la confirmación y entiende que el otro extremo ha abierto ya su conexión. A partir de este momento puede enviar ella también datos. La conexión ha quedado abierta en los dos sentidos.
Observamos que son necesarios 3 segmentos para que ambas máquinas abran sus conexiones y sepan que la otra también está preparada.

Números de secuencia.— Se utilizan números de secuencia distintos para cada sentido de la comunicación. Como hemos visto el primer número para cada sentido se acuerda al establecer la comunicación. Cada extremo se inventa un número aleatorio y envía éste como inicio de secuencia. Observamos que los números de secuencia no comienzan entonces en el cero. ¿Por qué se procede así? Uno de los motivos es para evitar conflictos: supongamos que la conexión en un ordenador se interrumpe nada más empezar y se crea una nueva. Si ambas han empezado en el cero es posible que el receptor entienda que la segunda conexión es una continuación de la primera (si utilizan los mismos puertos).

Cierre de una conexión
Cuando una aplicación ya no tiene más datos que transferir, el procedimiento normal es cerrar la conexión utilizando una variación del mecanismo de 3 vías explicado anteriormente.

El mecanismo de cierre es algo más complicado que el de establecimiento de conexión debido a que las conexiones son full-duplex y es necesario cerrar cada uno de los dos sentidos de forma independiente.


TCP - Cierre de una conexión


La máquina que ya no tiene más datos que transferir, envía un segmento con el bit FIN activado y cierra el sentido de envío. Sin embargo, el sentido de recepción de la conexión sigue todavía abierto.
La máquina receptora recibe el segmento con el bit FIN activado y devuelve la correspondiente confirmación. Pero no cierra inmediatamente el otro sentido de la conexión sino que informa a la aplicación de la petición de cierre. Aquí se produce un lapso de tiempo hasta que la aplicación decide cerrar el otro sentido de la conexión.
La primera máquina recibe el segmento ACK.
Cuando la máquina receptora toma la decisión de cerrar el otro sentido de la comunicación, envía un segmento con el bit FIN activado y cierra la conexión.
La primera máquina recibe el segmento FIN y envía el correspondiente ACK. Observemos que aunque haya cerrado su sentido de la conexión sigue devolviendo las confirmaciones.
La máquina receptora recibe el segmento ACK.
Técnicas
NAT (Network Address Translation)
Es un estándar creado por la Internet Engineering Task Force (IETF) el cual utiliza una o más direcciones IP para conectar varios computadores a otra red (normalmente a Internet), los cuales tiene una dirección IP completamente distinta (normalmente una IP no válida de Internet). Por lo tanto, se puede utilizar para dar salida a redes públicas a computadores que se encuentran con direccionamiento privado o para proteger máquinas públicas.

Fue inicialmente propuesto como otra solución para la extinción de direcciones IP. Como ya sabemos para poder comunicarse en Internet se requieren direcciones IP públicas únicas (“legales”) para cada host. La idea en la que se basa NAT es que sólo una pequeña parte de la red de una organización está conectada con el exterior simultáneamente, es decir, sólo se asigna una dirección IP pública oficial a un host cuando va a comunicarse con el exterior, por tanto, solo es necesario un pequeño número de direcciones públicas. Los hosts internos pueden utilizar direcciones IP privadas (o direcciones IP no oficiales) y para los paquetes de salida el dispositivo NAT cambia la dirección origen privada por una dirección pública oficial. Igualmente para los paquetes de entrada el dispositivo NAT cambia la dirección pública por otra privada.



Funcionamiento
El protocolo TCP/IP tiene la capacidad de generar varias conexiones simultáneas con un dispositivo remoto. Para realizar esto, dentro de la cabecera de un paquete IP, existen campos en los que se indica la dirección fuente y destino con sus respectivos puertos. Esta combinación de números define una única conexión.

Un encaminador NAT cambia la dirección fuente (lo que se conoce como SNAT, Source NAT) en cada paquete de salida y, dependiendo del método, también el puerto de fuente para que sea único. Estas traducciones de dirección se almacenan en una tabla, para recordar que dirección y puerto le corresponde a cada dispositivo cliente y así saber donde deben regresar los paquetes de respuesta. Si un paquete que intente ingresar a la red interna no existe en la tabla de traducciones, entonces es descartado. Por ello las conexiones que se inicien en el exterior (Internet) hacia el interior (Intranet) no están permitidas, lo que hace que dicho encaminador NAT tenga el “efecto secundario” de servir de cortafuegos.

Debido a este comportamiento, si queremos ofrecer al exterior (Internet) un servicio, se puede definir en la tabla que en un determinado puerto y dirección, se pueda acceder a un determinado dispositivo, como por ejemplo un servidor web, lo que se denomina NAT inverso o DNAT (Destination NAT).

Resumiendo:

SNAT - Source NAT es cuando alteramos el origen del primer paquete: esto es, estamos cambiando el lugar de donde viene la conexión. Source NAT siempre se hace después del encaminamiento, justo antes de que el paquete salga por el cable. El enmascaramiento es una forma especializada de SNAT.

DNAT - Destination NAT es cuando alteramos la dirección de destino del primer paquete: esto es, cambiamos la dirección a donde se dirige la conexión. DNAT siempre se hace antes del encaminamiento, cuando el paquete entra por el cable. El port forwarding (reenvío de puerto), el balanceo de carga y el proxy transparente son formas de DNAT.

Tipos de NAT
NAT tiene muchas formas de funcionamiento, entre las que destaca:

NAT estático (Static NAT): Realiza un mapeo en la que una dirección IP privada se traduce a una correspondiente dirección IP pública de forma unívoca. Normalmente se utiliza cuando un dispositivo necesita ser accesible desde fuera de la red privada.
NAT dinámico (Dynamic NAT): Varias direcciones IP privadas se traducen a una dirección pública. Por ejemplo, si un router posee la IP pública 194.68.10.10, esta dirección se utiliza para representar todo un rango de direcciones privadas como puede ser 192.168.1.x. Implementando esta forma de NAT se genera automáticamente un firewall entre la red pública y la privada, ya que sólo se permite la conexión que se origina desde ésta última.
Sobrecarga
La forma más utilizada de NAT, proviene del NAT dinámico ya que toma múltiples direcciones IP privadas (normalmente entregadas mediante DHCP) y las traduce a una única dirección IP pública utilizando diferentes puertos. Esto se conoce también como PAT (Port Address Translation - Traducción de Direcciones por Puerto), NAT de única dirección o NAT multiplexado a nivel de puerto. Otra denominación es Network Address Port Translation (NAPT).

Herramientas
netstat
Es una herramienta que se ejecuta en modo terminal y que permite ver los puertos que nuestro equipo tiene abiertos.

Está disponible tanto en Windows como en Linux. A menudo se utiliza con opciones, de las cuales las más frecuentes son:

-a:  Muestra todas las conexiones
-n:  Muestra números de puerto
-p:  Muestra programa o aplicación que está usando el puerto
-t:  Puertos TCP (sólo Linux)
-u:  Puertos UDP(sólo Linux)
-l:  Sólo puertos en modo escucha.


Archivo:Netstat -na (Windows).png
netstat -na (Windows)
Archivo:Netstat -punta (Linux).png
netstat -punta (Linux)


nmap
Es una herramienta que se ejecuta en modo terminal y que permite ver los puertos que otro equipo tiene abiertos. Es una herramienta disponible para Windows y Linux, aunque no viene instalada por defecto. Es necesario instalarla.

Nmap es extremadamente potente y dispone de numerosas opciones para realizar distintos tipos de sondeos o escaneos. Dichas opciones pueden consultarse en la página de manual propia.

Archivo:Nmap -sS 192.168.1.1 (Sondeo de puertos abiertos).png
nmap -sS 192.168.1.1 (Sondeo de puertos abiertos)
Archivo:Man nmap (Página de manual de nmap en Linux).png
man nmap (Página de manual de nmap en Linux)

Existe un front-end gráfico conocido como zenmap.

Archivo:Zenmap (front-end para nmap).png
zenmap (front-end para nmap)
Cortafuegos
Un cortafuegos (firewall en inglés) es una parte de un sistema o una red que está diseñada para bloquear el acceso no autorizado, permitiendo al mismo tiempo comunicaciones autorizadas.

Se trata de un dispositivo o conjunto de dispositivos configurados para permitir, limitar, cifrar, descifrar, el tráfico entre los diferentes ámbitos sobre la base de un conjunto de normas y otros criterios.

Existen 2 tipos de cortafuegos:

Personales
De red
Los cortafuegos personales son los que el usuario final instala en su equipo con el fin de proteger dicho equipo.

Los cortafuegos de red son los que se instalan en una Intranet con el fin de proteger todos los equipos que se hallen detrás de él. Una variante de los cortafuegos de red son los cortafuegos de nivel de aplicación de tráfico HTTP, que suelen conocerse mayormente como proxy o proxy-caché (si este dispone de cacheo de páginas web), y permite que los ordenadores de una organización entren a Internet de una forma controlada.



De ahora en adelante nos ocuparemos de los cortafuegos de red.


Los cortafuegos pueden ser implementados en hardware o software, o una combinación de ambos. Los cortafuegos se utilizan con frecuencia para evitar que los usuarios de Internet no autorizados tengan acceso a redes privadas conectadas a Internet, especialmente intranets. Todos los mensajes que entren o salgan de la intranet pasan a través del cortafuegos, que examina cada mensaje y bloquea aquellos que no cumplen los criterios de seguridad especificados. También es frecuente conectar al cortafuegos a una tercera red, llamada «zona desmilitarizada» o DMZ, en la que se ubican los servidores de la organización que deben permanecer accesibles desde la red exterior.




Un cortafuegos correctamente configurado añade una protección necesaria a la red, pero que en ningún caso debe considerarse suficiente. La seguridad informática abarca más ámbitos y más niveles de trabajo y protección.



Políticas del cortafuegos
Hay dos políticas básicas en la configuración de un cortafuegos que cambian radicalmente la filosofía fundamental de la seguridad en la organización:

Política restrictiva: Se deniega todo el tráfico excepto el que está explícitamente permitido. El cortafuegos obstruye todo el tráfico y hay que habilitar expresamente el tráfico de los servicios que se necesiten. Esta aproximación es la que suelen utilizar la empresas y organismos gubernamentales.
Política permisiva: Se permite todo el tráfico excepto el que esté explícitamente denegado. Cada servicio potencialmente peligroso necesitará ser aislado básicamente caso por caso, mientras que el resto del tráfico no será filtrado. Esta aproximación la suelen utilizar universidades, centros de investigación y servicios públicos de acceso a Internet.
La política restrictiva es la más segura, ya que es más difícil permitir por error tráfico potencialmente peligroso, mientras que en la política permisiva es posible que no se haya contemplado algún caso de tráfico peligroso y sea permitido por omisión.

Ejemplos de cortarfuegos para Linux
iptables (su sucesor será nftables)
IPCop
Shorewall
SmoothWall
UFW – Uncomplicated Firewall
Proxy-caché
El término proxy significa intermediario. Un proxy es un equipo o software intermediario que hace peticiones a distintos servidores en representación del equipo que se halla detrás de proxy haciendo uso de él. Las peticiones más frecuentes son aquellas que se realizan a páginas web aunque pueden ser de otro tipo. Pueden ser peticiones HTTP(páginas web), FTP(transferencia de archivos), DNS(resolución de nombres), …

Cuando un proxy hace una petición a un servidor aparece como origen de la petición el mismo proxy ocultando de esta forma el equipo que realizó la petición original detrás del proxy.

Los proxies suelen disponer de una memoria denominada caché donde se van almacenando el resultado de todas las peticiones por si en un futuro próximo otro equipo detrás del proxy realizase la misma petición. Esto tiene dos ventajas:

Aumenta la velocidad de obtención de respuesta puesto que está almacenada en la caché.
Ahorra ancho de banda puesto que dicha petición no tiene que volver a hacerse al servidor.
Debido a que la mayoría de los proxies disponen de una caché, el término empleado para referirse a ellos es el de proxy-caché. En algún caso particular un proxy podría no disponer de caché pero, entonces, no dispondría de las ventajas indicadas anteriormente. Soló proporcionaría cierto anonimato al equipo que realiza peticiones detrás del proxy.

Resumiendo, un proxy, o servidor proxy, en una red informática, es un servidor (un programa o sistema informático), que sirve de intermediario en las peticiones de recursos que realiza un cliente (A) a otro servidor (C). Por ejemplo, si una hipotética máquina A solicita un recurso a C, lo hará mediante una petición a B, que a su vez trasladará la petición a C; de esta forma C no sabrá que la petición procedió originalmente de A. Esta situación estratégica de punto intermedio suele ser aprovechada para soportar una serie de funcionalidades: control de acceso, registro del tráfico, prohibir cierto tipo de tráfico, mejorar el rendimiento, mantener el anonimato, proporcionar Caché web, etc; este último sirve para acelerar y mejorar la experiencia del usuario.

Tipos de proxy-caché según localización
Proxy local
En este caso el que quiere implementar la política es el mismo que hace la petición. Por eso se le llama local. Suelen estar en la misma máquina que el cliente que hace las peticiones. Son muy usados para que el cliente pueda controlar el tráfico y pueda establecer reglas de filtrado que por ejemplo pueden asegurar que no se revela información privada (Proxys de filtrado para mejora de la privacidad).

Proxy externo
El que quiere implementar la política del proxy es una entidad externa. Por eso se le llama externo. Se suelen usar para implementar cacheos, bloquear contenidos, control del tráfico, compartir IP, etc.

Tipos de proxy según su uso
Los proxies que veremos a continuación son todos ellos externos.

Proxy HTTP, FTP, …
Es el tipo de proxy más conocido. Es utilizado ampliamente como intermediario y memoria caché entre una red local e Internet. El tipo de tráfico cacheado principalmente es HTTP y FTP. A menudo se le añade un filtro de contenido con listas negras para bloqueo de determinados sitios. Puede además estar complementado con algún tipo de antivirus que comprobará todo el tráfico destinado a los equipos de la red local, con lo cual, en principio, no sería necesario de disponer de antivirus en cada PC de red, aunque si aconsejable.

Un software muy popular para proxy-caché http es Squid.

Caché DNS
Un servidor de nombres (DNS) en nuestra red local no tiene porque tener configurado un dominio. La configuración más simple es aquella en la cual únicamente actúa como caché DNS (el término proxy no se suele utilizar en este caso). Una caché DNS permite a un navegador web adquirir información de DNS de dicha caché, siempre que esta información se haya almacenado en caché peticiones anteriores, sin la necesidad de acceder a los servidores DNS públicos, lo que resulta en la navegación web más rápida.

El software más utilizado tanto de servidor DNS como caché DNS es Bind. Un software más ligero es dnsmasq.

Proxy inverso
Un servidor proxy inverso es un dispositivo de seguridad que suele desplegarse en la DMZ de una red para proteger a los servidores HTTP de una intranet corporativa, realizando funciones de seguridad que protegen a los servidores internos de ataques de usuarios en Internet.

El servidor proxy inverso protege a los servidores HTTP internos proporcionando un punto de acceso único a la red interna.

El administrador puede utilizar las características de autenticación y control de acceso del servidor proxy inverso para controlar quién puede acceder a los servidores internos y controlar a qué servidores puede acceder cada usuario individual.

Todo el tráfico hacia los servidores de la intranet parece dirigido a una única dirección de red (la dirección del servidor proxy inverso).

El administrador realiza configuraciones de correlación de URL en el servidor proxy inverso que hace esta redirección posible. Todo el tráfico enviado a los usuarios de Internet desde los servidores internos parece proceder de una única dirección de red.

Finalmente, con algoritmos perfeccionados, el proxy inverso puede distribuir la carga de trabajo mediante la redirección de las solicitudes a otros servidores similares. Este proceso se denomina balanceo de carga. Un software muy utilizado para esto es HAProxy.

Proxy web
Los proxy web se utilizan para navegación anónima.

Los equipos de una red local que disponga de un proxy-caché y filtro de contenido, pueden saltárselo mediante el uso de un proxy web. Este último, normalmente funciona sobre HTTPS puesto que dicho tipo de tráfico no es “cacheable” por el proxy de la red local. El administrador del proxy-caché de la red local, a menudo, no puede bloquear el tráfico HTTPS puesto que muchas webs (de correo, compras, administración pública, bancos, …) utilizan dicho protocolo. La solución es elaborar una lista negra con los proxies web más conocidos y activarla en el filtro de contenido.



Cortafuegos y Proxy-caché en un sólo equipo
Proxies transparentes
Muchas organizaciones (incluyendo empresas, colegios y familias) usan los proxies para reforzar las políticas de uso de la red o para proporcionar seguridad y servicios de caché. Normalmente, un proxy Web o NAT no es transparente a la aplicación cliente: debe ser configurada para usar el proxy, manualmente. Por lo tanto, el usuario puede evadir el proxy cambiando simplemente la configuración.






Un proxy transparente combina un servidor proxy con un cortafuegos de manera que las conexiones son interceptadas y desviadas hacia el proxy sin necesidad de configuración en el cliente, y habitualmente sin que el propio usuario conozca de su existencia.


Además, suele ser frecuente en el proxy-caché la instalación de un servicio de control de acceso a la web y algún antivirus de red. El control de acceso a la web normalmente se implementa mediante algún tipo de software de filtrado por contenido (además de URL e IP, puede bloquear accesos a páginas web según el contenido de estás (palabras desagradables, obscenas o similares e incluso por imágenes -aunque esté último método suele dar peores resultados-). Un software libre muy utilizado para ello es Dansguardian y sus listas negras asociadas.



Archivo:Squid + Dansguardian.png
Squid + Dansguardian

A continuación se muestra un ejemplo de script Linux para cortafuegos con reglas activadas para habilitar un proxy-transparente. Básicamente lo que hace es dirigir todas las petición a puertos destino 80 (web), 3128 (cliente despistado con configuración manual de proxy) y algunos otros puertos que nos interesen al puerto 8080 (dansguardian) donde tenemos el filtro de contenido.



#!/bin/sh
### BEGIN INIT INFO
# Provides:          cortafuegos
# Required-Start:    balanceo-de-carga
# Required-Stop:
# Should-Start:
# Default-Start:     2 3 4 5
# Default-Stop:      0 1 6
# Short-Description: Cortafuegos para IES Guadalpeña - Dpto. Informática
# Description:       Cortafuegos contiene las reglas de iptables que se aplicarán
#                    después de la configuración del soporte de red o networking
#                    y del balanceo de carga (si está habilitado).
#                    Proporciona redirección de puertos en el canal PREROUTING 
#                    para dar soporte a un proxy transparente.
### END INIT INFO
# Variables generales
PATH=/sbin:/usr/sbin:/bin:/usr/bin
NAME=cortafuegos
PIDFILE=/var/run/$NAME.pid
# Variables de red
IF_ADSL1="p1p1"            # Interface conectada a ADSL1
IF_ADSL2="p4p1"            # Interface conectada a ADSL2
IF_LOCAL="p2p1"            # Interface conectada a la LAN
IP_ADSL1="192.168.1.2"     # IP de la IF_ADSL1
IP_ADSL2="192.168.2.2"     # IP de la IF_ADLS2
IP_LOCAL="10.0.0.1"        # IP de la IF_LOCAL, Gateway Local
NET_ADSL1="192.168.1.0/24" # Red para IF_ADSL1
NET_ADSL2="192.168.2.0/24" # Red para IF_ADLS2
NET_LOCAL="10.0.0.0/8"     # Red para IF_LOCAL
GW_ADSL1="192.168.1.1"     # Gateway para ADSL1
GW_ADSL2="192.168.2.1"     # Gateway para ADSL2
###### START
do_start () {
# Reglas de iptables 
echo "Limpiando Reglas Anteriores..."
iptables -F
iptables -X
iptables -Z
iptables -t nat -F
iptables -t mangle -F

# Ahora hago el NAT
echo "Activando NAT ..."
echo 1 > /proc/sys/net/ipv4/ip_forward
# iptables -t nat -A POSTROUTING -s ${NET_LOCAL} -o ${IF_ADSL1} -j MASQUERADE
# iptables -t nat -A POSTROUTING -s ${NET_LOCAL} -o ${IF_ADSL2} -j MASQUERADE
iptables -t nat -A POSTROUTING -o ${IF_ADSL1} -j SNAT --to-source ${IP_ADSL1}
iptables -t nat -A POSTROUTING -o ${IF_ADSL2} -j SNAT --to-source ${IP_ADSL2}

# Redirecciono al Proxy
echo "Creando reglas para proxy transparente..."
iptables -t nat -A PREROUTING -i ${IF_LOCAL} -p tcp --dport http      -j DNAT --to ${IP_LOCAL}":8080"
iptables -t nat -A PREROUTING -i ${IF_LOCAL} -p tcp --dport 81        -j DNAT --to ${IP_LOCAL}":8080"
iptables -t nat -A PREROUTING -i ${IF_LOCAL} -p tcp --dport 8080:8099 -j DNAT --to ${IP_LOCAL}":8080"
iptables -t nat -A PREROUTING -i ${IF_LOCAL} -p tcp --dport 3128:3130 -j DNAT --to ${IP_LOCAL}":8080"

#echo "Reglas Aplicadas"
}
###### STATUS
do_status () {
echo "Listado de Reglas activas"
iptables -L -n -v
iptables -t nat -L -n -v
iptables -t mangle -L -n -v
}
###### STOP
do_stop () {
echo "Limpiando Reglas anteriores..."
iptables -F
iptables -X
iptables -Z
iptables -t nat -F
iptables -t mangle -F
}
case "$1" in
  start|"")
        do_start
        ;;
  restart)
        do_stop
        do_start
        ;;
  reload|force-reload)
        echo "Error: el argumento '$1' no está soportado" >&2
        exit 3
        ;;
  stop)
        do_stop
        ;;
  status)
        do_status
        ;;
  *)
        echo "Uso: cortafuegos [start|stop|restart|status]" >&2
        exit 3
        ;;
esac
:


Balanceadores de carga de red
En informática, el balanceo de carga distribuye las cargas de trabajo a través de múltiples recursos informáticos, como procesadores (balanceo de cómputo), enlaces de red (balanceo de red), ordenadores, cluster de ordenadores o unidades de disco. El balanceo de carga tiene como objetivo optimizar el uso de recursos, maximizar el rendimiento, minimizar el tiempo de respuesta y evitar la sobrecarga de cualquier recurso individual. El uso de varios componentes con el equilibrio de carga en lugar de un solo componente puede aumentar la confiabilidad mediante redundancia. El equilibrio de carga por lo general implica software o hardware dedicado, tal como un switch multicapa o un proceso DNS .

El balanceo de carga difiere del channel bonding en que el primero se realiza en la capa 4 del modelo OSI, mientras que el channel bonding hace la división del tráfico en un nivel inferior, ya en la capa 3 del modelo OSI o en el enlace de datos capa 2 del modelo OSI).

Existen distintos tipos de balanceo de carga según el elemento equilibrado siendo los más frecuentes:

Balanceo de carga entre procesadores (Operaciones de cómputo)
Balanceo de carga entre líneas de red (Tráfico de red)
Aquí se tratará el balanceo de carga de red y en concreto los dos tipos existentes:

Balanceo de carga en el lado cliente
Balanceo de carga en el lado servidor
Balanceo en el lado cliente (Multihoming)
El Multihoming (comúnmente conocido como ruta de doble WAN) es la capacidad de equilibrar el tráfico a través de dos o más enlaces WAN sin necesidad de utilizar protocolos de enrutamiento complejos como BGP.

Esta técnica equilibra sesiones de red como web, correo electrónico, etc a través de múltiples conexiones con el fin de extender la cantidad de ancho de banda utilizado por los usuarios de la LAN, lo que aumenta la cantidad total de ancho de banda disponible. Por ejemplo, un usuario tiene una única conexión a la WAN a 10 Mbit/s. Desea añadir una segunda línea de banda ancha (cable, DSL, inalámbrico, etc.) a 20 Mbit/s. Esto les proporcionará un total de 30 Mbits/s de ancho de banda para balancear sesiones.

El balanceo de sesión no sólo eso, equilibra sesiones a través de cada enlace WAN. Cuando los navegadores Web se conectan a Internet, que comúnmente se abren varias sesiones, una para el texto, otra para una imagen, otro por alguna otra imagen, etc. Cada una de estas sesiones pueden ser equilibradas a través de las conexiones disponibles. Una aplicación FTP sólo utiliza una sola sesión por lo que no está equilibrada; sin embargo, si se realiza una conexión FTP secundaria, entonces puede ser equilibrada por lo que, en conjunto, el tráfico se distribuye uniformemente a través de las diversas conexiones y por lo tanto proporciona un aumento global en el rendimiento.

A continuación se muestra un esquema de red donde se puede realizar “balanceo de carga” con 2 líneas de salida a internet.



Balanceo de carga en el lado servidor
El problema a solucionar es la sobrecarga de los servidores. Se puede balancear cualquier protocolo, pero dado que este sitio se centra en las tecnologías web, el artículo trata exclusivamente de balancear servidores HTTP.

Al mismo tiempo, si el balanceador detecta la caída de uno de los servidores web, puede optar por no enviarle más peticiones. De esta forma, si uno de los servidores web se cae, las peticiones del cliente no se dirigen al servidor caído.

Vemos que el balance de carga también contribuye a una infraestructura redundante y de alta disponibilidad (aunque no la asegura, el balance de carga por sí mismo no alcanza para tener HA1 ). En este punto creo conveniente introducir los conceptos básicos que se manejarán a lo largo del artículo:

Balanceador: es un sistema, software o hardware, que distribuye las peticiones de los clientes de forma equitativa entre distintos servidores de “backend”.
Servidor de backend: es un servidor (web en este caso), que responde la petición del usuario.
Así el balanceador distribuye las peticiones y son los servidores de backend, quienes arman la respuesta efectiva al cliente. Para balancear la carga entre varios servidores es deseable que el mismo balanceador sea justo (fair), y que detecte servidores sobrecargados para dejar de enviarle peticiones hasta que no baje su carga. Este mismo mecanismo sirve para que un balanceador no envíe peticiones a un servidor caído.





Balanceo mediante DNS
La forma más elemental de balancear la carga entre varios servidores esa utilizando el DNS. Por ejemplo, buscando la IP de yahoo.com con el comando dig he obtenido el siguiente resultado. En este caso responden 3 servidores: 206.190.36.45, 98.139.183.24 y 98.138.253.109.


Balanceo mediante DNS
Este es el tipo de balanceo más elemental que se puede hacer, y tiene una ventaja muy importante: simplicidad y eﬁciencia; ya que en principio lo único que se necesitan son varios servidores con distintas IPs, por lo que es barato, simple y fácil de mantener. Sin embargo, el balance de carga por DNS tiene algunos inconvenientes:

El balanceo mediante DNS no tiene en cuenta la carga de cada servidor.
El balanceo mediante DNS no detecta si un servidor ha caído.
Balanceo mediante balanceador
Una solución menos simple pero más adecuada es utilizar un hardware o software balanceador de carga. Debemos tener en cuenta que un balanceador de este tipo es por definición un proxy inverso. Actualmente un software muy utilizado es HAProxy.

Los balanceadores de carga tienen varias ventajas sobre el balanceado mediante DNS:

Un balanceador puede tener en cuenta la carga de cada equipo y distribuir las peticiones según esas cargas.
Si un servidor queda fuera de línea, el balanceador de carga lo detecta y redirige las peticiones web a los otros servidores..
Por último, la mayoría de los balanceadores pueden mantener las sesiones de los usuarios, de forma que un usuario que inicia sesión en el servidor “A” siempre sea dirigido por el balanceador al mismo servidor “A” (de no hacerlo el usuario perdería la sesión). Sin embargo, el balance de carga por DNS es del tipo “Round Robin”, por lo que es casi seguro que el usuario pierda la sesión.


VPN
Una red privada virtual, RPV, o VPN de las siglas en inglés de Virtual Private Network, es una tecnología de red que permite una extensión segura de la red local (LAN) sobre una red pública o no controlada como Internet. Permite que la computadora en la red envíe y reciba datos sobre redes compartidas o públicas como si fuera una red privada con toda la funcionalidad, seguridad y políticas de gestión de una red privada. Esto se realiza estableciendo una conexión virtual punto a punto mediante el uso de conexiones dedicadas, cifrado o la combinación de ambos métodos.

Ejemplos comunes son la posibilidad de conectar dos o más sucursales de una empresa utilizando como vínculo Internet, permitir a los miembros del equipo de soporte técnico la conexión desde su casa al centro de cómputo, o que un usuario pueda acceder a su equipo doméstico desde un sitio remoto, como por ejemplo un hotel. Todo ello utilizando la infraestructura de Internet.

El protocolo estándar de facto es el IPSEC, pero también están PPTP, L2F, L2TP, SSL/TLS, SSH, etc. Cada uno con sus ventajas y desventajas en cuanto a seguridad, facilidad, mantenimiento y tipos de clientes soportados.

Aplicaciones software muy conocidas son Hamachi para uso doméstico y OpenVPN para uso en empresas.

Básicamente existen 2 tipos de conexión VPN:

VPN de acceso remoto
Es quizás el modelo más usado actualmente, y consiste en usuarios o proveedores que se conectan con la empresa desde sitios remotos (oficinas comerciales, domicilios, hoteles, aviones preparados, etcétera) utilizando Internet como vínculo de acceso. Una vez autenticados tienen un nivel de acceso muy similar al que tienen en la red local de la empresa. Muchas empresas han reemplazado con esta tecnología su infraestructura dial-up (módems y líneas telefónicas).

VPN punto a punto
Este esquema se utiliza para conectar oficinas remotas con la sede central de la organización. El servidor VPN, que posee un vínculo permanente a Internet, acepta las conexiones vía Internet provenientes de los sitios y establece el túnel VPN. Los servidores de las sucursales se conectan a Internet utilizando los servicios de su proveedor local de Internet, típicamente mediante conexiones de banda ancha. Esto permite eliminar los costosos vínculos punto a punto tradicionales (realizados comúnmente mediante conexiones de cable físicas entre los nodos), sobre todo en las comunicaciones internacionales. Es más común el siguiente punto, también llamado tecnología de túnel o tunneling.

Tunneling
La técnica de tunneling consiste en encapsular un protocolo de red sobre otro (protocolo de red encapsulador) creando un túnel dentro de una red de computadoras. El establecimiento de dicho túnel se implementa incluyendo una PDU (unidades de datos de protocolo) determinada dentro de otra PDU con el objetivo de transmitirla desde un extremo al otro del túnel sin que sea necesaria una interpretación intermedia de la PDU encapsulada. De esta manera se encaminan los paquetes de datos sobre nodos intermedios que son incapaces de ver en claro el contenido de dichos paquetes. El túnel queda definido por los puntos extremos y el protocolo de comunicación empleado, que entre otros, podría ser SSH.

Actividades
En términos informáticos, referido a redes, ¿qué es un puerto?
Atendiendo al número de puerto, ¿cómo se clasifican?
¿Qué número de puerto y tipo (TCP, UDP) utilizan los siguientes servidores?
HTTP
HTTPS
DHCP
DNS
SSH
FTP
SMB (Compartición de archivos e impresoras)
MySQL
NTP (Tiempo de red)
BitTorrent
POP3 (Recepción de correo)
IMAP4 (Recepción de correo)
SMTP (Envío de correo)
¿Cuáles son los principales protocolos de la capa de transporte?
Características de UDP.
Características de TCP.
Campos de un segmento TCP. Bits SYN, ACK y FIN.
Cuando abrimos un puerto, ¿qué es una apertura pasiva y qué es una apertura activa?
Proceso de inicio de una conexión TCP.
Proceso de cierre de una conexión TCP.
Cuando se utiliza traducción de direcciones, la traducción de la dirección IP origen se denomina _________________________________
Cuando se utiliza traducción de direcciones, la traducción estática de direcciones se denomina _____________________________
Cuando se utiliza traducción de direcciones, la traducción de la dirección IP destino se denomina ___________________________
Cuando se utiliza traducción de direcciones, la traducción dinámica de direcciones se denomina ____________________________
Si tenemos un router NAT, ¿es posible iniciar una conexión desde Internet a nuestra Intranet a través de él? ¿Por qué? En el caso de que no sea posible, ¿qué debemos hacer para que lo sea?
Tipos de cortafuegos dependiendo del lugar de la red donde se colocan.
Tipos de políticas de los cortafuegos.
¿Qué es el SNAT? ¿Y el enmascaramiento?
¿Qué es el DNAT? Explica cada uno de los siguientes tipos de DNAT:
Port forwarding (redirección de puertos)
Balanceo de carga
Proxy transparente


IPTABLES.
Uso de iptables
iptables -t TABLA -L                      Listado de reglas
iptables -t TABLA -F                      Flush de reglas (borrado total)
 
iptables -t TABLA -P CANAL ACCEPT        Política por defecto permisiva
iptables -t TABLA -P CANAL DROP          Política por defecto restrictiva
 
iptables -t TABLA -A CANAL REGLA          Añadir regla
iptables -t TABLA -D CANAL REGLA          Borrar regla
TABLAS	CANALES o CADENAS
filter	INPUT, FORWARD, OUTPUT
nat	PREROUTING, POSTROUTING
mangle	


REGLAS	SIGNIFICADO
-s IP	Dirección IP origen
-d IP	Dirección IP destino
-i INTERFAZ	Tarjeta de red de entrada. Input
-o INTERFAZ	Tarjeta de red de salida. Output
-p PROTOCOLO	Protocolo (tcp, udp, icmp, ...)
--sport PUERTO	Puerto de origen. Source port
--dport PUERTO	Puerto de destino. Dest. port
-j ACCEPT	Aceptar paquetes
-j DROP	Ignorar paquetes
EJEMPLOS DE REGLAS:

Aceptamos paquetes TCP al puerto 80 desde cualquier IP.
iptables -t filter -A INPUT -s 0.0.0.0/0 -p tcp --dport 80 -j ACCEPT

Bloqueamos paquetes al servidor MySQL
iptables -t filter -A INPUT -p tcp --dport 3306 -j DROP

Permitimos salida a peticiones HTTPS
iptables -t filter -A OUTPUT -p tcp -m tcp --dport 443 -j ACCEPT

Permitimos que los equipos de la red 192.168.10.0 conectados a mi tarjeta eth1 puedan ver páginas web
iptables -t filter -A FORWARD -s 192.168.10.0/24 -i eth1 -p tcp --dport 80 -j ACCEPT

Política de preenrutamiento
iptables -t nat -P PREROUTING ACCEPT

Política de preenrutamiento
iptables -t nat -P POSTROUTING ACCEPT

Todo lo que venga por la tarjeta eth0 y vaya al puerto 80 lo redirigimos a una maquina interna
iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j DNAT --to 192.168.10.12:80
 
Todo lo que salga de nuestra red 192.168.10.0 por la tarjeta eth0 se enmascara (es un tipo de SNAT)
iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -o eth0 -j MASQUERADE

Haciendo uso del resumen que aparece arriba y de los ejemplos que aparecen en http://www.pello.info/filez/firewall/iptables.html, ¿cómo escribirías las siguientes reglas?

Hacer un listado de reglas de la tabla filter.
Hacer un listado de reglas de la tabla nat.
Hacer un borrado total (flush) de reglas de la tabla filter.
Hacer un borrado total (flush) de reglas de la tabla nat.
No permitir entrada del equipo 10.0.5.200 al servidor web de nuestro equipo
No permitir entrada del equipo 10.0.5.200 al servidor web 20.20.20.20.
Poner política por defecto ACCEPT para los canales INPUT, FORWARD y OUTPUT.
Poner política por defecto ACCEPT para los canales PREROUTING y POSTROUTING.
Hacer un enmascaramiento de los paquetes de nuestra red 10.0.5.0/24 que salen por eth2. (SNAT)
Todo lo que venga por la tarjeta eth0 destinado al puerto 80 se manda a 10.0.5.222 y puerto 8080. (DNAT)
Ejecuta netstat -na en tu equipo Windows. Muestra una captura de los puertos abiertos.
Ejecuta netstat -punta en un equipo Linux. Muestra una captura de los puertos abiertos.
Ejecuta Zenmap desde un equipo (Windows o Linux). Realiza las siguientes operaciones:
Ver puertos abiertos del equipo 10.0.5.1.
Ver lista de equipos en nuestra subred 10.0.5.0/24.
Ver puertos abiertos de los equipos www.google.es y 8.8.8.8
Hacer un trazado de ruta a los equipos anteriores. Hacer una captura de pantalla donde se muestre la topología.
Hacer un trazado de ruta a www.google.es/30. Hacer una captura de pantalla donde se muestre la topología.
Hacer un pequeño tutorial de configuración de un punto de acceso. (Opcional)
Estado del AP.
Claves de acceso.
Modos de funcionamiento (Repetidor, Bridge, Punto de Acceso, ...)
Configuración de la red Wi-Fi (SSID, Seguridad).
Hacer un pequeño tutorial de configuración de un router.
Estado del router.
Claves de acceso al router.
Configuración de IP Interna / Máscara.
Configuración del DHCP.
Configuración de la red Wi-Fi (SSID, Seguridad) si es un router inalámbrico.
Filtrado de MAC si está disponible.
NAT. Port forwarding. Apertura de puertos.
Hacer un pequeño tutorial de configuración de un switch gestionable si está disponible. (Opcional)
Estado del switch.
Claves de acceso.
Configuración de IP Interna / Máscara.
Configuración de VLANs si está disponible.
¿Qué es y para que sirve un proxy? Ventajas de su uso.
¿Qué diferencias existen entre un proxy normal y uno inverso?
Si tenemos 3 líneas ADSL de distintos ISP y queremos utilizarlas a la vez para nuestra red local para tener una conexión a Internet tolerante a fallos y mayor ancho de banda, ¿qué técnica podemos utilizar?
Tenemos 4 servidores web con el mismo contenido y queremos balancear las peticiones de los clientes entre los 4 servidores. Explica las 2 formas principales de hacerlo.


Bibliografía y referencias
RFC 2663
Listados de puertos más frecuentemente usados
Explicación de la técnica NAT
Explicación de todos los tipos de NAT (en inglés)
NAT en Cisco
Port Forwardind o Redirección de puertos
Manual práctico de IPTABLES
Documentación de IPROUTE2
Manual de proxy-caché transparente en PDF
Balanceo de carga en el lado cliente con iptables e iproute2
Instalación y configuración básica de HAProxy
HAproxy configuration and Load balancing Part 1
HAproxy configuration and Load balancing Part 2
Tema 12




Bibliografía y referencias
Control de Acceso al Medio (MAC) de distintas tecnologías
Antiguo módem analógico
LMDS
Blog francés acerca de la fibra óptica (fotos interesantes)
Proyecto Innovación sobre Fibra y Redes




ENLACES

Material CISCO CCNA
Módulo de PAR en IES Suárez de Figueroa (Extremadura)
Módulo de PAR en IES Gonzalo Narareno (Andalucía)
y por supuesto

Google
Wikipedia, la enciclopedia libre
YouTube
Contenido del Libro Grado de desarrollo: 75% (a fecha de 19:58 04 feb 2015 (UTC))
Versión: Junio 2015












Planificación y Administración de RedesGrado de desarrollo: 75% (a fecha de 20:03 04 feb 2015 (UTC))▶[+32] Índice, Introducción, Página de edición, Enlaces, Texto completo
Este es un libro de redes. Está especialmente orientado a los contenidos de Grado Superior del ciclo de Administración de Sistemas Informáticos en Red de la Familia Profesional de Informática y Comunicaciones en la Formación Profesional de Andalucía, España.
Se pueden orientar los contenidos, en parte, al módulo de "Redes Locales" del ciclo de grado de Sistemas Microinformáticos y Redes (SMR) de la Familia Profesional de Informática y Comunicaciones.
Y, por supuesto, puede ser útil para cualquier persona que desee adquirir los conocimientos de cómo se organizan y funcionan las redes.▶

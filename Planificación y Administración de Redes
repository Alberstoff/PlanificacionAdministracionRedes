






Tema 9: Redes locales virtuales.
Introducción
Conceptos generales
Protocolos
Caso práctico
Actividades
Bibliografía y referencias
Introducción
Una VLAN (acrónimo de virtual LAN, «red de área local virtual») es un método para crear redes lógicas independientes dentro de una misma red física. Varias VLAN pueden coexistir en un único conmutador físico o en una única red física. Son útiles para reducir el tamaño del dominio de difusión y ayudan en la administración de la red, separando segmentos lógicos de una red de área local (los departamentos de una empresa, por ejemplo) que no deberían intercambiar datos usando la red local (aunque podrían hacerlo a través de un enrutador o un conmutador de capa 3).



Tipos de VLAN
Las dos aproximaciones más habituales para la asignación de miembros de una VLAN son las siguientes:

VLAN estáticas
VLAN dinámicas.
Las VLAN estáticas también se denominan VLAN basadas en el puerto. Las asignaciones en una VLAN estática se crean mediante la asignación de los puertos de un switch o conmutador a dicha VLAN. Cuando un dispositivo entra en la red, automáticamente asume su pertenencia a la VLAN a la que ha sido asignado el puerto. Si el usuario cambia de puerto de entrada y necesita acceder a la misma VLAN, el administrador de la red debe cambiar manualmente la asignación a la VLAN del nuevo puerto de conexión en el switch.

En las VLAN dinámicas, el administrador de la red puede asignar los puertos que pertenecen a una VLAN de manera automática basándose en información tal como la dirección MAC del dispositivo que se conecta al puerto o el nombre de usuario utilizado para acceder al dispositivo. En este procedimiento, el dispositivo que accede a la red, hace una consulta a la base de datos de miembros de la VLAN.

Características
Las VLANs permiten dividir la red local en redes virtuales
Los equipos de la red que pertenecen a la misma VLAN pueden comunicarse entre ellos como si estuvieran conectados al mismo switch
La comunicación entre estaciones de diferentes VLANs requiere un dispositivo de nivel 3
A cada VLAN se le asigna un identificador de distinto color:
Los puertos de los switches quedan coloreados
Los puertos que unen switches se considera que pertenecen a la unión de los colores de los dos switches
Sólo se envía una trama por un puerto cuando la LAN origen y destino tienen el mismo color (es decir, ambos puertos pertenecen a la misma VLAN)
Ventajas
Permiten reconfigurar si hay un cambio sin tocar cables ni switches
Aumenta la seguridad
Aumenta el rendimiento de la red al separar dominios de difusión
La organización de la red se basa en las tareas de los usuarios y no en su localización física.
Conceptos generales
Tipos de puertos
En un switch, atendiendo a su función dentro de la VLAN, existirán dos tipos de puertos:

Puertos de acceso (access)
Puertos troncales (trunk)
Los puertos de acceso son aquellos a los que se conectan directamente los equipos terminales (ordenadores o periféricos). Por ellos solo viajan tramas pertenecientes a una única VLAN.

Los puertos troncales son aquellos por los que circulan tramas de una o más VLANs. Para distinguir el tráfico de las distinta VLANs es necesario etiquetar las tramas indicando que VLAN pertenecen.

Enlaces troncales (trunk)
Los enlaces troncales o trunks, son enlaces capaces de transportar el tráfico de más de una VLAN y se suele utilizar para interconectar dos switches, un switch y un router, incluso interconectar un switch y un servidor al cual se le ha instalado una NIC especial capaz de soportar trunking. Los enlaces troncales nos permiten transportar de forma lógica las VLANs utilizando un enlace físico.



Un enlace troncal (trunk) puede ser un único enlace físico o estar conformado por varios de ellos usando la técnica de agregación (link agregation) que permite combinar varios enlaces físicos en un enlace lógico que funciona como un único puerto de mayor ancho de banda.

Otras denominaciones para la agregación de enlaces son Trunking o Bonding. Cisco lo denomina EtherChannel (Modos: ON, PAgP o LACP).



Etiquetado
Los puertos de un switch pueden estar etiquetados (tagged) o no etiquetados (untagged).

En un enlace troncal es necesario diferenciar el tráfico de cada una de las VLANs, de tal forma que se le asigna a cada trama entrante un identificador llamado VLAN-ID. Para poder identificar el tráfico en un enlace troncal existen dos tipos de etiquetado:

ISL (Inter-Switch Link Protocol)
IEEE 802.1Q
ISL (Inter-Switch Link Protocol)
ISL es un protocolo propietario de Cisco que está en desuso. Este protocolo no altera la trama original, porque éste encapsula la trama Ethernet con una nueva cabecera de 26 bytes, que contiene al identificador VLAN (VLAN ID), y además añade un campo de secuencia de chequeo de trama (FCS ó CRC) de 4 bytes al final de la trama, como se muestra en la figura. Por lo tanto, como la trama ha sido encapsulada por ISL con nueva información, solamente los dispositivos que conozcan ISL podrán leer estas nuevas tramas.


VLAN - Trama ISL
IEEE 802.1Q
El estándar IEEE 802.1Q (también llamado dot1q) especifica el etiquetado de tramas como un método para implementar VLANs. Insertando un campo de 4 bytes dentro de la trama Ethernet para identificar a que VLAN pertenece la información que se está transportando entre dispositivos de capa 2.




VLAN - Trama 802.1Q



El proceso de insertar el campo IEEE 802.1Q dentro de la trama Ethernet provoca que el campo FCS sea inválido, debido a que se ha alterado la trama, por lo tanto es esencial que un nuevo FCS sea recalculado, basado en la nueva trama que contiene al campo IEEE 802.1Q. Este proceso es automáticamente desarrollado por el switch antes de que la trama sea enviada por el enlace troncal.

Este método es el más popular por ser empleado por switches de diferentes fabricantes, ofreciendo compatibilidad entre equipos. Incluso los switches Cisco pueden manejar este estándar.

VLAN nativa
Normalmente un puerto de switch configurado como un puerto troncal envía y recibe tramas Ethernet etiquetadas con IEEE 802.1q. Si un switch recibe tramas Ethernet sin etiquetar en su puerto troncal, se remiten a la VLAN que se configura en el switch como VLAN nativa. Ambos lados del enlace troncal deben configurarse para estar en la misma VLAN nativa.


La VLAN nativa es la vlan a la que pertenecía un puerto en un switch antes de ser configurado como trunk. Sólo se puede tener una VLAN nativa por puerto. En los equipos de Cisco Systems la VLAN nativa por defecto es la VLAN 1. Por la VLAN 1 además de datos, se manda información sobre PAgP, CDP, VTP.

Para establecer un trunking 802.1Q a ambos lados debemos tener la misma VLAN nativa porque la encapsulación todavía no se ha establecido y los dos switches deben hablar sobre un link sin encapsulación (usan la native VLAN) para ponerse de acuerdo en estos parámetros.

Protocolos
DTP
DTP (Dynamic Trunking Protocol) es un protocolo propietario creado por Cisco Systems que opera entre switches Cisco, el cual automatiza la configuración de trunking (etiquetado de tramas de diferentes VLAN's con ISL o 802.1Q) en enlaces Ethernet.

DTP se habilita automáticamente en un puerto del switch cuando se configura un modo de trunking adecuado en dicho puerto. Para ello el administrador debe ejecutar el comando switchport mode adecuado al configurar el puerto: switchport mode {access | trunk | dynamic auto | dynamic desirable}. Con el comando switchport nonegotiate se desactiva DTP.

En switches Catalyst 2960 de Cisco el modo dynamic auto es el modo por defecto. El puerto aguardará pasivamente la indicación del otro extremo del enlace para pasar a modo troncal. Para ello envía periódicamente tramas DTP al puerto en el otro lado del enlace indicando que es capaz de establecer un enlace troncal. Esto no quiere decir que lo solicita, sino que sólo lo informa. Si el puerto remoto está configurado en modo on o dynamic desirable se establece el enlace troncal correctamente. Sin embargo, si los dos extremos están en modo dynamic auto no se establecerá el enlace como troncal, sino como acceso.

VTP
VTP son las siglas de VLAN Trunking Protocol, un protocolo de mensajes de nivel 2 usado para configurar y administrar VLANs en equipos Cisco. Permite centralizar y simplificar la administración en un domino de VLANs, pudiendo crear, borrar y renombrar las mismas, reduciendo así la necesidad de configurar la misma VLAN en todos los nodos. El protocolo VTP nace como una herramienta de administración para redes de cierto tamaño, donde la gestión manual se vuelve inabordable.

VTP opera en 3 modos distintos:

Servidor
Cliente
Transparente
Servidor:

Es el modo por defecto. Desde él se pueden crear, eliminar o modificar VLANs. Su cometido es anunciar su configuración al resto de switches del mismo dominio VTP y sincronizar dicha configuración con la de otros servidores, basándose en los mensajes VTP recibidos a través de sus enlaces trunk. Debe haber al menos un servidor. Se recomienda autenticación MD5.

Cliente:

En este modo no se pueden crear, eliminar o modificar VLANs, tan sólo sincronizar esta información basándose en los mensajes VTP recibidos de servidores en el propio dominio. Un cliente VTP sólo guarda la información de la VLAN para el dominio completo mientras el switch está activado. Un reinicio del switch borra la información de la VLAN.

Transparente:

Desde este modo tampoco se pueden crear, eliminar o modificar VLANs que afecten a los demás switches. La información VLAN en los switches que trabajen en este modo sólo se puede modificar localmente. Su nombre se debe a que no procesa las actualizaciones VTP recibidas, tan sólo las reenvía a los switches del mismo dominio.

Los administradores cambian la configuración de las VLANs en el switch en modo servidor. Después de realizar cambios, estos son distribuidos a todos los demás dispositivos en el dominio VTP a través de los enlaces permitidos en el trunk (VLAN 1, por defecto), lo que minimiza los problemas causados por las configuraciones incorrectas y las inconsistencias. Los dispositivos que operen en modo cliente, automáticamente aplicarán la configuración que reciban del dominio VTP. En este modo no se podrán crear VLANs, sino que sólo se podrá aplicar la información que reciba de las publicaciones VTP.

El modo por defecto de los swicthes es el de servidor VTP. Se recomienda el uso de este modo para redes de pequeña escala en las que la información de las VLANs es pequeña y por tanto de fácil almacenamiento en las NVRAMs de los switches.

En redes de mayor tamaño, el administrador debe elegir qué switches actúan como servidores, basándose en las capacidades de éstos (los mejor equipados serán servidores y los demás, clientes).

El VTP sólo aprende sobre las VLAN de rango normal (ID de VLAN 1 a 1005). Las VLAN de rango extendido (ID mayor a 1005) no son admitidas por el VTP.

Caso práctico
Uso del módulo HWIC-4ESW (4 puertos de switch).
El HWIC-4ESW es el equivalente de un conmutador de capa 2 por lo que no se le puede asignar direcciones IP a los puertos físicos. Lo que se puede hacer es crear un SVI L3 (SVI: Interfaz Virtual del Switch) y asignar el puerto dentro de la VLAN.

Comandos IOS básicos
Router>?
Router>enable

Crear una VLAN
Router#vlan database
Router(vlan)#vlan 10
Router(vlan)#exit

Asignar una IP a la VLAN
Router#configure terminal
Router(config)#interface vlan 10
Router(config-if)#ip address 192.168.5.1 255.255.255.0
Router(config-if)#exit

Y asignar las interfaces dentro de esa VLAN
Router(config)#interface FastEthernet0/1/x
Router(config-if)#switchport access vlan 10
Router(config-if)#exit

Actividades
¿Qué tipos de VLAN existen más frecuentemente? Explicar.
En referencia a las VLAN, ¿qué tipos de puertos existen?. Explicar.
En los enlaces troncales, ¿es aconsejable utilizar agregación de enlaces? ¿Por qué?
¿Qué tipos de etiquetado se utilizan en las tramas para distinguirlas unas de otras como pertenecientes a alguna VLAN? Explicar.
Rellena la siguiente tabla.


Protocolo	Propietario de CISCO	Nivel OSI	Función
CDP			
STP			
DTP			
VTP			
¿Qué significan las siglas de cada protocolo?
Actividades de Packet Tracer
Configura un switch con 3 VLANs (Alumnos, Profesores, Gestión), según el esquema que se muestra a continuación. Todos los ordenadores deben estar en la misma red IP privada, pero sólo deberán verse entre sí los que se hallen en la misma VLAN.


Habilitando módulo HWIC-4ESW (4 port switch)
Asignar una IP a la VLAN
Router#configure terminal
Router(config)#interface vlan 10
Router(config-if)#ip address 192.168.5.1 255.255.255.0
Router(config-if)#exit
Asignar interfaces dentro de esa VLAN
Router(config)#interface range FastEthernet0/1/x-y
Router(config-if-range)#switchport access vlan 10
Router(config-if-range)#exit

Utilizando la misma red IP privada anterior, con las mismas VLANs, realizar el siguiente esquema. Las conexiones de los switches al router son enlaces troncales. Comprobar que existe comunicación entre los equipos de la misma VLAN.


Comandos para agregación de enlaces
Switch(config)#interface range FastEthernet0/x-y
Switch(config-if-range)# switchport mode trunk
Switch(config-if-range)# channel-group z mode on
Switch(config-if-range)#exit

Modifica el esquema anterior para añadir agregación de enlaces de la siguiente forma. Comprueba el correcto funcionamiento. ¿Por qué se han desactivado dos enlaces? ¿Qué protocolo es responsable de ello? ¿Por qué crees que se han desactivado esos y no otros enlaces?




Modifica el esquema anterior para que la agregación de enlaces sea como la que se muestra a continuación. Sustituye el router por un switch. Comprueba el correcto funcionamiento. ¿Por qué crees que se han desactivado esos y no otros enlaces?


Comandos para uso de VTP
En el switch principal
Switch(config)#vtp mode server
Switch(config)# vtp domain prueba
Switch(config)# vlan 10
Switch(config-vlan)# name alumnos
Switch(config-vlan)#exit
Switch(config)# vlan 20
Switch(config-vlan)# name profesores
Switch(config-vlan)#exit
En los switches secundarios
Switch(config)#vtp mode client

Elimina todas las VLANs que has creado en el esquema anterior y vuelve a crearlas haciendo uso de VTP. Para ello configura el switch principal como VTP mode server y los switches secundarios como VTP mode client. Comprueba el correcto funcionamiento.


Bibliografía y referencias
VLAN en Cisco
VLAN Trunks
Tema 10



Tema 10: Encaminamiento.
Introducción
Clasificación
Aplicación práctica
Protocolos interiores y exteriores
Estructura jerárquica de internet
Actividades
Bibliografía y referencias
Introducción
Encaminamiento (o enrutamiento, ruteo) es la función de buscar un camino entre todos los posibles en una red de paquetes cuyas topologías poseen una gran conectividad. Dado que se trata de encontrar la mejor ruta posible, lo primero será definir qué se entiende por mejor ruta y en consecuencia cuál es la métrica que se debe utilizar para medirla.

La métrica de la red puede ser por ejemplo de saltos necesarios para ir de un nodo a otro. Aunque ésta no se trata de una métrica óptima ya que supone “1” para todos los enlaces, es sencilla y suele ofrecer buenos resultados.

Otro tipo es la medición del retardo de tránsito entre nodos vecinos, en la que la métrica se expresa en unidades de tiempo y sus valores no son constantes sino que dependen del tráfico de la red.


Atendiendo al número de equipos a los que va destinado un datagrama, la comunicación se considera:

Unicast
Multicast
Anycast
Broadcast
Geocast

Unicast es el envío de información desde un único emisor a un único receptor. Se contrapone a multicast (envío a ciertos destinatarios específicos, más de uno), broadcast (radiado o difusión, donde los destinatarios son todas las estaciones en la red) y anycast (el destinatario es único, uno cualquiera no especificado).

Broadcast, difusión en español, es una forma de transmisión de información donde un nodo emisor envía información a una multitud de nodos receptores de manera simultánea, sin necesidad de reproducir la misma transmisión nodo por nodo.

Multicast, multidifusión en español, es el envío de la información en múltiples redes a múltiples destinos simultáneamente. Antes del envío de la información, deben establecerse una serie de parámetros. Para poder recibirla, es necesario establecer lo que se denomina "grupo multicast". Ese grupo multicast tiene asociado una dirección de internet. La versión actual del protocolo de internet, conocida como IPv4, reserva las direcciones de tipo D para la multidifusión.

Anycast es una forma de direccionamiento en la que la información es enrutada al mejor destino desde el punto de vista de la topología de la red. En la red internet, una dirección IP se puede anunciar desde varios puntos diferentes. Los routers intermedios encaminan el paquete hasta el destino más cercano. Un paquete enviado a una dirección anycast es entregado a la máquina más próxima desde el punto de vista del tiempo de latencia.

Geocast se refiere a la entrega de información a un grupo de destinos en una red identificada por su ubicación geográfica. Es una forma especializada de direccionamiento de multidifusión utilizado por algunos protocolos de enrutamiento para redes móviles ad hoc.

Clasificación
Los métodos de encaminamiento los podemos clasificar en función de:

El procedimiento de encaminamiento.
Las tablas de encaminamiento empleadas.
En función del procedimiento.
Los procedimientos de encaminamiento pueden ser:

Determinísticos o Estáticos
En los encaminamientos estático y cuasi-estático la información necesaria se recoge y envía mediante gestión (al crear la red y en operaciones de mantenimiento).

Estático
Las tablas de encaminamiento de los nodos se configuran de forma manual y permanecen inalterables hasta que no se vuelve a actuar sobre ellas. La adaptación a cambios es nula. Tanto la recogida como la distribución de información se realiza por gestión (se realiza de manera externa a la red), sin ocupar capacidad de red. El calculo de ruta se realiza off-line (en una maquina especifica),y las rutas pueden ser las óptimas al no estar sometido al requisito de tiempo real.

Este tipo de encaminamiento es el óptimo para topologías en los que solo hay una posibilidad de encaminamiento (topología en estrella).

Cuasiestático
Este encaminamiento, es igual que el estático pero en vez de dar una sola ruta fija, se dan además varias alternativas en caso de que la principal no funcione, de ahí que tenga una adaptabilidad reducida.

Este tipo de encaminamiento puede dar lugar a situaciones incoherentes, ya que no se enteran todos los nodos de los problemas de la red, sino sólo los adyacentes a los problemas.

Adaptativos o Dinámicos
En este tipo de procedimientos de encaminamiento la información se recoge y envía de forma periódica con el fin de detectar cambios en la red.

Centralizado
En este tipo de encaminamiento, todos los nodos son iguales salvo el nodo central, que recoge la información de control de todos los nodos y calcula la FIB (tabla de encaminamiento) para cada nodo, es decir, el nodo central decide la tabla de encaminamiento de cada nodo en función de la información de control que éstos le mandan. El inconveniente de este método es que consumimos recursos de la red, y se harían necesaria rutas alternativas para comunicarse con el nodo central. La adaptación a cambios es perfecta siempre y cuando las notificaciones de los cambios lleguen antes de iniciar los cálculos de las rutas.

Aislado
Se basa en que cada vez que un nodo recibe un paquete que tiene que reenviar (porque no es para él) lo reenvía por todos los enlaces salvo por el que le llegó.

Distribuido
En este tipo de encaminamiento todos los nodos son iguales, todos envían y reciben información de control y todos calculan, a partir de su RIB (base de información de encaminamiento) sus tablas de encaminamiento. La adaptación a cambios es optima siempre y cuando estos sean notificados.

Hay dos familias de procedimientos distribuidos:

Vector de distancias

Cada nodo informa a sus nodos vecinos de todas las distancias conocidas por él, mediante vectores de distancias (de longitud variable según los nodos conocidos). El vector de distancias es un vector de longitud variable que contiene un par (nodo:distancia al nodo) por cada nodo conocido por el nodo que lo envía, por ejemplo (A:0;B:1;D:1) que dice que el nodo que lo manda dista "0" de A,"1" de B y "1" de D, y de los demás no sabe nada (ésta es la forma en la que un nodo dice lo que sabe en cada momento). El nodo solo conoce la distancia a los distintos nodos de la red pero no conoce la topología.

Con todos los vectores recibidos, cada nodo monta su tabla de encaminamiento ya que al final conoce qué nodo vecino tiene la menor distancia al destino del paquete, pues se lo han dicho con el vector de distancias.

Estado de enlaces

Cada nodo difunde a todos los demás nodos de la red sus distancias con sus enlaces vecinos, es decir, cada nodo comunica su entorno local a todos los nodos. Así cada nodo es capaz de conocer la topología de la red. La clave y dificultad de este método es la difusión.

A continuación se muestra una tabla comparativa de todos los tipos de encaminamiento vistos.



Clasificación de los métodos de encaminamiento
Tipos de encaminamiento	Recepción de información de control	Envío de información de control	Decisión de encaminamiento	Adaptación a los cambios
Estático	NO	NO	OFF-LINE	NO
Cuasi - estático	NO	NO	OFF-LINE	Reducida
Centralizado	Nodos-Nodo central	Nodo central-Nodos	Nodo central	SI
Aislado	NO	NO	Inundación, por ejemplo	SI
Distribuido	Todos los nodos	Todos los nodos	Todos los nodos	SI


Comparación Vector de distancias – Estado del Enlaces.
Haremos una comparación entre los algortitmos de vector de distancias y de estado de enlaces, ambos del tipo distribuido:

Consumo de capacidad.

Lo ideal es que el tráfico de control sea lo más pequeño posible. Con vectores de distancia se transmiten vectores cuyo tamaño es del orden del número de nodos de la red pues cada nodo comunica a su vecino todas las distancias que conoce; con procedimientos de estado de enlace, el tamaño del tráfico enviado es siempre el mismo independientemente del tamaño de la red. En consecuencia, consume más capacidad un vector de distancias.

Consumo de memoria

El encaminamiento basado en estado de enlace hace que cada nodo almacene toda la topología de la red, sin embargo con vectores de distancias sólo ha de almacenar distancias con el resto de los nodos. Luego consume más memoria en los nodos un procedimiento basado en estado de enlace.

Adaptabilidad a los cambios

El método de vector de distancia es más sencillo, pero se adapta peor a los cambios que el de estado de enlace. Esto es porque mientras que este último tiene información de toda la red, el primero sólo sabe a quién tiene que reenviar un paquete, pero no tiene información de la topología. Luego se adapta mejor un encaminamiento de estado de enlaces.


No obstante, el encaminamiento basado en vector de distancias es mucho menos complejo que el de estado de enlaces, cosa que en algunos casos prácticos puede llegar a ser muy importante.

En función de las tablas de encaminamiento empleadas.
Los nodos manejan tablas de encaminamiento, en las que aparece la ruta que deben seguir los paquetes con destino a un nodo determinado de la red.

Podemos distinguir entre encaminamiento salto a salto y encaminamiento fijado en origen. Nosotros veremos con detalle sólo el primer tipo (salto a salto).

Encaminamiento salto a salto
En la literatura inglesa, este tipo de encaminamiento se denomina como hop by hop. Se basa en que cada nodo no tiene que conocer la ruta completa hasta el destino, sino que sólo debe saber cuál es el siguiente nodo al que tiene que mandar el paquete: las tablas dan el nodo siguiente en función del destino. Como ejemplo, tomemos la siguiente red:

Red de ejemplo




Las tablas de encaminamiento de los nodos A y B serán:

Tabla 1. Tablas de encaminamiento para la red de laFigura 1



Tabla de encaminamiento del nodo A	Tabla de encaminamiento del nodo B
Destino	Siguiente nodo	Destino	Siguiente nodo
B	B	A	A
C	B	C	C
D	B	D	C
E	H	E	C
F	H	F	C
G	H	G	G
H	H	H	A
En la tabla de encaminamiento de cada nodo deberá aparecer una entrada en el campo destino por cada nodo que se pueda alcanzar desde el citado nodo, y en el campo siguiente nodo aparecerá el nodo vecino al que se deberá enviar los datos para alcanzar el citado nodo destino. Las soluciones propuestas no son únicas, pudiendo elegir otros caminos que minimicen el tiempo de retardo, el número de saltos, etc. La única condición que se impone es que debe haber consistencia: si, por ejemplo, para ir de A a B pasamos por C, entonces para ir de B a C no podremos pasar por A, porque entonces se formaría un bucle y el paquete mandado estaría continuamente viajando entre los nodos B y A, como puede comprobarse fácilmente.

Encaminamiento fijado en origen.
En inglés este encaminamiento se llama source routing. En él, son los sistemas finales los que fijan la ruta que ha de seguir cada paquete. Para ello, cada paquete lleva un campo que especifica su ruta(campo RI: Routing Information), y los nodos sólo se dedican a reenviar los paquetes por esas rutas ya especificadas. Así pues, son los sistemas finales los que tienen las tablas de encaminamiento y no se hace necesaria la consulta o existencia de tablas de encaminamiento en los nodos intermedios. Este tipo de encaminamiento suele ser típico de las redes de IBM.


Tabla 2. Tablas de encaminamiento para la red de laFigura 1



Tabla de encaminamiento del nodo A	Tabla de encaminamiento del nodo B
Destino	Ruta a seguir	Destino	Ruta a seguir
B	B	A	A
C	B-C	C	C
D	B-C-D	D	C-D
E	H-G-E	E	C-F-E
F	H-G-F	F	C-F
G	H-G	G	G
H	H	H	A-H
Comparación entre ambos tipos de encaminamiento.
Lo veremos por medio de la siguiente tabla:

Tabla 3. Comparación entre encaminamiento salto a salto y fijado en origen



Fijado en Origen	Salto a Salto
Conocimiento	Los sistemas finales han de tener un conocimiento completo de la red	SIMPLICIDAD: Los nodos han de tener un conocimiento parcial de la red (saber qué rutas son las mejores)
Complejidad	Recae toda en los sistemas finales	En los sistemas intermedios ya que son los que tienen que encaminar
Problemas de Bucles	No hay bucles: el sistema final fija la ruta (ROBUSTEZ).	Sí pueden ocurrir: no se tiene una visión completa de la red (INCONSISTENCIA)
Los bucles (situación que se da cuando los paquetes pasan más de una vez por un nodo) ocurren porque los criterios de los nodos no son coherentes, generalmente debido a que los criterios de encaminamiento o no han convergido después de un cambio en la ruta de un paquete; cuando por cualquier causa un paquete sufre un cambio de encaminamiento, la red tarda en adaptarse a ese cambio pues la noticia del cambio tiene que llegar a todos los nodos. Es en ese transitorio cuando se pueden dar los bucles, ya que unos nodos se han adaptado y otros no. El objetivo de los algoritmos de encaminamiento es detener el curso de los paquetes antes de que se produzcan bucles. Esto es importante sobre todo cuando se envían los paquete s por varias rutas simultáneamente (técnicas de inundación, etc...).

Aplicación práctica
Una red de redes está formada por redes interconectadas mediante routers o encaminadores. Cuando enviamos un datagrama desde un ordenador hasta otro, éste tiene que ser capaz de encontrar la ruta más adecuada para llegar a su destino. Esto es lo que se conoce como encaminamiento.

Los routers (encaminadores) son los encargados de elegir las mejores rutas. Estas máquinas pueden ser ordenadores con varias direcciones IP o bien, aparatos específicos.

Los routers deben conocer, al menos parcialmente, la estructura de la red que les permita encaminar de forma correcta cada mensaje hacia su destino. Esta información se almacena en las llamadas tablas de encaminamiento.

Observemos que debido al sistema de direccionamiento IP esta misión no es tan complicada. Lo único que necesitamos almacenar en las tablas son los prefijos de las direcciones (que nos indican la red). Por ejemplo, si el destino es la máquina 149.33.19.4 con máscara 255.255.0.0, nos basta con conocer el encaminamiento de la red 149.33.0.0 ya que todas las que empiecen por 149.33 se enviarán hacia el mismo sitio.

La orden Route muestra y modifica la tabla de encaminamiento de un host. Todos los hosts (y no sólo los routers) tienen tablas de encaminamientos. A continuación se muestra una tabla sencilla para un host con IP 192.168.0.2 / 255.255.255.0 y puerta de salida 192.168.0.1.

C:\>route print
Rutas activas:
Dirección de red Máscara de red    Puerta de enlace  Interfaz      Métrica
0.0.0.0          0.0.0.0           192.168.0.1       192.168.0.2   1    (7)
127.0.0.0        255.0.0.0         127.0.0.1         127.0.0.1     1    (6)
192.168.0.0      255.255.255.0     192.168.0.2       192.168.0.2   1    (5)
192.168.0.2      255.255.255.255   127.0.0.1         127.0.0.1     1    (4)
192.168.0.255    255.255.255.255   192.168.0.2       192.168.0.2   1    (3)
224.0.0.0        224.0.0.0         192.168.0.2       192.168.0.2   1    (2)
255.255.255.255  255.255.255.255   192.168.0.2       0.0.0.0       1    (1)
Estas tabla se lee de abajo a arriba. La línea (1) indica que los datagramas con destino "255.255.255.255" (dirección de difusión a la red del host) deben ser aceptados. La línea (2) representa un grupo de multidifusión (multicasting). La dirección "224.0.0.0" es una dirección de clase D que se utiliza para enviar mensajes a una colección de hosts registrados previamente. Estas dos líneas se suelen pasar por alto: aparecen en todas las tablas de rutas.

La línea (3) indica que todos los mensajes cuyo destinatario sea "192.168.0.255" deben ser aceptados (es la dirección de difusión a la red del host). La línea (4) se encarga de aceptar todos los mensajes que vayan destinados a la dirección del host "192.168.0.2".

La línea (5) indica que los mensajes cuyo destinatario sea una dirección de la red del host "192.168.0.0 / 255.255.255.0" deben salir del host por su tarjeta de red para que se entreguen directamente en su subred. La línea (6) es la dirección de loopback: todos los paquetes con destino "127.0.0.0 / 255.0.0.0" serán aceptados por el propio host.

Finalmente, la línea (7) representa a "todas las demás direcciones que no se hayan indicado anteriormente". En concreto son aquellas direcciones remotas que no pertenecen a la red del host. ¿A dónde se enviarán? Se enviarán a la puerta de salida (gateway) de la red "192.168.0.1".

Nótese que la tabla de rutas es la traducción de la configuración IP del host que habitualmente se escribe en las ventanas de Windows.



Gestión del encaminamiento IP
No existe un único protocolo para actualizar las tablas de encaminamiento IP, pudiendo elegirse el más adecuado dependiendo de los requisitos internos de las redes a interconectar y las preferencias de cada administrador.

A lo largo del tiempo, se han impuesto distintas soluciones, tanto abiertas como propietarias. Todas ellas operan con estrategias Adaptativas Salto a Salto.


¿Cómo pueden convivir todas ellas? Mediante los Dominios de Encaminamiento o Sistemas Autónomos (SA). Un SA es un conjunto de redes gestionadas por una administración común y que comparten una estrategia de encaminamiento común. En inglés sus siglas son AS.

Cada sistema autónomo:

Elige su arquitectura y protocolos de encaminamiento internos.
Es responsable de la consistencia de sus rutas internas.
Debe recolectar información sobre todas sus redes y designar uno a más routers para pasar la información a otros sistemas autónomos.
Será por tanto necesario definir dos tipos de encaminamiento:

Intradominio o IGP (Internal Gateway Protocol): Es el utilizado dentro del SA. Ejemplos: RIP, OSPF, IGRP, EIGRP, ...
Interdominio o EGP (External Gateway Protocol): Encamina entre Sistemas Autónomos. Ejemplos: BGP, IDPR, ...
Los routers frontera ejecutan el encaminamiento EGP para cambiar información con routers de otros sistemas autónomos, y el IGP para cambiar información con otros routers de su SA:





Sistemas participantes
La función de encaminamiento se realiza principalmente en los routers, aunque en algunas situaciones los hosts también deben participar en la toma de decisiones (para seleccionar el router de su red al que envía el datagrama):

Estrategia básica de envío

Si el host destino se encuentra en la misma red, se encapsula el datagrama IP en una trama de subred, se obtiene la dirección física (mediante ARP) y se envía (entrega directa)
Si no está en la misma subred, se envía el datagrama a un router, éste lo reenvía al siguiente, y así sucesivamente, hasta alcanzar un router conectado a la misma subred que la máquina destino (entrega indirecta)
Para conocer si el host destino se encuentra en la misma subred que el origen, éste compara el prefijo de red de ambas direcciones. Si coinciden, se encuentran en la misma subred.

Para los envíos será necesario llevar a cabo la conversión entre direcciones IP y de subred (física) del destinatario (host o router). Esta función puede desempeñarla el protocolo ARP.

El encaminador sólo modifica los campos TTL y checksum del datagrama, no las direcciones IP origen o destino. Aunque debe obtener la dirección IP del siguiente salto y, a partir de ella, la de subred donde enviará el datagrama.

Tablas de encaminamiento
El encaminamiento IP hace uso de tablas de encaminamiento que se encuentran en cada máquina (hosts y routers, puesto que ambos encaminan datagramas) y almacenan información sobre los posibles destinos y cómo alcanzarlos.

La estrategia es siempre salto a salto (next-hop routing): las tablas almacenan el siguiente salto para las direcciones IP destino. Las direcciones son siempre IP, no físicas, debido a que se facilita su gestión y se ocultan los detalles de las subredes.

Para acelerar el proceso y reducir el consumo de recursos, las tablas sólo necesitan los prefijos de subred de las direcciones IP y no la dirección IP completa.

En un entorno de interconexión total, como el de Internet, no es posible que las tablas contengan la información sobre todas las posibles direcciones destino; se utiliza el principio de información oculta, que permite tomar decisiones de encaminamiento con la información mínima necesaria:

Se aísla la información de hosts dentro del entorno local (subred) donde se encuentran; un host remoto puede enviar datagramas sin conocer al detalle la subred. El esquema de direccionamiento IP está diseñado para ayudar a conseguir éste objetivo.
Se agrupan múltiples entradas de la tabla en una sola, la ruta por defecto.
Nota: Todos los routers listados en la tabla de encaminamiento de un nodo deben de encontrarse en subredes a las que dicho nodo esté conectado directamente (estrategia salto a salto).

Métricas
Una métrica es un valor utilizado por los protocolos de enrutamiento para asignar costos a fin de alcanzar las redes remotas.

La identificación de la mejor ruta de un router implica la evaluación de múltiples rutas hacia la misma red de destino y la selección de la ruta óptima o "la más corta" para llegar a esa red. Cuando existen múltiples rutas para llegar a la misma red, cada ruta usa una interfaz de salida diferente en el router para llegar a esa red. La mejor ruta es elegida por un protocolo de enrutamiento en función del valor o la métrica que usa para determinar la distancia para llegar a esa red.

Las métricas utilizadas en los protocolos de enrutamiento IP incluyen:

Conteo de saltos: una métrica simple que cuenta la cantidad de routers que un paquete tiene que atravesar
Ancho de banda: influye en la selección de rutas al preferir la ruta con el ancho de banda más alto
Carga: considera la utilización de tráfico de un enlace determinado
Retardo: considera el tiempo que tarda un paquete en atravesar una ruta
Confiabilidad: evalúa la probabilidad de una falla de enlace calculada a partir del conteo de errores de la interfaz o las fallas de enlace previas
Costo: un valor determinado ya sea por el IOS o por el administrador de red para indicar la preferencia hacia una ruta. El costo puede representar una métrica, una combinación de las mismas o una política.
Algunos protocolos de enrutamiento, como RIP, usan un conteo de saltos simple, que consiste en el número de routers entre un router y la red de destino. Otros protocolos de enrutamiento, como OSPF, determinan la ruta más corta al analizar el ancho de banda de los enlaces y al utilizar dichos enlaces con el ancho de banda más rápido desde un router hacia la red de destino. Los protocolos de enrutamiento dinámico generalmente usan sus propias reglas y métricas para construir y actualizar las tablas de enrutamiento. Una métrica es un valor cuantitativo que se usa para medir la distancia hacia una ruta determinada. La mejor ruta a una red es la ruta con la métrica más baja. Por ejemplo, un router preferirá una ruta que se encuentra a 5 saltos antes que una ruta que se encuentra a 10 saltos.

El objetivo principal del protocolo de enrutamiento es determinar las mejores trayectorias para cada ruta a fin de incluirlas en la tabla de enrutamiento. El algoritmo de enrutamiento genera un valor, o una métrica, para cada ruta a través de la red. Las métricas se pueden calcular sobre la base de una sola característica o de varias características de una ruta. Algunos protocolos de enrutamiento pueden basar la elección de la ruta en varias métricas, combinándolas en un único valor métrico. Cuanto menor es el valor de la métrica, mejor es la ruta.

Cuando un router tiene múltiples rutas hacia una red de destino y el valor de esa métrica (conteo de saltos, ancho de banda, etc.) es el mismo, esto se conoce como métrica de mismo costo, y el router realizará un balanceo de carga de mismo costo.

La métrica para cada protocolo de enrutamiento es:

RIP: conteo de saltos: la mejor ruta se elige según la ruta con el menor conteo de saltos.
IGRP e EIGRP: ancho de banda, retardo, confiabilidad y carga; la mejor ruta se elige según la ruta con el valor de métrica compuesto más bajo calculado a partir de estos múltiples parámetros. Por defecto, sólo se usan el ancho de banda y el retardo.
IS-IS y OSPF: costo; la mejor ruta se elige según la ruta con el costo más bajo. . La implementación de OSPF de Cisco usa el ancho de banda
Distancia administrativa
Aunque es menos común, puede implementarse más de un protocolo de enrutamiento dinámico en la misma red. En algunas situaciones, posiblemente sea necesario enrutar la misma dirección de red utilizando múltiples protocolos de enrutamiento como RIP y OSPF. Debido a que diferentes protocolos de enrutamiento usan diferentes métricas, RIP usa el conteo de saltos y OSPF usa el ancho de banda, no es posible comparar las métricas para determinar la mejor ruta.

La distancia administrativa (AD) define la preferencia de un origen de enrutamiento. A cada origen de enrutamiento, entre ellas protocolos de enrutamiento específicos, rutas estáticas e incluso redes conectadas directamente, se le asigna un orden de preferencia de la más preferible a la menos preferible utilizando el valor de distancia administrativa. Los routers Cisco usan la función de AD para seleccionar la mejor ruta cuando aprende sobre la misma red de destino desde dos o más orígenes de enrutamiento diferentes.

La distancia administrativa es un valor entero entre 0 y 255. Cuanto menor es el valor, mayor es la preferencia del origen de ruta. Una distancia administrativa de 0 es la más preferida. Solamente una red conectada directamente tiene una distancia administrativa igual a 0 que no puede cambiarse. Cada protocolo tiene AD predeterminada: OSPF 110, EIGRP 90, IGRP 100, RIP 120 que aparecen en las tablas de enrutamiento precediendo a la métrica. La AD de 0 se reserva para las redes conectadas directamente y la de 1 para las redes estáticas.

Ojo, si agregamos una ruta estática que también haya sido aprendida por un protocolo dinámico, la ruta estática tendrá preferencia al tener una distancia administrativa de 1.

Protocolos de enrutamiento con clase y sin clase
Los protocolos de enrutamiento con clase no envían información de la máscara de subred en las actualizaciones de enrutamiento. Los primeros protocolos de enrutamiento tales como el RIP, fueron con clase. En aquel momento, las direcciones de red se asignaban en función de las clases; clase A, B o C. No era necesario que un protocolo de enrutamiento incluyera una máscara de subred en la actualización de enrutamiento porque la máscara de red podía determinarse en función del primer octeto de la dirección de red. Los protocolos de enrutamiento con clase no pueden usarse cuando una red se divide en subredes utilizando más de una máscara de subred; en otras palabras, los protocolos de enrutamiento con clase no admiten máscaras de subred de longitud variable (VLSM).

Los protocolos de enrutamiento sin clase incluyen la máscara de subred con la dirección de red en las actualizaciones de enrutamiento. Las redes de la actualidad ya no se asignan en función de las clases y la máscara de subred no puede determinarse según el valor del primer octeto. La mayoría de las redes de la actualidad requieren protocolos de enrutamiento sin clase porque admiten VLSM, redes no contiguas y otras funciones. Los protocolos de enrutamiento sin clase son RIPv2, EIGRP, OSPF, IS-IS y BGP.

Resumen de rutas
La creación de tablas de enrutamiento más pequeñas hace que el proceso de búsqueda en la tabla de enrutamiento sea más eficiente ya que existen menos rutas para buscar. Si se puede utilizar una ruta estática en lugar de múltiples rutas estáticas, el tamaño de la tabla de enrutamiento se reducirá. En muchos casos, una sola ruta estática puede utilizarse para representar docenas, cientos o incluso miles de rutas.

Podemos utilizar una sola dirección de red para representar múltiples subredes. Por ejemplo, las redes 10.0.0.0/16, 10.1.0.0/16, 10.2.0.0/16, 10.3.0.0/16, 10.4.0.0/16, 10.5.0.0/16, hasta 10.255.0.0/16, pueden representarse con una sola dirección de red: 10.0.0.0/8.

Las múltiples rutas estáticas pueden resumirse en una sola ruta estática si:

las redes de destino pueden resumirse en una sola dirección de red, y
todas las múltiples rutas estáticas utilizan la misma interfaz de salida o dirección IP del siguiente salto.
Protocolos interiores y exteriores
Protocolos interiores (IGP)
Routing Information Protocol (RIP)
Protocolo IGP. RFC 1095. Muy simple y extendido, gracias a que fue incluido en la distribución UNIX BSD (routed)

Características generales:

Vector distancia.
Métrica = número de saltos (de 1 a 15). 16 es infinito.
Dos tipos de participantes: activos (sólo pueden ser routers) y pasivos.
Cada 30 segundos los participantes activos difunden su vector de distancias: duplas de (prefijo IP, distancia).
Utiliza UDP como protocolo de transporte (puerto 520).
Todos los participantes (activos y pasivos) escuchan los mensajes RIP y actualizan sus tablas.
Existe un proceso de borrado de rutas (cada 180 segundos), para mantener las tablas fiables y para recuperarse ante caídas de routers, por ejemplo.
Dos tipos de paquetes. REQUEST: enviados por los routers o hosts que acaban de conectarse o su información ha caducado. RESPONSE: enviados periódicamente, en respuesta a un REQUEST o cuando cambia algún coste.
Actualmente existen dos versiones del protocolo: RIPv1 y RIPv2 (aporta subnetting y autenticación).
Limitaciones:

Existen diferencias entre implementaciones debido a que la RFC tardó un poco en aparecer.
Convergencia lenta (inconsistencias transitorias provocan bucles de encaminamiento). Se han propuesto algunas soluciones, pero son parciales o no sirven para todas las topologías.
Carga las redes innecesariamente. Todos los routers hacen broadcast periódicamente.
Permite 15 saltos como máximo.
Métrica de saltos. No contempla otras posibilidades (caudal, probabilidad de error, etc.)
Open Shortest Path First (OSPF)
Primero el Camino Abierto más Corto. Protocolo IGP. RFC 1247. Presentado en 1990 como sustituto de RIP. Recomendado por la IETF para redes IP.

Características generales:

Escalable: admite redes con miles de encaminadores
Estado de Enlaces
Soporta subnetting: prefijos + máscaras.
Los mensajes OSPF se encapsulan directamente dentro de datagramas IP: no utilizan ningún protocolo de transporte.
Encaminamiento multimétrica. Distinto camino dependiendo del campo TOS de la cabecera IP. También soporta balanceado de carga entre rutas de igual coste.
Encaminamiento jerárquico. Divide el sistema autónomo en áreas. Cada área esconde su topología. El encaminador OSPF sólo necesita conocer la topología de su área.
Tipos de encaminadores: Internal, Area Border, Backbone y AS Boundary.
Tipos de Redes: Point to Point, Broadcast y Non-Broadcast
Inyección de rutas externas: uno o varios encaminadores aprenden rutas externas y las propagan.
Descubrimiento dinámico de encaminadores.
Adaptación a redes locales: aprovecha las redes con difusión hardware para disminuir el número de mensajes OSPF.
Soporte para autentificación, lo que proporciona mayor seguridad y evita ataques.
Protocolos exteriores (EGP)
BGP
Border Gateway Protocol es un protocolo mediante el cual se intercambia información de encaminamiento entre sistemas autónomos.

Entre los sistemas autónomos de los ISP se intercambian sus tablas de rutas a través del protocolo BGP. Este intercambio de información de encaminamiento se hace entre los routers externos de cada sistema autónomo. Estos routers deben soportar BGP. Se trata del protocolo más utilizado para redes con intención de configurar un EGP (external gateway protocol)

Es el protocolo principal de publicación de rutas utilizado por las compañías más importantes de ISP en Internet. BGP4 es la primera versión que admite encaminamiento entre dominios sin clase (CIDR) y agregado de rutas. A diferencia de los protocolos de Gateway internos (IGP), como RIP, OSPF y EIGRP, no usa métricas como número de saltos, ancho de banda, o retardo. En cambio, BGP toma decisiones de encaminamiento basándose en políticas de la red, o reglas que utilizan varios atributos de ruta BGP.

Con BGP los encaminadores en la frontera de un sistema autónomo intercambian prefijos de redes hacia las que saben encaminar. Las rutas aprendidas son inyectadas en el IGP para distribuirlas entre los encaminadores interiores al AS.


Relaciones entre Sistemas Autónomos

Las relaciones que existen entre distintos sistemas autónomos son principalmente de peering y de tránsito. Básicamente una relación de tránsito es la que existe entre un proveedor y un cliente, de modo que el cliente pague por los recursos de Internet que le puede suministrar su proveedor. Las relaciones de peering no suelen se pagadas y consisten en un enlace para comunicar dos sistemas autónomos con el fin de reducir costes, latencia, pérdida de paquetes y obtener caminos redundantes. Se suele hacer peering con sistemas autónomos potencialmente similares, es decir, no se hace peering con un cliente potencial ya que saldría uno de los dos sistemas autónomos beneficiado.



Curiosidad

Durante las protestas de Egipto de 2011 el gobierno de Hosni Mubarak ordenó a todos los proveedores de acceso que operan en el país árabe el corte de las conexiones internacionales. Como consecuencia de los cortes y bloqueos en la noche del 27 al 28 de enero los enrutadores egipcios dejaron de anunciar hasta 3.500 rutas de BGP, dejando al resto de enrutadores sin la información necesaria para intercambiar tráfico con los servidores egipcios.

Fuente y más información:

http://internacional.elpais.com/internacional/2011/01/28/actualidad/1296169207_850215.html

Estructura jerárquica de internet
NOTA: Tier es una palabra inglesa que puede traducirse por nivel.

Una red Tier 1 (Tier 1 ISPs o Internet backbone networks) es capaz de alcanzar cualquier red de Internet sin tener que pagar por tránsito (por enviar sus bits a través de otras redes.)

Grandes proveedores internacionales (AT&T, Deutsche Telekom,
AOL, Telefónica y algunos más)
Conectados directamente a cada uno de los demás Tier 1 ISPs
Conectados a un gran número de Tier 2 ISPs
Cobertura internacional
Los Tier 2 ISPs suelen ser regionales o nacionales y son los

ISPs más comunes.

Se conectan sólo a algunos Tier 1 ISPs (pagando por el uso de sus redes).
También se conectan a muchos otros Tier 2 ISPs (mediante acuerdos de peering), de forma que el tráfico fluye entre ambas redes sin necesidad de usar una red Tier 1.
Pero para alcanzar una gran cantidad de redes necesitan encaminar su tráfico a través de los ISP de nivel 1 a los que están conectados (ellos son los clientes y el Tier 1 el proveedor de tránsito).
Los Tier 3 ISPs son ISPs locales de acceso

Para alcanzar internet solamente contratan tránsito IP (normalmente a ISPs Tier2) ¿Cómo se conectan los ISPs?
Point of Presence (PoP): es un interfaz entre dos ISPs. Pueden estar en las propias instalaciones de un ISP o en un IX.
Internet eXchange point: infraestructura en la que los ISPs intercambian tráfico entre sus redes.
Reducen la cantidad de tráfico que deben enviar a los ISPs superiores → reducción de costes
Aprenden nuevas rutas → mayor eficiencia y tolerancia a fallos
Mantienen el tráfico local → mejor latencia
Actividades
Actividades de teoría
Atendiendo al número de receptores de un paquete, ¿qué tipos de encaminamiento existen? Explicar.
¿En qué se diferencian el encaminamiento estático del encaminamiento dinámico?
¿Qué comando utilizamos para ver la tabla de rutas en un equipo terminal Windows? ¿Y en Linux?
En Windows, desde un terminal de texto, elimina la ruta por defecto con el comando route. Prueba a hacer un ping al equipo 8.8.8.8. Vuelve a añadir la ruta. Vuelve a probar el ping. (Realiza dos capturas de pantalla)
En Linux, desde un terminal de texto, elimina la ruta por defecto con el comando route. Prueba a hacer un ping al equipo 8.8.8.8. Vuelve a añadir la ruta. Vuelve a probar el ping. (Realiza dos capturas de pantalla)
En un equipo terminal, ¿por qué es tan importante la puerta de enlace o ruta por defecto?
Haz un esquema de los distintos protocolos de encaminamiento dinámico que existen, atendiendo a externos o internos. Y en estos últimos según se basen en el vector de distancia o en el estado del enlace.
¿Qué protocolos admiten encaminamiento sin clase?
¿Qué es la distancia administrativa y cuándo es necesaria?
De los protocolos de encaminamiento, ¿cuáles son propietarios?
¿Cómo está organizada Internet? ¿Qué niveles existen?
¿Qué son y por qué son importantes los Internet eXchange points?


Actividades de Packet Tracer
Inicio (comandos básicos)

Router>ping IP
Router>show ip route
Router>enable
Router#configure terminal
Router(config)#no ip domain-lookup

<Aquí ponemos los comandos de enrutamiento>

Fin
Router0(config-router)#exit
Router0(config)#exit
Router0#copy running-config startup-config


Enrutamiento estático
Añadimos rutas estáticas

Router(config)#ip route   RED   MASCARA    SIGUIENT_SALTO
Router(config)#ip route ...
Conecta 2 routers entre sí y comprueba que tienen comunicación entre ellos (utiliza el comando ping). Router1 (11.0.0.1/30), Router2 (11.0.0.2/30). ¿Es necesario configurar tablas de rutas? ¿Por qué? Muestra la tabla de rutas con el comando show ip route.




Añade al Router1 un módulo HWIC-4ESW (4 ports switch). Configura el módulo HWIC-4ESW como se vio en el tema anterior. Añade 4 PC y configura una red diferente para ellos (192.168.1.0/24). Configura la puerta de enlace de cada uno de los PC. Añade una entrada a la tabla de rutas en el Router2 para alcanzar la red 192.168.1.0. Comprueba que hay comunicación entre los PC y el Router2. Muestra la tabla de rutas del Router2 con el comando show ip route.


Router2(config)#ip route 192.168.1.0   255.255.255.0   11.0.0.1




Añade un switch y 4 PC más en otra red. Configura Router1 para alcanzar la red2 (192.168.2.0). Configura Router2 para alcanzar la red1 (192.168.1.0). Comprueba que hay comunicación entre los PC del Router1 y los del Router2. Muestra la tabla de rutas del Router1 con el comando show ip route.
Router1(config)#ip route 192.168.2.0   255.255.255.0   11.0.0.2
Router2(config)#ip route 192.168.1.0   255.255.255.0   11.0.0.1




Añade el Router3 (12.0.0.0/30 hacia Router1; 13.0.0.0/30 hacia Router2). Configura su tabla de rutas. Modifica la tabla de rutas del Router2 para que los envíos que vayan a la red local del Router1 pasen por el Router3. Configura el Router3. Muestra las tablas de rutas de los Router2 y Router3 con el comando show ip route.
Router1(config)#ip route 192.168.2.0   255.255.255.0   11.0.0.2
Router1(config)#ip route 192.168.2.0   255.255.255.0   12.0.0.2
Router2(config)#ip route 192.168.1.0   255.255.255.0   11.0.0.1
Router2(config)#ip route 192.168.1.0   255.255.255.0   13.0.0.2
Router3(config)#ip route 192.168.1.0   255.255.255.0   12.0.0.1
Router3(config)#ip route 192.168.2.0   255.255.255.0   13.0.0.1




Añade un Router4 (con IP 14.0.0.0/30 y 15.0.0.0/30, por ejemplo) con un módulo HWIC-2T para 2 líneas serie. Añade a los Router3 y Router1 otro módulo HWIC-2T. Recuerda Guardar la configuración en ejecución a la NVRAM (Save Running Configuration to NVRAM) antes de apagar los routers si no quieres perderla. Modifica la tabla de rutas de Router3 para que los paquetes que vayan a la red local del Router1 pasen por Router4. Muestra las tablas de rutas de los Router3 y Router4 con el comando show ip route.
Router3(config)#ip route 192.168.1.0   255.255.255.0   12.0.0.1
Router3(config)#ip route 192.168.1.0   255.255.255.0   15.0.0.2
Router4(config)#ip route 192.168.1.0   255.255.255.0   14.0.0.1
Router4(config)#ip route 192.168.2.0   255.255.255.0   15.0.0.1




Añade un Router5 (16.0.0.0/30). Elimina todas las entradas de las tablas de rutas de los Router1 y Router2. Añade a Router1 una entrada para alcanzar la red2 a través del Router2. Añade a Router2 una entrada para alcanzar la red1 a través del Router1. Añade a ambos routers, una ruta por defecto (para enviar datos a cualquier otra red) a través de Router3. Configura Router3 y Router4 para que sus rutas por defecto se encaminen hacia Router5. Muestra las tablas de rutas de los Router3 y Router4 con el comando show ip route.
Router1(config)#ip route 192.168.2.0   255.255.255.0 11.0.0.2
Router1(config)#ip route 0.0.0.0       0.0.0.0       12.0.0.2
Router2(config)#ip route 192.168.1.0   255.255.255.0 11.0.0.1
Router2(config)#ip route 0.0.0.0       0.0.0.0       13.0.0.2
...
Router5(config)#ip route 0.0.0.0       0.0.0.0       16.0.0.1


Enrutamiento dinámico (RIP)
Habilitamos RIP 2 y publicamos rutas adyacentes

Router0(config)#router rip
Router0(config-router)#version 2
Router0(config-router)#network  RED
Router0(config-router)#network  RED


Crea un esquema con 3 routers tal como se muestra. Configura RIP versión 2 en cada uno de ellos. Comprueba que hay comunicación entre PC0 y PC1. ¿Cuáles son las tablas de rutas de Router0 y Router2?
Router0(config)#router rip
Router0(config-router)#version 2
Router0(config-router)#network 10.0.0.0
Router0(config-router)#network 11.0.0.0 
]



Haz que Router1 se publique como ruta por defecto. Cualquier paquete con IP destino que no se halle en las redes mostradas se enviará a Router1, que a su vez lo enviará hacia fuera. Mostrar tabla de rutas de Router0.
Router1(config-router)#default-information originate




Enrutamiento dinámico (OSPF)
Habilitamos OSPF y publicamos rutas adyacentes

Router(config)#router ospf x
Router(config-router)#network  RED   WILDCARD  area 0 
Router(config-router)#network  RED   WILDCARD  area 0

x:        número de proceso (puede tomar un valor entre 1 y 65535)
WILDCARD: inverso binario de la máscara de red.
area 0:   núm. área (aconsejable poner 0 para área única en todos los routers de la misma)


Crea un esquema con 3 routers tal como se muestra. Configura OSPF en cada uno de ellos. Comprueba que hay comunicación entre PC0 y PC1. ¿Cuáles son las tablas de rutas de Router0 y Router2?
Router0(config-router)#network  10.0.0.0   0.255.255.255   area 0
Router0(config-router)#network  11.0.0.0   0.255.255.255   area 0


Haz que Router1 se publique como ruta por defecto. Cualquier paquete con IP destino que no se halle en las redes mostradas se enviará a Router1, que a su vez lo enviará hacia fuera. Mostrar tabla de rutas de Router0.
Router1(config-router)#ip route   0.0.0.0   0.0.0.0   200.0.0.1
Router1(config-router)#default-information originate


Enrutamiento dinámico (BGP)
Habilitamos BGP 

Router(config)#router bgp  x
Router(config-router)#neighbor   IP   remote-as  y
   
Redes detrás del router BGP 
Router(config-router)#network  RED  mask MASK
Router(config-router)#network  RED  mask MASK
Router(config-router)#network  RED  mask MASK
...
 
x, y: números de sistemas autónomos.


Crear el siguiente esquema. Tenemos 2 sistemas autónomos (AS): uno funcionando internamente con RIP (AS=10) y otro con OSPF (AS=20). Como routers frontera tenemos Router1 y Router-1. Configurar BGP en Router1 y Router-1. Mostrar ambas tablas de rutas.
Router-1(config)#router bgp 20
Router-1(config-router)#neighbor  200.0.0.1   remote-as 10
Router-1(config-router)#network   20.0.0.0    mask 255.0.0.0
Router-1(config-router)#network   21.0.0.0    mask 255.0.0.0
Router-1(config-router)#network   22.0.0.0    mask 255.0.0.0
Router-1(config-router)#network   23.0.0.0    mask 255.0.0.0


No olvides crear las rutas por defecto, tanto en Router1 como en Router-1

Router1(config-router)#default-information originate
Router-1(config-router)#ip route   0.0.0.0   0.0.0.0   200.0.0.1
Router-1(config-router)#default-information originate


Añadir a Router1 una red exterior. Configurar la ruta BGP por defecto en Router1. Debes configurar además el equipo exterior 100.0.0.2 con soporte de BGP. Mostrar tablas de rutas de Router-1.
Router1(config-router)#neighbor 100.0.0.2   default-originate




Actividad práctica (Opcional)
Instalar en el ordenador de casa los servicios:
XAMPP (servidor de páginas web)
VNC (servidor de acceso remoto gráfico)
En el router hacer DNAT estático (es decir, abrir y redirigir puertos o port forwarding):
80 (a ordenador de casa)
5800-5810, 5900-5910 (a ordenador de casa)
Hacer DDNS (DNS dinámico), es decir, registrar un nombre de dominio en dyndns, no-ip, o similar.
Bibliografía y referencias
Conceptos generales de enrutamiento
Enrutamiento estático en Cisco
Enrutamiento dinámico (Parte 1) en Cisco
Enrutamiento dinámico (Parte 2) en Cisco
Como funciona la Red: peering & transit (en inglés)
Tema 11



Tema 11: La capa de transporte.
Conceptos generales
Estándares
Técnicas
Herramientas
Actividades
Bibliografía y referencias
Conceptos generales
La capa de red transfiere datagramas entre dos ordenadores a través de la red utilizando como identificadores las direcciones IP. La capa de transporte añade la noción de puerto para distinguir entre los muchos destinos dentro de un mismo host. No es suficiente con indicar la dirección IP del destino, además hay que especificar la aplicación que recogerá el mensaje. Cada aplicación que esté esperando un mensaje utiliza un número de puerto distinto; más concretamente, la aplicación está a la espera de un mensaje en un puerto determinado (escuchando un puerto).

Pero no sólo se utilizan los puertos para la recepción de mensajes, también para el envío: todos los mensajes que envíe un ordenador debe hacerlo a través de uno de sus puertos. El siguiente diagrama representa una transmisión entre el ordenador 194.35.133.5 y el 135.22.8.165. El primero utiliza su puerto 1256 y el segundo, el 80.



La capa de transporte transmite mensajes entre las aplicaciones de dos ordenadores. Por ejemplo, entre nuestro navegador de páginas web y un servidor de páginas web, o entre nuestro programa de correo electrónico y un servidor de correo.



Puertos
Un ordenador puede estar conectado con distintos servidores a la vez; por ejemplo, con un servidor de noticias y un servidor de correo. Para distinguir las distintas conexiones dentro de un mismo ordenador se utilizan los puertos.

Un puerto es un número de 16 bits, por lo que existen 65536 puertos en cada ordenador. Las aplicaciones utilizan estos puertos para recibir y transmitir mensajes.

La asignación de puertos puede obtenerse desde el IANA

Se pueden clasificar en

Puertos bien conocidos (Known Ports: 0 hasta 1023).
Puertos registrados (Registered Ports: 1024 hasta 49151)
Puertos dinámicos y/o privados (Dynamic and/or Private Ports: 49152 hasta 65535)
A continuación se muestra una lista de los puertos más importantes.

Puertos bien conocidos
Puerto/ protocolo	Descripción
0/udp	Reservado
20/tcp	FTP File Transfer Protocol (Protocolo de Transferencia de Ficheros) - datos
21/tcp	FTP File Transfer Protocol (Protocolo de Transferencia de Ficheros) - control
22/tcp	SSH, scp, SFTP
23/tcp	Telnet manejo remoto de equipo, inseguro
25/tcp	SMTP Simple Mail Transfer Protocol (Protocolo Simple de Transferencia de Correo)
53/tcp	DNS Domain Name System (Sistema de Nombres de Dominio)
53/udp	DNS Domain Name System (Sistema de Nombres de Dominio)
67/udp	BOOTP BootStrap Protocol (Server), también usado por DHCP
68/udp	BOOTP BootStrap Protocol (Client), también usado por DHCP
69/udp	TFTP Trivial File Transfer Protocol (Protocolo Trivial de Transferencia de Ficheros)
80/tcp	HTTP HyperText Transfer Protocol (Protocolo de Transferencia de HiperTexto) (WWW)
88/tcp	Kerberos Agente de autenticación
110/tcp	POP3 Post Office Protocol (E-mail)
123/udp	NTP Protocolo de sincronización de tiempo
123/tcp	NTP Protocolo de sincronización de tiempo
137/tcp	NetBIOS Servicio de nombres
137/udp	NetBIOS Servicio de nombres
138/tcp	NetBIOS Servicio de envío de datagramas
138/udp	NetBIOS Servicio de envío de datagramas
139/tcp	NetBIOS Servicio de sesiones
139/udp	NetBIOS Servicio de sesiones
143/tcp	IMAP4 Internet Message Access Protocol (E-mail)
161/tcp	SNMP Simple Network Management Protocol
161/udp	SNMP Simple Network Management Protocol
389/tcp	LDAP Protocolo de acceso ligero a Bases de Datos
389/udp	LDAP Protocolo de acceso ligero a Bases de Datos
443/tcp	HTTPS/SSL para la transferencia segura de páginas web
445/tcp	Microsoft-DS (Active Directory, compartición en Windows, gusano Sasser, Agobot)
445/udp	Microsoft-DS compartición de ficheros
465/tcp	SMTP Sobre SSL. Envío de correo electrónico (E-mail)
631/tcp	CUPS sistema de impresión de Unix
993/tcp	IMAP4 sobre SSL (E-mail)
995/tcp	POP3 sobre SSL (E-mail)
1023/tcp	Reservado
1023/udp	Reservado
Puertos registrados
Puerto/ protocolo	Descripción
1024/tcp/	Reservado
1024/udp	Reservado
1433/tcp	Microsoft-SQL-Server
1512/tcp	WINS Windows Internet Naming Service
2049/tcp	NFS Archivos del sistema de red
3128/tcp	HTTP web cache y por defecto en Squid cache
3306/tcp	MySQL sistema de gestión de bases de datos
3389/tcp	RDP (Remote Desktop Protocol) Terminal Server
4662/tcp	eMule (aplicación de compartición de ficheros)
4672/udp	eMule (aplicación de compartición de ficheros)
4899/tcp	RAdmin (Remote Administrator), herramienta de administración remota (normalmente troyanos)
5432/tcp	PostgreSQL sistema de gestión de bases de datos
5631/tcp	PC-Anywhere protocolo de escritorio remoto
5632/udp	PC-Anywhere protocolo de escritorio remoto
5400/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5500/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5600/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5700/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5800/tcp	VNC protocolo de escritorio remoto (usado sobre HTTP)
5900/tcp	VNC protocolo de escritorio remoto (conexión normal)
6881/tcp	BitTorrent puerto por defecto
6969/tcp	BitTorrent puerto de tracker
8080/tcp	HTTP alternativo. Proxy Web el servidor de almacenamiento en caché. Tomcat.
8118/tcp	privoxy
10000/tcp	Webmin (Administración remota web)
31337/tcp	Back Orifice herramienta de administración remota (por lo general troyanos)
49151/tcp	Reservado
49151/udp	Reservado
Puede encontrarse las lista completa con el servicio asociado en http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xhtml

Estándares
Protocolo UDP
El protocolo UDP (User Datagram Protocol, protocolo de datagrama de usuario) proporciona una comunicación muy sencilla entre las aplicaciones de dos ordenadores. Al igual que el protocolo IP, UDP es:

No orientado a conexión. No se establece una conexión previa con el otro extremo para transmitir un mensaje UDP. Los mensajes se envían sin más y éstos pueden duplicarse o llegar desordenados al destino.
No fiable. Los mensajes UDP se pueden perder o llegar dañados.
UDP utiliza el protocolo IP para transportar sus mensajes. Como vemos, no añade ninguna mejora en la calidad de la transferencia; aunque sí incorpora los puertos origen y destino en su formato de mensaje. Las aplicaciones (y no el protocolo UDP) deberán programarse teniendo en cuenta que la información puede no llegar de forma correcta.



Encabezado UDP	Área de datos UDP	
Encabezado del datagrama	Área de datos del datagrama IP	
Encabezado de la trama	Área de datos de la trama	Final de la trama
Formato del mensaje UDP
0	10	20	30
0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1
Puerto UDP origen	Puerto UDP destino
Longitud mensaje UDP	Suma verificación UDP
Datos
...
Puerto UDP de origen (16 bits, opcional). Número de puerto de la máquina origen.
Puerto UDP de destino (16 bits). Número de puerto de la máquina destino.
Longitud del mensaje UDP (16 bits). Especifica la longitud medida en bytes del mensaje UDP incluyendo la cabecera. La longitud mínima es de 8 bytes.
Suma de verificación UDP (16 bits, opcional). Suma de comprobación de errores del mensaje. Para su cálculo se utiliza una pseudo-cabecera que también incluye las direcciones IP origen y destino. Para conocer estos datos, el protocolo UDP debe interactuar con el protocolo IP.
Datos. Aquí viajan los datos que se envían las aplicaciones. Los mismos datos que envía la aplicación origen son recibidos por la aplicación destino después de atravesar toda la Red de redes.
Protocolo TCP
El protocolo TCP (Transmission Control Protocol, protocolo de control de transmisión) está basado en IP que es no fiable y no orientado a conexión, y sin embargo es:



Orientado a conexión. Es necesario establecer una conexión previa entre las dos máquinas antes de poder transmitir ningún dato. A través de esta conexión los datos llegarán siempre a la aplicación destino de forma ordenada y sin duplicados. Finalmente, es necesario cerrar la conexión.
Fiable. La información que envía el emisor llega de forma correcta al destino.
El protocolo TCP permite una comunicación fiable entre dos aplicaciones. De esta forma, las aplicaciones que lo utilicen no tienen que preocuparse de la integridad de la información: dan por hecho que todo lo que reciben es correcto.

El flujo de datos entre una aplicación y otra viajan por un circuito virtual. Sabemos que los datagramas IP pueden seguir rutas distintas, dependiendo del estado de los encaminadores intermedios, para llegar a un mismo sitio. Esto significa que los datagramas IP que transportan los mensajes siguen rutas diferentes aunque el protocolo TCP logré la ilusión de que existe un único circuito por el que viajan todos los bytes uno detrás de otro (algo así como una tubería entre el origen y el destino). Para que esta comunicación pueda ser posible es necesario abrir previamente una conexión. Esta conexión garantiza que los todos los datos lleguen correctamente de forma ordenada y sin duplicados. La unidad de datos del protocolo es el byte, de tal forma que la aplicación origen envía bytes y la aplicación destino recibe estos bytes.

Sin embargo, cada byte no se envía inmediatamente después de ser generado por la aplicación, sino que se espera a que haya una cierta cantidad de bytes, se agrupan en un segmento y se envía el segmento completo. Para ello son necesarias unas memorias intermedias o buffers. Cada uno de estos segmentos viaja en el campo de datos de un datagrama IP. Si el segmento es muy grande será necesario fragmentar el datagrama, con la consiguiente pérdida de rendimiento; y si es muy pequeño, se estarán enviando más cabeceras que datos. Por consiguiente, es importante elegir el mayor tamaño de segmento posible que no provoque fragmentación.



Encabezado TCP	Área de datos TCP	
Encabezado del datagrama	Área de datos del datagrama IP	
Encabezado de la trama	Área de datos de la trama	Final de la trama
El protocolo TCP envía un flujo de información no estructurado. Esto significa que los datos no tienen ningún formato, son únicamente los bytes que una aplicación envía a otra. Ambas aplicaciones deberán ponerse de acuerdo para comprender la información que se están enviando.

Cada vez que se abre una conexión, se crea un canal de comunicación bidireccional en el que ambas aplicaciones pueden enviar y recibir información, es decir, una conexión es full-dúplex.



Formato del segmento TCP
Ya hemos comentado que el flujo de bytes que produce una determinada aplicación se divide en uno o más segmentos TCP para su transmisión. Cada uno de estos segmentos viaja en el campo de datos de un datagrama IP. Para facilitar el control de flujo de la información los bytes de la aplicación se numeran. De esta manera, cada segmento indica en su cabecera el primer byte que transporta. Las confirmaciones o acuses de recibo (ACK) representan el siguiente byte que se espera recibir (y no el número de segmento recibido, ya que éste no existe).



0	10	20	30
0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1	2	3	4	5	6	7	8	9	0	1
Puerto TCP origen	Puerto TCP destino
Número de secuencia
Número de acuse de recibo
HLEN	Reservado	Bits código	Ventana
Suma de verificación	Puntero de urgencia
Opciones (si las hay)	Relleno
Datos
...
Puerto fuente (16 bits). Puerto de la máquina origen. Al igual que el puerto destino es necesario para identificar la conexión actual.
Puerto destino (16 bits). Puerto de la máquina destino.
Número de secuencia (32 bits). Indica el número de secuencia del primer byte que trasporta el segmento.
Número de acuse de recibo (32 bits). Indica el número de secuencia del siguiente byte que se espera recibir. Con este campo se indica al otro extremo de la conexión que los bytes anteriores se han recibido correctamente.
HLEN (4 bits). Longitud de la cabecera medida en múltiplos de 32 bits (4 bytes). El valor mínimo de este campo es 5, que corresponde a un segmento sin datos (20 bytes).
Reservado (6 bits). Bits reservados para un posible uso futuro.
Bits de código o indicadores (6 bits). Los bits de código determinan el propósito y contenido del segmento. A continuación se explica el significado de cada uno de estos bits (mostrados de izquierda a derecha) si está a 1.
URG. El campo Puntero de urgencia contiene información válida.
ACK. El campo Número de acuse de recibo contiene información válida, es decir, el segmento actual lleva un ACK. Observemos que un mismo segmento puede transportar los datos de un sentido y las confirmaciones del otro sentido de la comunicación.
PSH. La aplicación ha solicitado una operación push (enviar los datos existentes en la memoria temporal sin esperar a completar el segmento).
RST. Interrupción de la conexión actual.
SYN. Sincronización de los números de secuencia. Se utiliza al crear una conexión para indicar al otro extremo cual va a ser el primer número de secuencia con el que va a comenzar a transmitir (veremos que no tiene porqué ser el cero).
FIN. Indica al otro extremo que la aplicación ya no tiene más datos para enviar. Se utiliza para solicitar el cierre de la conexión actual.
Ventana (16 bits). Número de bytes que el emisor del segmento está dispuesto a aceptar por parte del destino.
Suma de verificación (24 bits). Suma de comprobación de errores del segmento actual. Para su cálculo se utiliza una pseudo-cabecera que también incluye las direcciones IP origen y destino.
Puntero de urgencia (8 bits). Se utiliza cuando se están enviando datos urgentes que tienen preferencia sobre todos los demás e indica el siguiente byte del campo Datos que sigue a los datos urgentes. Esto le permite al destino identificar donde terminan los datos urgentes. Nótese que un mismo segmento puede contener tanto datos urgentes (al principio) como normales (después de los urgentes).
Opciones (variable). Si está presente únicamente se define una opción: el tamaño máximo de segmento que será aceptado.
Relleno. Se utiliza para que la longitud de la cabecera sea múltiplo de 32 bits.
Datos. Información que envía la aplicación.
Fiabilidad
¿Cómo es posible enviar información fiable basándose en un protocolo no fiable? Es decir, si los datagramas que transportan los segmentos TCP se pueden perder, ¿cómo pueden llegar los datos de las aplicaciones de forma correcta al destino?

La respuesta a esta pregunta es sencilla: cada vez que llega un mensaje se devuelve una confirmación (acknowledgement) para que el emisor sepa que ha llegado correctamente. Si no le llega esta confirmación pasado un cierto tiempo, el emisor reenvía el mensaje.

Veamos a continuación la manera más sencilla (aunque ineficiente) de proporcionar una comunicación fiable. El emisor envía un dato, arranca su temporizador y espera su confirmación (ACK). Si recibe su ACK antes de agotar el temporizador, envía el siguiente dato. Si se agota el temporizador antes de recibir el ACK, reenvía el mensaje. Los siguientes esquemas representan este comportamiento:


TCP - Confirmaciones positivas (ACK)



TCP - Temporizador

Este esquema es perfectamente válido aunque muy ineficiente debido a que sólo se utiliza un sentido de la comunicación a la vez y el canal está desaprovechado la mayor parte del tiempo. Para solucionar este problema se utiliza un protocolo de ventana deslizante, que se resume en el siguiente esquema. Los mensajes y las confirmaciones van numerados y el emisor puede enviar más de un mensaje antes de haber recibido todas las confirmaciones anteriores.


TCP - Ventana deslizante
Conexiones
Una conexión son dos pares dirección IP:puerto. No puede haber dos conexiones iguales en un mismo instante en toda la Red. Aunque bien es posible que un mismo ordenador tenga dos conexiones distintas y simultáneas utilizando un mismo puerto. El protocolo TCP utiliza el concepto de conexión para identificar las transmisiones. En el siguiente ejemplo se han creado tres conexiones. Las dos primeras son al mismo servidor Web (puerto 80) y la tercera a un servidor de FTP (puerto 21).



Host 1	Host 2
194.35.133.5:1256	135.22.8.165:80
184.42.15.16:1305	135.22.8.165:80
184.42.15.16:1323	135.22.10.15:21


Para que se pueda crear una conexión, el extremo del servidor debe hacer una apertura pasiva del puerto (escuchar su puerto y quedar a la espera de conexiones) y el cliente, una apertura activa en el puerto del servidor (conectarse con el puerto de un determinado servidor).

Nota: El comando NetStat muestra las conexiones abiertas en un ordenador, así como estadísticas de los distintos protocolos de Internet.

Establecimiento de una conexión
Antes de transmitir cualquier información utilizando el protocolo TCP es necesario abrir una conexión. Un extremo hace una apertura pasiva y el otro, una apertura activa. El mecanismo utilizado para establecer una conexión consta de tres vías.


TCP - Establecimiento de una conexión


La máquina que quiere iniciar la conexión hace una apertura activa enviando al otro extremo un mensaje que tenga el bit SYN activado. Le informa además del primer número de secuencia que utilizará para enviar sus mensajes.
La máquina receptora (un servidor generalmente) recibe el segmento con el bit SYN activado y devuelve la correspondiente confirmación. Si desea abrir la conexión, activa el bit SYN del segmento e informa de su primer número de secuencia. Deja abierta la conexión por su extremo.
La primera máquina recibe el segmento y envía su confirmación. A partir de este momento puede enviar datos al otro extremo. Abre la conexión por su extremo.
La máquina receptora recibe la confirmación y entiende que el otro extremo ha abierto ya su conexión. A partir de este momento puede enviar ella también datos. La conexión ha quedado abierta en los dos sentidos.
Observamos que son necesarios 3 segmentos para que ambas máquinas abran sus conexiones y sepan que la otra también está preparada.

Números de secuencia.— Se utilizan números de secuencia distintos para cada sentido de la comunicación. Como hemos visto el primer número para cada sentido se acuerda al establecer la comunicación. Cada extremo se inventa un número aleatorio y envía éste como inicio de secuencia. Observamos que los números de secuencia no comienzan entonces en el cero. ¿Por qué se procede así? Uno de los motivos es para evitar conflictos: supongamos que la conexión en un ordenador se interrumpe nada más empezar y se crea una nueva. Si ambas han empezado en el cero es posible que el receptor entienda que la segunda conexión es una continuación de la primera (si utilizan los mismos puertos).

Cierre de una conexión
Cuando una aplicación ya no tiene más datos que transferir, el procedimiento normal es cerrar la conexión utilizando una variación del mecanismo de 3 vías explicado anteriormente.

El mecanismo de cierre es algo más complicado que el de establecimiento de conexión debido a que las conexiones son full-duplex y es necesario cerrar cada uno de los dos sentidos de forma independiente.


TCP - Cierre de una conexión


La máquina que ya no tiene más datos que transferir, envía un segmento con el bit FIN activado y cierra el sentido de envío. Sin embargo, el sentido de recepción de la conexión sigue todavía abierto.
La máquina receptora recibe el segmento con el bit FIN activado y devuelve la correspondiente confirmación. Pero no cierra inmediatamente el otro sentido de la conexión sino que informa a la aplicación de la petición de cierre. Aquí se produce un lapso de tiempo hasta que la aplicación decide cerrar el otro sentido de la conexión.
La primera máquina recibe el segmento ACK.
Cuando la máquina receptora toma la decisión de cerrar el otro sentido de la comunicación, envía un segmento con el bit FIN activado y cierra la conexión.
La primera máquina recibe el segmento FIN y envía el correspondiente ACK. Observemos que aunque haya cerrado su sentido de la conexión sigue devolviendo las confirmaciones.
La máquina receptora recibe el segmento ACK.
Técnicas
NAT (Network Address Translation)
Es un estándar creado por la Internet Engineering Task Force (IETF) el cual utiliza una o más direcciones IP para conectar varios computadores a otra red (normalmente a Internet), los cuales tiene una dirección IP completamente distinta (normalmente una IP no válida de Internet). Por lo tanto, se puede utilizar para dar salida a redes públicas a computadores que se encuentran con direccionamiento privado o para proteger máquinas públicas.

Fue inicialmente propuesto como otra solución para la extinción de direcciones IP. Como ya sabemos para poder comunicarse en Internet se requieren direcciones IP públicas únicas (“legales”) para cada host. La idea en la que se basa NAT es que sólo una pequeña parte de la red de una organización está conectada con el exterior simultáneamente, es decir, sólo se asigna una dirección IP pública oficial a un host cuando va a comunicarse con el exterior, por tanto, solo es necesario un pequeño número de direcciones públicas. Los hosts internos pueden utilizar direcciones IP privadas (o direcciones IP no oficiales) y para los paquetes de salida el dispositivo NAT cambia la dirección origen privada por una dirección pública oficial. Igualmente para los paquetes de entrada el dispositivo NAT cambia la dirección pública por otra privada.



Funcionamiento
El protocolo TCP/IP tiene la capacidad de generar varias conexiones simultáneas con un dispositivo remoto. Para realizar esto, dentro de la cabecera de un paquete IP, existen campos en los que se indica la dirección fuente y destino con sus respectivos puertos. Esta combinación de números define una única conexión.

Un encaminador NAT cambia la dirección fuente (lo que se conoce como SNAT, Source NAT) en cada paquete de salida y, dependiendo del método, también el puerto de fuente para que sea único. Estas traducciones de dirección se almacenan en una tabla, para recordar que dirección y puerto le corresponde a cada dispositivo cliente y así saber donde deben regresar los paquetes de respuesta. Si un paquete que intente ingresar a la red interna no existe en la tabla de traducciones, entonces es descartado. Por ello las conexiones que se inicien en el exterior (Internet) hacia el interior (Intranet) no están permitidas, lo que hace que dicho encaminador NAT tenga el “efecto secundario” de servir de cortafuegos.

Debido a este comportamiento, si queremos ofrecer al exterior (Internet) un servicio, se puede definir en la tabla que en un determinado puerto y dirección, se pueda acceder a un determinado dispositivo, como por ejemplo un servidor web, lo que se denomina NAT inverso o DNAT (Destination NAT).

Resumiendo:

SNAT - Source NAT es cuando alteramos el origen del primer paquete: esto es, estamos cambiando el lugar de donde viene la conexión. Source NAT siempre se hace después del encaminamiento, justo antes de que el paquete salga por el cable. El enmascaramiento es una forma especializada de SNAT.

DNAT - Destination NAT es cuando alteramos la dirección de destino del primer paquete: esto es, cambiamos la dirección a donde se dirige la conexión. DNAT siempre se hace antes del encaminamiento, cuando el paquete entra por el cable. El port forwarding (reenvío de puerto), el balanceo de carga y el proxy transparente son formas de DNAT.

Tipos de NAT
NAT tiene muchas formas de funcionamiento, entre las que destaca:

NAT estático (Static NAT): Realiza un mapeo en la que una dirección IP privada se traduce a una correspondiente dirección IP pública de forma unívoca. Normalmente se utiliza cuando un dispositivo necesita ser accesible desde fuera de la red privada.
NAT dinámico (Dynamic NAT): Varias direcciones IP privadas se traducen a una dirección pública. Por ejemplo, si un router posee la IP pública 194.68.10.10, esta dirección se utiliza para representar todo un rango de direcciones privadas como puede ser 192.168.1.x. Implementando esta forma de NAT se genera automáticamente un firewall entre la red pública y la privada, ya que sólo se permite la conexión que se origina desde ésta última.
Sobrecarga
La forma más utilizada de NAT, proviene del NAT dinámico ya que toma múltiples direcciones IP privadas (normalmente entregadas mediante DHCP) y las traduce a una única dirección IP pública utilizando diferentes puertos. Esto se conoce también como PAT (Port Address Translation - Traducción de Direcciones por Puerto), NAT de única dirección o NAT multiplexado a nivel de puerto. Otra denominación es Network Address Port Translation (NAPT).

Herramientas
netstat
Es una herramienta que se ejecuta en modo terminal y que permite ver los puertos que nuestro equipo tiene abiertos.

Está disponible tanto en Windows como en Linux. A menudo se utiliza con opciones, de las cuales las más frecuentes son:

-a:  Muestra todas las conexiones
-n:  Muestra números de puerto
-p:  Muestra programa o aplicación que está usando el puerto
-t:  Puertos TCP (sólo Linux)
-u:  Puertos UDP(sólo Linux)
-l:  Sólo puertos en modo escucha.


Archivo:Netstat -na (Windows).png
netstat -na (Windows)
Archivo:Netstat -punta (Linux).png
netstat -punta (Linux)


nmap
Es una herramienta que se ejecuta en modo terminal y que permite ver los puertos que otro equipo tiene abiertos. Es una herramienta disponible para Windows y Linux, aunque no viene instalada por defecto. Es necesario instalarla.

Nmap es extremadamente potente y dispone de numerosas opciones para realizar distintos tipos de sondeos o escaneos. Dichas opciones pueden consultarse en la página de manual propia.

Archivo:Nmap -sS 192.168.1.1 (Sondeo de puertos abiertos).png
nmap -sS 192.168.1.1 (Sondeo de puertos abiertos)
Archivo:Man nmap (Página de manual de nmap en Linux).png
man nmap (Página de manual de nmap en Linux)

Existe un front-end gráfico conocido como zenmap.

Archivo:Zenmap (front-end para nmap).png
zenmap (front-end para nmap)
Cortafuegos
Un cortafuegos (firewall en inglés) es una parte de un sistema o una red que está diseñada para bloquear el acceso no autorizado, permitiendo al mismo tiempo comunicaciones autorizadas.

Se trata de un dispositivo o conjunto de dispositivos configurados para permitir, limitar, cifrar, descifrar, el tráfico entre los diferentes ámbitos sobre la base de un conjunto de normas y otros criterios.

Existen 2 tipos de cortafuegos:

Personales
De red
Los cortafuegos personales son los que el usuario final instala en su equipo con el fin de proteger dicho equipo.

Los cortafuegos de red son los que se instalan en una Intranet con el fin de proteger todos los equipos que se hallen detrás de él. Una variante de los cortafuegos de red son los cortafuegos de nivel de aplicación de tráfico HTTP, que suelen conocerse mayormente como proxy o proxy-caché (si este dispone de cacheo de páginas web), y permite que los ordenadores de una organización entren a Internet de una forma controlada.



De ahora en adelante nos ocuparemos de los cortafuegos de red.


Los cortafuegos pueden ser implementados en hardware o software, o una combinación de ambos. Los cortafuegos se utilizan con frecuencia para evitar que los usuarios de Internet no autorizados tengan acceso a redes privadas conectadas a Internet, especialmente intranets. Todos los mensajes que entren o salgan de la intranet pasan a través del cortafuegos, que examina cada mensaje y bloquea aquellos que no cumplen los criterios de seguridad especificados. También es frecuente conectar al cortafuegos a una tercera red, llamada «zona desmilitarizada» o DMZ, en la que se ubican los servidores de la organización que deben permanecer accesibles desde la red exterior.




Un cortafuegos correctamente configurado añade una protección necesaria a la red, pero que en ningún caso debe considerarse suficiente. La seguridad informática abarca más ámbitos y más niveles de trabajo y protección.



Políticas del cortafuegos
Hay dos políticas básicas en la configuración de un cortafuegos que cambian radicalmente la filosofía fundamental de la seguridad en la organización:

Política restrictiva: Se deniega todo el tráfico excepto el que está explícitamente permitido. El cortafuegos obstruye todo el tráfico y hay que habilitar expresamente el tráfico de los servicios que se necesiten. Esta aproximación es la que suelen utilizar la empresas y organismos gubernamentales.
Política permisiva: Se permite todo el tráfico excepto el que esté explícitamente denegado. Cada servicio potencialmente peligroso necesitará ser aislado básicamente caso por caso, mientras que el resto del tráfico no será filtrado. Esta aproximación la suelen utilizar universidades, centros de investigación y servicios públicos de acceso a Internet.
La política restrictiva es la más segura, ya que es más difícil permitir por error tráfico potencialmente peligroso, mientras que en la política permisiva es posible que no se haya contemplado algún caso de tráfico peligroso y sea permitido por omisión.

Ejemplos de cortarfuegos para Linux
iptables (su sucesor será nftables)
IPCop
Shorewall
SmoothWall
UFW – Uncomplicated Firewall
Proxy-caché
El término proxy significa intermediario. Un proxy es un equipo o software intermediario que hace peticiones a distintos servidores en representación del equipo que se halla detrás de proxy haciendo uso de él. Las peticiones más frecuentes son aquellas que se realizan a páginas web aunque pueden ser de otro tipo. Pueden ser peticiones HTTP(páginas web), FTP(transferencia de archivos), DNS(resolución de nombres), …

Cuando un proxy hace una petición a un servidor aparece como origen de la petición el mismo proxy ocultando de esta forma el equipo que realizó la petición original detrás del proxy.

Los proxies suelen disponer de una memoria denominada caché donde se van almacenando el resultado de todas las peticiones por si en un futuro próximo otro equipo detrás del proxy realizase la misma petición. Esto tiene dos ventajas:

Aumenta la velocidad de obtención de respuesta puesto que está almacenada en la caché.
Ahorra ancho de banda puesto que dicha petición no tiene que volver a hacerse al servidor.
Debido a que la mayoría de los proxies disponen de una caché, el término empleado para referirse a ellos es el de proxy-caché. En algún caso particular un proxy podría no disponer de caché pero, entonces, no dispondría de las ventajas indicadas anteriormente. Soló proporcionaría cierto anonimato al equipo que realiza peticiones detrás del proxy.

Resumiendo, un proxy, o servidor proxy, en una red informática, es un servidor (un programa o sistema informático), que sirve de intermediario en las peticiones de recursos que realiza un cliente (A) a otro servidor (C). Por ejemplo, si una hipotética máquina A solicita un recurso a C, lo hará mediante una petición a B, que a su vez trasladará la petición a C; de esta forma C no sabrá que la petición procedió originalmente de A. Esta situación estratégica de punto intermedio suele ser aprovechada para soportar una serie de funcionalidades: control de acceso, registro del tráfico, prohibir cierto tipo de tráfico, mejorar el rendimiento, mantener el anonimato, proporcionar Caché web, etc; este último sirve para acelerar y mejorar la experiencia del usuario.

Tipos de proxy-caché según localización
Proxy local
En este caso el que quiere implementar la política es el mismo que hace la petición. Por eso se le llama local. Suelen estar en la misma máquina que el cliente que hace las peticiones. Son muy usados para que el cliente pueda controlar el tráfico y pueda establecer reglas de filtrado que por ejemplo pueden asegurar que no se revela información privada (Proxys de filtrado para mejora de la privacidad).

Proxy externo
El que quiere implementar la política del proxy es una entidad externa. Por eso se le llama externo. Se suelen usar para implementar cacheos, bloquear contenidos, control del tráfico, compartir IP, etc.

Tipos de proxy según su uso
Los proxies que veremos a continuación son todos ellos externos.

Proxy HTTP, FTP, …
Es el tipo de proxy más conocido. Es utilizado ampliamente como intermediario y memoria caché entre una red local e Internet. El tipo de tráfico cacheado principalmente es HTTP y FTP. A menudo se le añade un filtro de contenido con listas negras para bloqueo de determinados sitios. Puede además estar complementado con algún tipo de antivirus que comprobará todo el tráfico destinado a los equipos de la red local, con lo cual, en principio, no sería necesario de disponer de antivirus en cada PC de red, aunque si aconsejable.

Un software muy popular para proxy-caché http es Squid.

Caché DNS
Un servidor de nombres (DNS) en nuestra red local no tiene porque tener configurado un dominio. La configuración más simple es aquella en la cual únicamente actúa como caché DNS (el término proxy no se suele utilizar en este caso). Una caché DNS permite a un navegador web adquirir información de DNS de dicha caché, siempre que esta información se haya almacenado en caché peticiones anteriores, sin la necesidad de acceder a los servidores DNS públicos, lo que resulta en la navegación web más rápida.

El software más utilizado tanto de servidor DNS como caché DNS es Bind. Un software más ligero es dnsmasq.

Proxy inverso
Un servidor proxy inverso es un dispositivo de seguridad que suele desplegarse en la DMZ de una red para proteger a los servidores HTTP de una intranet corporativa, realizando funciones de seguridad que protegen a los servidores internos de ataques de usuarios en Internet.

El servidor proxy inverso protege a los servidores HTTP internos proporcionando un punto de acceso único a la red interna.

El administrador puede utilizar las características de autenticación y control de acceso del servidor proxy inverso para controlar quién puede acceder a los servidores internos y controlar a qué servidores puede acceder cada usuario individual.

Todo el tráfico hacia los servidores de la intranet parece dirigido a una única dirección de red (la dirección del servidor proxy inverso).

El administrador realiza configuraciones de correlación de URL en el servidor proxy inverso que hace esta redirección posible. Todo el tráfico enviado a los usuarios de Internet desde los servidores internos parece proceder de una única dirección de red.

Finalmente, con algoritmos perfeccionados, el proxy inverso puede distribuir la carga de trabajo mediante la redirección de las solicitudes a otros servidores similares. Este proceso se denomina balanceo de carga. Un software muy utilizado para esto es HAProxy.

Proxy web
Los proxy web se utilizan para navegación anónima.

Los equipos de una red local que disponga de un proxy-caché y filtro de contenido, pueden saltárselo mediante el uso de un proxy web. Este último, normalmente funciona sobre HTTPS puesto que dicho tipo de tráfico no es “cacheable” por el proxy de la red local. El administrador del proxy-caché de la red local, a menudo, no puede bloquear el tráfico HTTPS puesto que muchas webs (de correo, compras, administración pública, bancos, …) utilizan dicho protocolo. La solución es elaborar una lista negra con los proxies web más conocidos y activarla en el filtro de contenido.



Cortafuegos y Proxy-caché en un sólo equipo
Proxies transparentes
Muchas organizaciones (incluyendo empresas, colegios y familias) usan los proxies para reforzar las políticas de uso de la red o para proporcionar seguridad y servicios de caché. Normalmente, un proxy Web o NAT no es transparente a la aplicación cliente: debe ser configurada para usar el proxy, manualmente. Por lo tanto, el usuario puede evadir el proxy cambiando simplemente la configuración.






Un proxy transparente combina un servidor proxy con un cortafuegos de manera que las conexiones son interceptadas y desviadas hacia el proxy sin necesidad de configuración en el cliente, y habitualmente sin que el propio usuario conozca de su existencia.


Además, suele ser frecuente en el proxy-caché la instalación de un servicio de control de acceso a la web y algún antivirus de red. El control de acceso a la web normalmente se implementa mediante algún tipo de software de filtrado por contenido (además de URL e IP, puede bloquear accesos a páginas web según el contenido de estás (palabras desagradables, obscenas o similares e incluso por imágenes -aunque esté último método suele dar peores resultados-). Un software libre muy utilizado para ello es Dansguardian y sus listas negras asociadas.



Archivo:Squid + Dansguardian.png
Squid + Dansguardian

A continuación se muestra un ejemplo de script Linux para cortafuegos con reglas activadas para habilitar un proxy-transparente. Básicamente lo que hace es dirigir todas las petición a puertos destino 80 (web), 3128 (cliente despistado con configuración manual de proxy) y algunos otros puertos que nos interesen al puerto 8080 (dansguardian) donde tenemos el filtro de contenido.



#!/bin/sh
### BEGIN INIT INFO
# Provides:          cortafuegos
# Required-Start:    balanceo-de-carga
# Required-Stop:
# Should-Start:
# Default-Start:     2 3 4 5
# Default-Stop:      0 1 6
# Short-Description: Cortafuegos para IES Guadalpeña - Dpto. Informática
# Description:       Cortafuegos contiene las reglas de iptables que se aplicarán
#                    después de la configuración del soporte de red o networking
#                    y del balanceo de carga (si está habilitado).
#                    Proporciona redirección de puertos en el canal PREROUTING 
#                    para dar soporte a un proxy transparente.
### END INIT INFO
# Variables generales
PATH=/sbin:/usr/sbin:/bin:/usr/bin
NAME=cortafuegos
PIDFILE=/var/run/$NAME.pid
# Variables de red
IF_ADSL1="p1p1"            # Interface conectada a ADSL1
IF_ADSL2="p4p1"            # Interface conectada a ADSL2
IF_LOCAL="p2p1"            # Interface conectada a la LAN
IP_ADSL1="192.168.1.2"     # IP de la IF_ADSL1
IP_ADSL2="192.168.2.2"     # IP de la IF_ADLS2
IP_LOCAL="10.0.0.1"        # IP de la IF_LOCAL, Gateway Local
NET_ADSL1="192.168.1.0/24" # Red para IF_ADSL1
NET_ADSL2="192.168.2.0/24" # Red para IF_ADLS2
NET_LOCAL="10.0.0.0/8"     # Red para IF_LOCAL
GW_ADSL1="192.168.1.1"     # Gateway para ADSL1
GW_ADSL2="192.168.2.1"     # Gateway para ADSL2
###### START
do_start () {
# Reglas de iptables 
echo "Limpiando Reglas Anteriores..."
iptables -F
iptables -X
iptables -Z
iptables -t nat -F
iptables -t mangle -F

# Ahora hago el NAT
echo "Activando NAT ..."
echo 1 > /proc/sys/net/ipv4/ip_forward
# iptables -t nat -A POSTROUTING -s ${NET_LOCAL} -o ${IF_ADSL1} -j MASQUERADE
# iptables -t nat -A POSTROUTING -s ${NET_LOCAL} -o ${IF_ADSL2} -j MASQUERADE
iptables -t nat -A POSTROUTING -o ${IF_ADSL1} -j SNAT --to-source ${IP_ADSL1}
iptables -t nat -A POSTROUTING -o ${IF_ADSL2} -j SNAT --to-source ${IP_ADSL2}

# Redirecciono al Proxy
echo "Creando reglas para proxy transparente..."
iptables -t nat -A PREROUTING -i ${IF_LOCAL} -p tcp --dport http      -j DNAT --to ${IP_LOCAL}":8080"
iptables -t nat -A PREROUTING -i ${IF_LOCAL} -p tcp --dport 81        -j DNAT --to ${IP_LOCAL}":8080"
iptables -t nat -A PREROUTING -i ${IF_LOCAL} -p tcp --dport 8080:8099 -j DNAT --to ${IP_LOCAL}":8080"
iptables -t nat -A PREROUTING -i ${IF_LOCAL} -p tcp --dport 3128:3130 -j DNAT --to ${IP_LOCAL}":8080"

#echo "Reglas Aplicadas"
}
###### STATUS
do_status () {
echo "Listado de Reglas activas"
iptables -L -n -v
iptables -t nat -L -n -v
iptables -t mangle -L -n -v
}
###### STOP
do_stop () {
echo "Limpiando Reglas anteriores..."
iptables -F
iptables -X
iptables -Z
iptables -t nat -F
iptables -t mangle -F
}
case "$1" in
  start|"")
        do_start
        ;;
  restart)
        do_stop
        do_start
        ;;
  reload|force-reload)
        echo "Error: el argumento '$1' no está soportado" >&2
        exit 3
        ;;
  stop)
        do_stop
        ;;
  status)
        do_status
        ;;
  *)
        echo "Uso: cortafuegos [start|stop|restart|status]" >&2
        exit 3
        ;;
esac
:


Balanceadores de carga de red
En informática, el balanceo de carga distribuye las cargas de trabajo a través de múltiples recursos informáticos, como procesadores (balanceo de cómputo), enlaces de red (balanceo de red), ordenadores, cluster de ordenadores o unidades de disco. El balanceo de carga tiene como objetivo optimizar el uso de recursos, maximizar el rendimiento, minimizar el tiempo de respuesta y evitar la sobrecarga de cualquier recurso individual. El uso de varios componentes con el equilibrio de carga en lugar de un solo componente puede aumentar la confiabilidad mediante redundancia. El equilibrio de carga por lo general implica software o hardware dedicado, tal como un switch multicapa o un proceso DNS .

El balanceo de carga difiere del channel bonding en que el primero se realiza en la capa 4 del modelo OSI, mientras que el channel bonding hace la división del tráfico en un nivel inferior, ya en la capa 3 del modelo OSI o en el enlace de datos capa 2 del modelo OSI).

Existen distintos tipos de balanceo de carga según el elemento equilibrado siendo los más frecuentes:

Balanceo de carga entre procesadores (Operaciones de cómputo)
Balanceo de carga entre líneas de red (Tráfico de red)
Aquí se tratará el balanceo de carga de red y en concreto los dos tipos existentes:

Balanceo de carga en el lado cliente
Balanceo de carga en el lado servidor
Balanceo en el lado cliente (Multihoming)
El Multihoming (comúnmente conocido como ruta de doble WAN) es la capacidad de equilibrar el tráfico a través de dos o más enlaces WAN sin necesidad de utilizar protocolos de enrutamiento complejos como BGP.

Esta técnica equilibra sesiones de red como web, correo electrónico, etc a través de múltiples conexiones con el fin de extender la cantidad de ancho de banda utilizado por los usuarios de la LAN, lo que aumenta la cantidad total de ancho de banda disponible. Por ejemplo, un usuario tiene una única conexión a la WAN a 10 Mbit/s. Desea añadir una segunda línea de banda ancha (cable, DSL, inalámbrico, etc.) a 20 Mbit/s. Esto les proporcionará un total de 30 Mbits/s de ancho de banda para balancear sesiones.

El balanceo de sesión no sólo eso, equilibra sesiones a través de cada enlace WAN. Cuando los navegadores Web se conectan a Internet, que comúnmente se abren varias sesiones, una para el texto, otra para una imagen, otro por alguna otra imagen, etc. Cada una de estas sesiones pueden ser equilibradas a través de las conexiones disponibles. Una aplicación FTP sólo utiliza una sola sesión por lo que no está equilibrada; sin embargo, si se realiza una conexión FTP secundaria, entonces puede ser equilibrada por lo que, en conjunto, el tráfico se distribuye uniformemente a través de las diversas conexiones y por lo tanto proporciona un aumento global en el rendimiento.

A continuación se muestra un esquema de red donde se puede realizar “balanceo de carga” con 2 líneas de salida a internet.



Balanceo de carga en el lado servidor
El problema a solucionar es la sobrecarga de los servidores. Se puede balancear cualquier protocolo, pero dado que este sitio se centra en las tecnologías web, el artículo trata exclusivamente de balancear servidores HTTP.

Al mismo tiempo, si el balanceador detecta la caída de uno de los servidores web, puede optar por no enviarle más peticiones. De esta forma, si uno de los servidores web se cae, las peticiones del cliente no se dirigen al servidor caído.

Vemos que el balance de carga también contribuye a una infraestructura redundante y de alta disponibilidad (aunque no la asegura, el balance de carga por sí mismo no alcanza para tener HA1 ). En este punto creo conveniente introducir los conceptos básicos que se manejarán a lo largo del artículo:

Balanceador: es un sistema, software o hardware, que distribuye las peticiones de los clientes de forma equitativa entre distintos servidores de “backend”.
Servidor de backend: es un servidor (web en este caso), que responde la petición del usuario.
Así el balanceador distribuye las peticiones y son los servidores de backend, quienes arman la respuesta efectiva al cliente. Para balancear la carga entre varios servidores es deseable que el mismo balanceador sea justo (fair), y que detecte servidores sobrecargados para dejar de enviarle peticiones hasta que no baje su carga. Este mismo mecanismo sirve para que un balanceador no envíe peticiones a un servidor caído.





Balanceo mediante DNS
La forma más elemental de balancear la carga entre varios servidores esa utilizando el DNS. Por ejemplo, buscando la IP de yahoo.com con el comando dig he obtenido el siguiente resultado. En este caso responden 3 servidores: 206.190.36.45, 98.139.183.24 y 98.138.253.109.


Balanceo mediante DNS
Este es el tipo de balanceo más elemental que se puede hacer, y tiene una ventaja muy importante: simplicidad y eﬁciencia; ya que en principio lo único que se necesitan son varios servidores con distintas IPs, por lo que es barato, simple y fácil de mantener. Sin embargo, el balance de carga por DNS tiene algunos inconvenientes:

El balanceo mediante DNS no tiene en cuenta la carga de cada servidor.
El balanceo mediante DNS no detecta si un servidor ha caído.
Balanceo mediante balanceador
Una solución menos simple pero más adecuada es utilizar un hardware o software balanceador de carga. Debemos tener en cuenta que un balanceador de este tipo es por definición un proxy inverso. Actualmente un software muy utilizado es HAProxy.

Los balanceadores de carga tienen varias ventajas sobre el balanceado mediante DNS:

Un balanceador puede tener en cuenta la carga de cada equipo y distribuir las peticiones según esas cargas.
Si un servidor queda fuera de línea, el balanceador de carga lo detecta y redirige las peticiones web a los otros servidores..
Por último, la mayoría de los balanceadores pueden mantener las sesiones de los usuarios, de forma que un usuario que inicia sesión en el servidor “A” siempre sea dirigido por el balanceador al mismo servidor “A” (de no hacerlo el usuario perdería la sesión). Sin embargo, el balance de carga por DNS es del tipo “Round Robin”, por lo que es casi seguro que el usuario pierda la sesión.


VPN
Una red privada virtual, RPV, o VPN de las siglas en inglés de Virtual Private Network, es una tecnología de red que permite una extensión segura de la red local (LAN) sobre una red pública o no controlada como Internet. Permite que la computadora en la red envíe y reciba datos sobre redes compartidas o públicas como si fuera una red privada con toda la funcionalidad, seguridad y políticas de gestión de una red privada. Esto se realiza estableciendo una conexión virtual punto a punto mediante el uso de conexiones dedicadas, cifrado o la combinación de ambos métodos.

Ejemplos comunes son la posibilidad de conectar dos o más sucursales de una empresa utilizando como vínculo Internet, permitir a los miembros del equipo de soporte técnico la conexión desde su casa al centro de cómputo, o que un usuario pueda acceder a su equipo doméstico desde un sitio remoto, como por ejemplo un hotel. Todo ello utilizando la infraestructura de Internet.

El protocolo estándar de facto es el IPSEC, pero también están PPTP, L2F, L2TP, SSL/TLS, SSH, etc. Cada uno con sus ventajas y desventajas en cuanto a seguridad, facilidad, mantenimiento y tipos de clientes soportados.

Aplicaciones software muy conocidas son Hamachi para uso doméstico y OpenVPN para uso en empresas.

Básicamente existen 2 tipos de conexión VPN:

VPN de acceso remoto
Es quizás el modelo más usado actualmente, y consiste en usuarios o proveedores que se conectan con la empresa desde sitios remotos (oficinas comerciales, domicilios, hoteles, aviones preparados, etcétera) utilizando Internet como vínculo de acceso. Una vez autenticados tienen un nivel de acceso muy similar al que tienen en la red local de la empresa. Muchas empresas han reemplazado con esta tecnología su infraestructura dial-up (módems y líneas telefónicas).

VPN punto a punto
Este esquema se utiliza para conectar oficinas remotas con la sede central de la organización. El servidor VPN, que posee un vínculo permanente a Internet, acepta las conexiones vía Internet provenientes de los sitios y establece el túnel VPN. Los servidores de las sucursales se conectan a Internet utilizando los servicios de su proveedor local de Internet, típicamente mediante conexiones de banda ancha. Esto permite eliminar los costosos vínculos punto a punto tradicionales (realizados comúnmente mediante conexiones de cable físicas entre los nodos), sobre todo en las comunicaciones internacionales. Es más común el siguiente punto, también llamado tecnología de túnel o tunneling.

Tunneling
La técnica de tunneling consiste en encapsular un protocolo de red sobre otro (protocolo de red encapsulador) creando un túnel dentro de una red de computadoras. El establecimiento de dicho túnel se implementa incluyendo una PDU (unidades de datos de protocolo) determinada dentro de otra PDU con el objetivo de transmitirla desde un extremo al otro del túnel sin que sea necesaria una interpretación intermedia de la PDU encapsulada. De esta manera se encaminan los paquetes de datos sobre nodos intermedios que son incapaces de ver en claro el contenido de dichos paquetes. El túnel queda definido por los puntos extremos y el protocolo de comunicación empleado, que entre otros, podría ser SSH.

Actividades
En términos informáticos, referido a redes, ¿qué es un puerto?
Atendiendo al número de puerto, ¿cómo se clasifican?
¿Qué número de puerto y tipo (TCP, UDP) utilizan los siguientes servidores?
HTTP
HTTPS
DHCP
DNS
SSH
FTP
SMB (Compartición de archivos e impresoras)
MySQL
NTP (Tiempo de red)
BitTorrent
POP3 (Recepción de correo)
IMAP4 (Recepción de correo)
SMTP (Envío de correo)
¿Cuáles son los principales protocolos de la capa de transporte?
Características de UDP.
Características de TCP.
Campos de un segmento TCP. Bits SYN, ACK y FIN.
Cuando abrimos un puerto, ¿qué es una apertura pasiva y qué es una apertura activa?
Proceso de inicio de una conexión TCP.
Proceso de cierre de una conexión TCP.
Cuando se utiliza traducción de direcciones, la traducción de la dirección IP origen se denomina _________________________________
Cuando se utiliza traducción de direcciones, la traducción estática de direcciones se denomina _____________________________
Cuando se utiliza traducción de direcciones, la traducción de la dirección IP destino se denomina ___________________________
Cuando se utiliza traducción de direcciones, la traducción dinámica de direcciones se denomina ____________________________
Si tenemos un router NAT, ¿es posible iniciar una conexión desde Internet a nuestra Intranet a través de él? ¿Por qué? En el caso de que no sea posible, ¿qué debemos hacer para que lo sea?
Tipos de cortafuegos dependiendo del lugar de la red donde se colocan.
Tipos de políticas de los cortafuegos.
¿Qué es el SNAT? ¿Y el enmascaramiento?
¿Qué es el DNAT? Explica cada uno de los siguientes tipos de DNAT:
Port forwarding (redirección de puertos)
Balanceo de carga
Proxy transparente


IPTABLES.
Uso de iptables
iptables -t TABLA -L                      Listado de reglas
iptables -t TABLA -F                      Flush de reglas (borrado total)
 
iptables -t TABLA -P CANAL ACCEPT        Política por defecto permisiva
iptables -t TABLA -P CANAL DROP          Política por defecto restrictiva
 
iptables -t TABLA -A CANAL REGLA          Añadir regla
iptables -t TABLA -D CANAL REGLA          Borrar regla
TABLAS	CANALES o CADENAS
filter	INPUT, FORWARD, OUTPUT
nat	PREROUTING, POSTROUTING
mangle	


REGLAS	SIGNIFICADO
-s IP	Dirección IP origen
-d IP	Dirección IP destino
-i INTERFAZ	Tarjeta de red de entrada. Input
-o INTERFAZ	Tarjeta de red de salida. Output
-p PROTOCOLO	Protocolo (tcp, udp, icmp, ...)
--sport PUERTO	Puerto de origen. Source port
--dport PUERTO	Puerto de destino. Dest. port
-j ACCEPT	Aceptar paquetes
-j DROP	Ignorar paquetes
EJEMPLOS DE REGLAS:

Aceptamos paquetes TCP al puerto 80 desde cualquier IP.
iptables -t filter -A INPUT -s 0.0.0.0/0 -p tcp --dport 80 -j ACCEPT

Bloqueamos paquetes al servidor MySQL
iptables -t filter -A INPUT -p tcp --dport 3306 -j DROP

Permitimos salida a peticiones HTTPS
iptables -t filter -A OUTPUT -p tcp -m tcp --dport 443 -j ACCEPT

Permitimos que los equipos de la red 192.168.10.0 conectados a mi tarjeta eth1 puedan ver páginas web
iptables -t filter -A FORWARD -s 192.168.10.0/24 -i eth1 -p tcp --dport 80 -j ACCEPT

Política de preenrutamiento
iptables -t nat -P PREROUTING ACCEPT

Política de preenrutamiento
iptables -t nat -P POSTROUTING ACCEPT

Todo lo que venga por la tarjeta eth0 y vaya al puerto 80 lo redirigimos a una maquina interna
iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j DNAT --to 192.168.10.12:80
 
Todo lo que salga de nuestra red 192.168.10.0 por la tarjeta eth0 se enmascara (es un tipo de SNAT)
iptables -t nat -A POSTROUTING -s 192.168.10.0/24 -o eth0 -j MASQUERADE

Haciendo uso del resumen que aparece arriba y de los ejemplos que aparecen en http://www.pello.info/filez/firewall/iptables.html, ¿cómo escribirías las siguientes reglas?

Hacer un listado de reglas de la tabla filter.
Hacer un listado de reglas de la tabla nat.
Hacer un borrado total (flush) de reglas de la tabla filter.
Hacer un borrado total (flush) de reglas de la tabla nat.
No permitir entrada del equipo 10.0.5.200 al servidor web de nuestro equipo
No permitir entrada del equipo 10.0.5.200 al servidor web 20.20.20.20.
Poner política por defecto ACCEPT para los canales INPUT, FORWARD y OUTPUT.
Poner política por defecto ACCEPT para los canales PREROUTING y POSTROUTING.
Hacer un enmascaramiento de los paquetes de nuestra red 10.0.5.0/24 que salen por eth2. (SNAT)
Todo lo que venga por la tarjeta eth0 destinado al puerto 80 se manda a 10.0.5.222 y puerto 8080. (DNAT)
Ejecuta netstat -na en tu equipo Windows. Muestra una captura de los puertos abiertos.
Ejecuta netstat -punta en un equipo Linux. Muestra una captura de los puertos abiertos.
Ejecuta Zenmap desde un equipo (Windows o Linux). Realiza las siguientes operaciones:
Ver puertos abiertos del equipo 10.0.5.1.
Ver lista de equipos en nuestra subred 10.0.5.0/24.
Ver puertos abiertos de los equipos www.google.es y 8.8.8.8
Hacer un trazado de ruta a los equipos anteriores. Hacer una captura de pantalla donde se muestre la topología.
Hacer un trazado de ruta a www.google.es/30. Hacer una captura de pantalla donde se muestre la topología.
Hacer un pequeño tutorial de configuración de un punto de acceso. (Opcional)
Estado del AP.
Claves de acceso.
Modos de funcionamiento (Repetidor, Bridge, Punto de Acceso, ...)
Configuración de la red Wi-Fi (SSID, Seguridad).
Hacer un pequeño tutorial de configuración de un router.
Estado del router.
Claves de acceso al router.
Configuración de IP Interna / Máscara.
Configuración del DHCP.
Configuración de la red Wi-Fi (SSID, Seguridad) si es un router inalámbrico.
Filtrado de MAC si está disponible.
NAT. Port forwarding. Apertura de puertos.
Hacer un pequeño tutorial de configuración de un switch gestionable si está disponible. (Opcional)
Estado del switch.
Claves de acceso.
Configuración de IP Interna / Máscara.
Configuración de VLANs si está disponible.
¿Qué es y para que sirve un proxy? Ventajas de su uso.
¿Qué diferencias existen entre un proxy normal y uno inverso?
Si tenemos 3 líneas ADSL de distintos ISP y queremos utilizarlas a la vez para nuestra red local para tener una conexión a Internet tolerante a fallos y mayor ancho de banda, ¿qué técnica podemos utilizar?
Tenemos 4 servidores web con el mismo contenido y queremos balancear las peticiones de los clientes entre los 4 servidores. Explica las 2 formas principales de hacerlo.


Bibliografía y referencias
RFC 2663
Listados de puertos más frecuentemente usados
Explicación de la técnica NAT
Explicación de todos los tipos de NAT (en inglés)
NAT en Cisco
Port Forwardind o Redirección de puertos
Manual práctico de IPTABLES
Documentación de IPROUTE2
Manual de proxy-caché transparente en PDF
Balanceo de carga en el lado cliente con iptables e iproute2
Instalación y configuración básica de HAProxy
HAproxy configuration and Load balancing Part 1
HAproxy configuration and Load balancing Part 2
Tema 12




Bibliografía y referencias
Control de Acceso al Medio (MAC) de distintas tecnologías
Antiguo módem analógico
LMDS
Blog francés acerca de la fibra óptica (fotos interesantes)
Proyecto Innovación sobre Fibra y Redes




ENLACES

Material CISCO CCNA
Módulo de PAR en IES Suárez de Figueroa (Extremadura)
Módulo de PAR en IES Gonzalo Narareno (Andalucía)
y por supuesto

Google
Wikipedia, la enciclopedia libre
YouTube
Contenido del Libro Grado de desarrollo: 75% (a fecha de 19:58 04 feb 2015 (UTC))
Versión: Junio 2015












Planificación y Administración de RedesGrado de desarrollo: 75% (a fecha de 20:03 04 feb 2015 (UTC))▶[+32] Índice, Introducción, Página de edición, Enlaces, Texto completo
Este es un libro de redes. Está especialmente orientado a los contenidos de Grado Superior del ciclo de Administración de Sistemas Informáticos en Red de la Familia Profesional de Informática y Comunicaciones en la Formación Profesional de Andalucía, España.
Se pueden orientar los contenidos, en parte, al módulo de "Redes Locales" del ciclo de grado de Sistemas Microinformáticos y Redes (SMR) de la Familia Profesional de Informática y Comunicaciones.
Y, por supuesto, puede ser útil para cualquier persona que desee adquirir los conocimientos de cómo se organizan y funcionan las redes.▶
